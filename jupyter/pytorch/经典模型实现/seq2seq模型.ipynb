{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "混合前端的seq2seq模型部署\n",
    "seq2seq模型由两个递归神经网络组成：编码器encoder和解码器decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "PAD_token = 0 #used for padding short sentences\n",
    "SOS_token = 1 #Start-of-sentence token\n",
    "EOS_token = 2 #End-of-sentence token\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "数据预处理\n",
    "在训练之前往往需要建立一个模型词汇表，把每个单词都映射到一个整数索引，\n",
    "我们使用Voc对象来包含从单词到索引的映射，以及词汇表中的单词总数，我们将在运行模型之前加载对象\n",
    "\n",
    "此外，使用normalizeString函数将字符串中的所有字符转换为小写，并删除所有非字母字符\n",
    "使用indexesFromSentence函数接受一个单词的句子并返回相应的单词索引序列。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token:\"PAD\", SOS_token:\"SOS\", EOS_token:\"EOS\"}\n",
    "        self.num_words = 3 #Count SOS, EOS, PAD\n",
    "        \n",
    "    def addSenetnce(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "            \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    \n",
    "    def trim(self, min_count):\n",
    "        #如果某个词出现的次数小于min_count,则把他去掉\n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed = True\n",
    "        keep_words = []\n",
    "        for k,v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "                \n",
    "        print('keep_words {} /{} ={:.4f}'.format(len(keep_words), len(self.word2index), len(keep_words)/len(self.word2index)))\n",
    "        \n",
    "        #重建dict\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token:\"PAD\", SOS_token:\"SOS\", EOS_token:\"EOS\"}\n",
    "        self.num_words = 3\n",
    "        for word in keep_words:\n",
    "            self.addWord(word)\n",
    "            \n",
    "def normalizeString(s):\n",
    "    #将字母小写，并过滤掉那些非字母字符\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \",s)\n",
    "    return s\n",
    "\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    #返回一个句子的Index序列\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "编码器模块\n",
    "    我们通过torch.nn.gru模块实现编码器的RNN。本模块接受一批语句（嵌入单词的向量）的输入，我们最终返回双向GRU的输出的和。\n",
    "    由于我们的模型是使用批处理进行训练的，所以我们的EncoderRNN模型的forward函数需要一个填充的输入批处理。\n",
    "    为了批量处理可变长度而句子，我们通过MAX_LENGTH令牌允许一个句子中支持的的最大长度，并且批处理中所有小于MAX_LENGTH令牌的句子都用专门的PAD_token令牌填充在最后。\n",
    "    而要使用带有pytorch RNN模块的批量填充，我们必须要在forward模块调用torch.nn.utils.rnn.pack_padded_sequence和torch.nn.utils.rnn.pad_packed_sequence进行数据转换。\n",
    "    同时forward函数还需要接受一个input_length列表，其中包含批处理中每个句子的长度，该输入在填充时通过torch.nn.utils.rnn.pack_padded_sequence使用。\n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        \n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, \n",
    "                          dropout=(0 if n_layers==1 else dropout),bidirectional=True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lenghts, hidden=None):\n",
    "        \n",
    "        embedded = self.embedding(input_seq)\n",
    "        \n",
    "        #pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lenghts)\n",
    "        \n",
    "        #forward pass through biGRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        #unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        \n",
    "        #sum bidirectional GRU outputs\n",
    "        outputs = outputs[:,:,:self.hidden_size] + outputs[:,:,self.hidden_size]\n",
    "        \n",
    "        #return output and final hidden state\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attention模块\n",
    "    接下来我们定义注意力模块，这个模块将用作解码器模型中的子模块。\n",
    "    它取当前decoder的输出和encoder的输出，并且返回一个attention列表energies.\n",
    "    这个energies与编码器输出的输出大小相同，两者最终相乘，得到一个加权张量，其最大值表示在特定时间步长解码的与源语句最相关的部分。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in [\"dot\",\"general\",\"concat\"]:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "            \n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == \"general\":\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == \"concat\":\n",
    "            self.attn = torch.nn.Linear(self.hidden_size*2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden*encoder_output, dim=2)\n",
    "    \n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden*energy, dim=2)\n",
    "    \n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1,-1), encoder_output),2)).tanh()\n",
    "        return torch.sum(self.v*energy, dim=2)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        #计算the attention weights(energies) based on the given method\n",
    "        \n",
    "        if self.method == \"general\":\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == \"concat\":\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == \"dot\":\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "    \n",
    "        attn_energies = attn_energies.t() #将batch_size和max_length转置\n",
    "        \n",
    "        #return the softmax normalized probability scores(with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        \n",
    "        #Define layers\n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        #使用单向GRU\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "    \n",
    "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "        #we run this one step(word) at a time\n",
    "        #get embedding of current input word\n",
    "        \n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "        \n",
    "        #forward through unidirectional GRU\n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        \n",
    "        #calculate attention weights from the current GRU output\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
