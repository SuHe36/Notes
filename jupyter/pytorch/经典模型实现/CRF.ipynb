{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF(nn.Module):\n",
    "    \"\"\"\n",
    "    这个主要是线性链条件随机场\n",
    "    nb_labels(int): 标注序列的总的类别数；\n",
    "    bos_tag_id(int): 表示句子起始符号对应的id\n",
    "    eos_tag_id(int): 表示句子结束符号对应的id\n",
    "    batch_first(bool): 是个布尔变量，表示向量的第一维是否表示batch 维度\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, nb_labels, bos_tag_id, eos_tag_id, batch_first=True):\n",
    "        super().__init__()\n",
    "        self.nb_labels = nb_labels\n",
    "        self.BOS_TAG_ID = bos_tag_id\n",
    "        self.EOS_TAG_ID = eos_tag_id\n",
    "        self.batch_first = batch_first\n",
    "        self.transitions = nn.Parameter(torch.empty(self.nb_labels, self.nb_labels))\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.uniform_(self.transitions, -0.1,0.1)\n",
    "        # 将transitions矩阵，也就是lable与label之间的转移矩阵进行随机初始化，(-0.1,0.1)之间的均匀分布\n",
    "        self.transitions.data[:, self.BOS_TAG_ID] = -10000.0\n",
    "        # 因为不允许有存在label转移到下一个label为bos，所以将他们的值设置为-10000，因为exp(-10000)接近于0\n",
    "        self.transitions.data[self.EOS_TAG_ID,:] = -10000.0\n",
    "        # 同理，不允许eos转移到任意的下一个label，所以也将他们的值设置为-10000\n",
    "        \n",
    "    \n",
    "    def forward(self, emissions, tags, mask=None):\n",
    "        \"\"\"\n",
    "        计算负对数似然损失\n",
    "        \"\"\"\n",
    "    nll = -self.log_likelihood(emissions, tags, mask=mask)\n",
    "    return nll\n",
    "\n",
    "    def log_likelihood(self, emissions, tags, mask=None):\n",
    "        \"\"\"\n",
    "        计算损失函数\n",
    "        emissions(torch.tensor): 维度是(batch_size, seq_len, nb_labels)，是模型输出的句子的每个位置对于每个label的score，\n",
    "                    如果bach_first为false的话，维度就是(seq_len, batch_size, nb_labels)。下同\n",
    "        \n",
    "        tags(torch.tensor): 维度是(batch_size,seq_len), 句子序列的gold labels\n",
    "        \n",
    "        mask(torch.tensor): 维度是(batch_size, seq_len)，表示序列中的有效位置\n",
    "        \n",
    "        returns: torch.tensor,维度是(batch_size), 对于每一个句子的对数似然值\n",
    "        \"\"\"\n",
    "        \n",
    "        if not self.batch_first:\n",
    "            emissions = emissions.transpose(0,1)\n",
    "            tags = tags.transpose(0,1)\n",
    "            \n",
    "        if mask is None:\n",
    "            mask = torch.ones(emissions.shape[:2], dtype=torch.float)\n",
    "            # emissions.shape[:2]，返回的结果是(batch_size, seq_len)，所以mask的维度就是(batch_size, seq_len)\n",
    "            \n",
    "        scores = self._compute_scores(emissions, tags, mask=mask)\n",
    "        partition = self._compute_log_partition(emissions, mask=mask)\n",
    "        return torch.sum(scores - partition)\n",
    "    \n",
    "    \n",
    "    def _compute_scores(self, emissions, tags, mask):\n",
    "        \"\"\"\n",
    "        对于每个batch，用emissions和tags计算分值；\n",
    "        Args:\n",
    "            emissions(torch.tensor): (batch_size, seq_len, nb_labels)\n",
    "            tags(torch.tensor): (batch_size, seq_len)\n",
    "            mask(torch.tensor): (batch_size, seq_len)\n",
    "            \n",
    "        returns:\n",
    "            torch.tensor: 对于每个batch内的每个seq的分值， 维度是(batch_size)\n",
    "        \"\"\"\n",
    "        batch_size, seq_length = tags.shape\n",
    "        scores = torch.zeros(batch_size)\n",
    "        \n",
    "        # 保存每个seq的第一个tag和最后一个tag，留着进行从(bos -> first_tag)和(last_tag -> eos)的转换\n",
    "        first_tags = tags[:,0]\n",
    "        last_valid_idx = mask.int().sum(1)-1\n",
    "        last_tags = tags.gather(1, last_valid_idx.unsqueeze(1)).squeeze()\n",
    "        \n",
    "        #计算从bos到first_tags之间转换的分值\n",
    "        t_scores = self.transitions[self.BOS_TAG_ID, first_tags]\n",
    "        \n",
    "        #计算emission对于first_tags的分值，也就是去emission矩阵中取出下标为first_tags的值\n",
    "        e_scores = emissions[:,0].gather(1, first_tags.unsqueeze(1)).squeeze()\n",
    "        \n",
    "        # 对于一个词的分值是把t_scores和e_scores加起来\n",
    "        scores += e_scores + t_scores\n",
    "        \n",
    "        # 现在就是对于剩下的每一个词都做这个运算\n",
    "        for i in range(1, seq_length):\n",
    "            is_valid = mask[:i]\n",
    "            \n",
    "            previous_tags = tags[:, i-1]\n",
    "            current_tags = tags[:, i]\n",
    "            \n",
    "            # 计算t_score和e_score\n",
    "            e_scores = emissions[:,i].gather(1, current_tags.unsqueeze(1)).squeeze()\n",
    "            t_scores = self.transitions[previous_tags, current_tags]\n",
    "            \n",
    "            # 应用mask\n",
    "            e_scores = e_scores * is_valid\n",
    "            t_scores = t_scores * is_valid\n",
    "            \n",
    "            scores += e_scores + t_scores\n",
    "            \n",
    "        scores += self.transitions[last_tags, self.EOS_TAG_ID]\n",
    "        \n",
    "        return scores\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
