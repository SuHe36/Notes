{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): | ^C\n",
      "\\ "
     ]
    }
   ],
   "source": [
    "!conda install pytorch-lightning -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import transformers\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "  # Instantiate the model\n",
    "  def __init__(self, learning_rate, tokenizer, model, hparams):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.model = model\n",
    "    self.learning_rate = learning_rate\n",
    "    # self.freeze_encoder = freeze_encoder\n",
    "    # self.freeze_embeds_ = freeze_embeds\n",
    "    self.hparams = hparams\n",
    "\n",
    "    if self.hparams.freeze_encoder:\n",
    "      freeze_params(self.model.get_encoder())\n",
    "\n",
    "    if self.hparams.freeze_embeds:\n",
    "      self.freeze_embeds()\n",
    "  \n",
    "  def freeze_embeds(self):\n",
    "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
    "    freeze_params(self.model.model.shared)\n",
    "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
    "      freeze_params(d.embed_positions)\n",
    "      freeze_params(d.embed_tokens)\n",
    "\n",
    "  # Do a forward pass through the model\n",
    "  def forward(self, input_ids, **kwargs):\n",
    "    return self.model(input_ids, **kwargs)\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
    "    return optimizer\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    # Load the data into variables\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "\n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "    # Create the loss function\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    # Calculate the loss on the un-shifted tokens\n",
    "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss':loss}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "\n",
    "    src_ids, src_mask = batch[0], batch[1]\n",
    "    tgt_ids = batch[2]\n",
    "\n",
    "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
    "    \n",
    "    # Run the model and get the logits\n",
    "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
    "    lm_logits = outputs[0]\n",
    "\n",
    "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
    "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
    "\n",
    "    return {'loss': val_loss}\n",
    "  \n",
    "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
    "  def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40):\n",
    "    ''' Function to generate text '''\n",
    "    generated_ids = self.model.generate(\n",
    "        text[\"input_ids\"],\n",
    "        attention_mask=text[\"attention_mask\"],\n",
    "        use_cache=True,\n",
    "        decoder_start_token_id = self.tokenizer.pad_token_id,\n",
    "        num_beams= eval_beams,\n",
    "        max_length = max_len,\n",
    "        early_stopping = early_stopping\n",
    "    )\n",
    "    return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
    "\n",
    "def freeze_params(model):\n",
    "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
    "      adapted from finetune.py '''\n",
    "  for layer in model.parameters():\n",
    "    layer.requires_grade = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pytorch_lightning' has no attribute 'LightningDataModule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-42850bcd7da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a dataloading module as per the PyTorch Lightning Docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSummaryDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningDataModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pytorch_lightning' has no attribute 'LightningDataModule'"
     ]
    }
   ],
   "source": [
    "# Create a dataloading module as per the PyTorch Lightning Docs\n",
    "class SummaryDataModule(pl.LightningDataModule):\n",
    "  def __init__(self, tokenizer, data_file, batch_size, num_examples = 20000):\n",
    "    super().__init__()\n",
    "    self.tokenizer = tokenizer\n",
    "    self.data_file = data_file\n",
    "    self.batch_size = batch_size\n",
    "    self.num_examples = num_examples\n",
    "  \n",
    "  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n",
    "  def prepare_data(self):\n",
    "    self.data = pd.read_csv(self.data_file)[:self.num_examples]\n",
    "    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n",
    "\n",
    "  # encode the sentences using the tokenizer  \n",
    "  def setup(self, stage):\n",
    "    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'])\n",
    "    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'])\n",
    "    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'])\n",
    "\n",
    "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
    "  def train_dataloader(self):\n",
    "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n",
    "    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
    "    return train_data\n",
    "\n",
    "  def val_dataloader(self):\n",
    "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n",
    "    val_data = DataLoader(dataset, batch_size = self.batch_size)                       \n",
    "    return val_data\n",
    "\n",
    "  def test_dataloader(self):\n",
    "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n",
    "    test_data = DataLoader(dataset, batch_size = self.batch_size)                   \n",
    "    return test_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the hparams dictionary to pass in the model\n",
    "# I realise that this isn't really how this is meant to be used, but having this here reminds me that I can edit it when I need\n",
    "hparams = argparse.Namespace()\n",
    "\n",
    "hparams.freeze_encoder = True\n",
    "hparams.freeze_embeds = True\n",
    "hparams.eval_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens_right(input_ids, pad_token_id):\n",
    "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
    "      This is taken directly from modeling_bart.py\n",
    "  \"\"\"\n",
    "  prev_output_tokens = input_ids.clone()\n",
    "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
    "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
    "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
    "  return prev_output_tokens\n",
    "\n",
    "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\"):\n",
    "  ''' Function that tokenizes a sentence \n",
    "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
    "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
    "  '''\n",
    "\n",
    "  input_ids = []\n",
    "  attention_masks = []\n",
    "  target_ids = []\n",
    "  tokenized_sentences = {}\n",
    "\n",
    "  for sentence in source_sentences:\n",
    "    encoded_dict = tokenizer(\n",
    "          sentence,\n",
    "          max_length=max_length,\n",
    "          padding=\"max_length\" if pad_to_max_length else None,\n",
    "          truncation=True,\n",
    "          return_tensors=return_tensors,\n",
    "          add_prefix_space = True\n",
    "      )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "  input_ids = torch.cat(input_ids, dim = 0)\n",
    "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "\n",
    "  for sentence in target_sentences:\n",
    "    encoded_dict = tokenizer(\n",
    "          sentence,\n",
    "          max_length=max_length,\n",
    "          padding=\"max_length\" if pad_to_max_length else None,\n",
    "          truncation=True,\n",
    "          return_tensors=return_tensors,\n",
    "          add_prefix_space = True\n",
    "      )\n",
    "    # Shift the target ids to the right\n",
    "    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n",
    "    target_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "  target_ids = torch.cat(target_ids, dim = 0)\n",
    "  \n",
    "\n",
    "  batch = {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "      \"labels\": target_ids,\n",
    "  }\n",
    "\n",
    "  return batch\n",
    "\n",
    "\n",
    "def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n",
    "  '''\n",
    "  Function that noises a sentence by adding <mask> tokens\n",
    "  Args: sentence - the sentence to noise\n",
    "        percent_words - the percent of words to replace with <mask> tokens; the number is rounded up using math.ceil\n",
    "  Returns a noised sentence\n",
    "  '''\n",
    "  # Create a list item and copy\n",
    "  sentence_ = sentence_.split(' ')\n",
    "  sentence = sentence_.copy()\n",
    "  \n",
    "  num_words = math.ceil(len(sentence) * percent_words)\n",
    "  \n",
    "  # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n",
    "  # that word is often a rhyming word and plays an important role in song construction\n",
    "  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence)-1)))\n",
    "  \n",
    "  words_to_noise = random.sample(sample_tokens, num_words)\n",
    "  \n",
    "  # Swap out words, but not full stops\n",
    "  for pos in words_to_noise:\n",
    "      if sentence[pos] != '.':\n",
    "          sentence[pos] = replacement_token\n",
    "  \n",
    "  # Remove redundant spaces\n",
    "  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n",
    "  \n",
    "  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n",
    "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
    "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
    "  return sentence\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens_right(input_ids, pad_token_id):\n",
    "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
    "      This is taken directly from modeling_bart.py\n",
    "  \"\"\"\n",
    "  prev_output_tokens = input_ids.clone()\n",
    "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
    "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
    "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
    "  return prev_output_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([[1,2,3],[4,5,6]])\n",
    "pad_token_id = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = shift_tokens_right(input_ids, pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 1, 2],\n",
       "        [6, 4, 5]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor([[1,2,3],[4,5,6]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [4, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ids = y[:,:-1].contiguous()\n",
    "y_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_labels=y[:,1:].clone().detach()\n",
    "lm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_labels[y[:,1:] == 3] = -100 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2, -100],\n",
       "        [   5,    6]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained(\"/Users/hesu/Documents/AiQuestion/bart_trans/model/bart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.prepare_seq2seq_batch(\n",
    "    src_texts=['good morning.', ],\n",
    "    tgt_texts=['good bye.'],\n",
    "    max_length=100, return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   0, 8396,  662,    4,    2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]]), 'labels': tensor([[    0,  8396, 15687,     4,     2]])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = inputs[\"input_ids\"].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 8396,  662,    4,    2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"attention_mask\"].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = inputs[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.tensor([[1,2,3],[4,5,6]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
