{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch \n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.formal = self.data.formal\n",
    "        self.informal = self.data.informal\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.formal)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        informal = str(self.informal[index])\n",
    "        informal = ' '.join(informal.split())\n",
    "\n",
    "        formal = str(self.formal[index])\n",
    "        formal = ' '.join(formal.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([informal], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt',truncation=True)\n",
    "        target = self.tokenizer.batch_encode_plus([formal], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt', truncation=True)\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if _%10 == 0:\n",
    "            print({\"Training Loss\": loss.item()})\n",
    "\n",
    "        if _%500==0:\n",
    "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer)\n",
    "        # xm.mark_step()\n",
    "\n",
    "\n",
    "\n",
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length=150, \n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%100==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals\n",
    "\n",
    "\n",
    "def get_argments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--train_batch_size\",type=int, default=32)\n",
    "    parser.add_argument(\"--valid_batch_size\",type=int, default=32)\n",
    "    parser.add_argument(\"--train_epochs\",type=int, default=10)\n",
    "    parser.add_argument(\"--val_epochs\",type=int,default=4)\n",
    "    parser.add_argument(\"--learning_rate\",type=float,default=1e-4)\n",
    "    parser.add_argument('--seed',type=int,default=42)\n",
    "    parser.add_argument(\"--max_len\",type=int,default=128)\n",
    "    parser.add_argument(\"--generate_len\",type=int,default=128)\n",
    "    parser.add_argument(\"--pretrained_model\",type=str,default='../model/T5')\n",
    "    parser.add_argument(\"--tokenizer_dir\",type=str,default='../model/T5')\n",
    "    parser.add_argument(\"--train_data\",type=str,default='../data/informal_to_formal/em/train.csv')\n",
    "    parser.add_argument(\"--save_model\",type=str,default='../model/informal_to_formal_t5/epoch-')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "def main():\n",
    "\n",
    "    args = get_argments()\n",
    "\n",
    "\n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(args.seed) # pytorch random seed\n",
    "    np.random.seed(args.seed) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    # tokenzier for encoding the text\n",
    "    tokenizer = T5Tokenizer.from_pretrained(args.tokenizer_dir)\n",
    "    \n",
    "\n",
    "    df = pd.read_csv(args.train_data)\n",
    "    df = df[['formal','informal']]\n",
    "    df.informal = 'paraphrase: ' + df.informal + ' </s>'\n",
    "    df.formal = df.formal + ' </s>'\n",
    "    print(df.head())\n",
    "\n",
    "    train_dataset = df.reset_index(drop=True)\n",
    "\n",
    "    print(\"FULL Dataset: {}\".format(df.shape))\n",
    "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "#    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "\n",
    "    training_set = CustomDataset(train_dataset, tokenizer, args.max_len, args.generate_len)\n",
    "#    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        'batch_size': args.train_batch_size,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    val_params = {\n",
    "        'batch_size': args.valid_batch_size,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "#    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(args.pretrained_model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    # Training loop\n",
    "    print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "    for epoch in range(args.train_epochs):\n",
    "        train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "        \n",
    "        output_dir = args.save_model + str(epoch)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        model.save_pretrained(output_dir)\n",
    "\n",
    "    print(\"Training is over !\")\n",
    "#    torch.save(model, \"../model/test_t5\")\n",
    "\n",
    "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
    "    # Saving the dataframe as predictions.csv\n",
    "#    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "#    for epoch in range(config.VAL_EPOCHS):\n",
    "#        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n",
    "#        print(\"predictions:\",predictions)\n",
    "#        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "#        final_df.to_csv('../models/predictions.csv')\n",
    "#        print('Output Files generated for review')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch \n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers3 import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.formal = self.data.formal\n",
    "        self.informal = self.data.informal\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.formal)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        informal = str(self.informal[index])\n",
    "        informal = ' '.join(informal.split())\n",
    "\n",
    "        formal = str(self.formal[index])\n",
    "        formal = ' '.join(formal.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([informal], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt',truncation=True)\n",
    "        target = self.tokenizer.batch_encode_plus([formal], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt', truncation=True)\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def genrate(tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length=150, \n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals\n",
    "\n",
    "\n",
    "def get_argments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--gen_batch_size\",type=int, default=32)\n",
    "    parser.add_argument(\"--train_epochs\",type=int, default=10)\n",
    "    parser.add_argument(\"--val_epochs\",type=int,default=1)\n",
    "    parser.add_argument(\"--learning_rate\",type=float,default=1e-4)\n",
    "    parser.add_argument('--seed',type=int,default=42)\n",
    "    parser.add_argument(\"--max_len\",type=int,default=128)\n",
    "    parser.add_argument(\"--generate_len\",type=int,default=128)\n",
    "    parser.add_argument(\"--pretrained_model\",type=str,default='../model/T5')\n",
    "    parser.add_argument(\"--tokenizer_dir\",type=str,default='../model/T5')\n",
    "    parser.add_argument(\"--gen_data\",type=str,default='../data/informal_to_formal/em/train.csv')\n",
    "    parser.add_argument(\"--save_model\",type=str,default='../model/informal_to_formal_t5/epoch-')\n",
    "    parser.add_argument(\"--output_file\",type=str,default='')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "def main():\n",
    "\n",
    "    args = get_argments()\n",
    "\n",
    "\n",
    "\n",
    "    torch.manual_seed(args.seed) # pytorch random seed\n",
    "    np.random.seed(args.seed) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    tokenizer = T5Tokenizer.from_pretrained(args.tokenizer_dir)\n",
    "    \n",
    "\n",
    "    df = pd.read_csv(args.gen_data)\n",
    "    df = df[['formal','informal']]\n",
    "    df.informal = 'paraphrase: ' + df.informal\n",
    "    print(df.head())\n",
    "\n",
    "    gen_dataset = df.reset_index(drop=True)\n",
    "\n",
    "    print(\"FULL Dataset: {}\".format(df.shape))\n",
    "    print(\"TRAIN Dataset: {}\".format(gen_dataset.shape))\n",
    "\n",
    "\n",
    "    gen_set = CustomDataset(gen_dataset, tokenizer, args.max_len, args.generate_len)\n",
    "\n",
    "\n",
    "    gen_params = {\n",
    "        'batch_size': args.gen_batch_size,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    gen_loader = DataLoader(gen_set, **gen_params)\n",
    "\n",
    "\n",
    "    model = T5ForConditionalGeneration.from_pretrained(args.pretrained_model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    fw = open(args.output_file,\"w\")\n",
    "\n",
    "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "    predictions, actuals = genrate( tokenizer, model, device, gen_loader)\n",
    "    for i in range(len(predictions)):\n",
    "        fw.write(predictions[i] +\"\\n\")\n",
    "    print(\"predictions:\",predictions)\n",
    "#    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "#    final_df.to_csv('../t5/predictions.csv')\n",
    "    print('Output Files generated for review')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
