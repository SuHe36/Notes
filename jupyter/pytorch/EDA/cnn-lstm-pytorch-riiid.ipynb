{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here  I have tried with LSTM and CNN using pytorch\n",
    "\n",
    "TODO: Ensembling both model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data modeling used from this kernel\n",
    "https://www.kaggle.com/yaroslavmavliutov/riiid-prediction-cnn-keras-0-751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10bc2bd10>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10a2b8d90>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10a3bd0d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10a3bd190>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10a3bd790>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known')': /packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl\u001b[0m\n",
      "\u001b[31mERROR: Could not install packages due to an EnvironmentError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/bc/45/5118a05b0d61173e6eb12bc5804f0fbb6f196adb0a20e0b16efc2b8e98be/seaborn-0.11.0-py3-none-any.whl (Caused by NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x10bc41150>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lectures_csv = pd.read_csv(\"/Users/hesu/Documents/KT/riiid/lectures.csv\")\n",
    "example_test_csv = pd.read_csv(\"/Users/hesu/Documents/KT/riiid/example_test.csv\")\n",
    "train_csv = pd.read_csv(\"/Users/hesu/Documents/KT/riiid/train.csv\", low_memory=False, nrows=1000000)\n",
    "questions_csv = pd.read_csv(\"/Users/hesu/Documents/KT/riiid/questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture. So, let's keep just the questions\n",
    "train_csv = train_csv[train_csv.content_type_id == 0]\n",
    "# read -1 as null, for lectures\n",
    "train_csv = train_csv[train_csv.answered_correctly != -1]\n",
    "\n",
    "train_csv = train_csv.sort_values(['timestamp'], ascending=True).reset_index(drop = True)\n",
    "\n",
    "content_mean_final = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "content_mean_final.columns = [\"answered_correctly_content_mean\"]\n",
    "\n",
    "user_mean_final = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\n",
    "user_mean_final.columns = [\"answered_correctly_user_mean\", 'sum_correct', 'count']\n",
    "\n",
    "#saving value to fillna\n",
    "elapsed_time_mean_final = train_csv.prior_question_elapsed_time.mean()\n",
    "\n",
    "train_csv.drop(['timestamp', 'content_type_id'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "validation = pd.DataFrame()\n",
    "for i in range(4):\n",
    "    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n",
    "    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n",
    "    validation = validation.append(last_records)\n",
    "X = pd.DataFrame()\n",
    "for i in range(15):\n",
    "    last_records = train_csv.drop_duplicates('user_id', keep = 'last')\n",
    "    train_csv = train_csv[~train_csv.index.isin(last_records.index)]\n",
    "    X = X.append(last_records)\n",
    "\n",
    "\n",
    "results_c = train_csv[['content_id','answered_correctly']].groupby(['content_id']).agg(['mean'])\n",
    "results_c.columns = [\"answered_correctly_content_mean\"]\n",
    "\n",
    "results_u = train_csv[['user_id','answered_correctly']].groupby(['user_id']).agg(['mean', 'sum', 'count'])\n",
    "results_u.columns = [\"answered_correctly_user_mean\", 'sum_correct', 'count']\n",
    "\n",
    "result_time_mean = train_csv.prior_question_elapsed_time.mean()\n",
    "\n",
    "del(train_csv)\n",
    "\n",
    "X = pd.merge(X, results_u, on=['user_id'], how=\"left\")\n",
    "X = pd.merge(X, results_c, on=['content_id'], how=\"left\")\n",
    "\n",
    "validation = pd.merge(validation, results_u, on=['user_id'], how=\"left\")\n",
    "validation = pd.merge(validation, results_c, on=['content_id'], how=\"left\")\n",
    "\n",
    "y = X['answered_correctly']\n",
    "X = X.drop(['answered_correctly'], axis=1)\n",
    "\n",
    "y_val = validation['answered_correctly']\n",
    "X_val = validation.drop(['answered_correctly'], axis=1)\n",
    "\n",
    "lencoder = LabelEncoder()\n",
    "\n",
    "X['prior_question_had_explanation'].fillna(False, inplace = True)\n",
    "X['prior_question_had_explanation_enc'] = lencoder.fit_transform(X['prior_question_had_explanation'])\n",
    "X['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\n",
    "X['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\n",
    "X['sum_correct'].fillna(0, inplace = True)\n",
    "X['count'].fillna(0, inplace = True)\n",
    "X['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\n",
    "\n",
    "X_val['prior_question_had_explanation'].fillna(False, inplace = True)\n",
    "X_val['prior_question_had_explanation_enc'] = lencoder.fit_transform(X_val['prior_question_had_explanation'])\n",
    "X_val['answered_correctly_user_mean'].fillna(0.5,  inplace=True)\n",
    "X_val['answered_correctly_content_mean'].fillna(0.5,  inplace=True)\n",
    "X_val['sum_correct'].fillna(0, inplace = True)\n",
    "X_val['count'].fillna(0, inplace = True)\n",
    "X_val['prior_question_elapsed_time'].fillna(result_time_mean, inplace = True)\n",
    "\n",
    "X = X[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n",
    "       'prior_question_elapsed_time','prior_question_had_explanation_enc']]\n",
    "X_val = X_val[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n",
    "       'prior_question_elapsed_time','prior_question_had_explanation_enc']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "X_train = X.reshape(X.shape[0], 1,X.shape[1])\n",
    "X_test = X_val.reshape(X_val.shape[0], 1,X_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55271, 1, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIIDModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(RIIDModel,self).__init__()\n",
    "    self.cnn1 = nn.Conv1d(1,32,2)\n",
    "    self.cnn2 = nn.Conv1d(32,64,2)\n",
    "    self.fc1 = nn.Linear(256,32)\n",
    "    self.fc2 = nn.Linear(32,1)\n",
    "    self.drop = nn.Dropout(0.1)\n",
    "    self.relu = nn.ReLU()\n",
    "  \n",
    "  def forward(self,x):\n",
    "    out = self.relu(self.cnn1(x))\n",
    "    out = self.drop(self.relu(self.cnn2(out)))\n",
    "    out = out.view(out.shape[0],-1)\n",
    "    out = self.relu(self.fc1(out))\n",
    "    out = self.fc2(out)\n",
    "    return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIIDModelLSTM(nn.Module):\n",
    "  def __init__(self,device):\n",
    "    super(RIIDModelLSTM,self).__init__()\n",
    "    self.n_layers = 2\n",
    "    self.lstm = nn.LSTM(6,6,num_layers = self.n_layers,batch_first=True,dropout=0.3)\n",
    "    self.fc1 = nn.Linear(6,32)\n",
    "    self.fc2 = nn.Linear(32,1)\n",
    "    self.drop = nn.Dropout(0.1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.device = device\n",
    "  \n",
    "  def init_hidden(self, batch_size):\n",
    "    c0 = torch.zeros((self.n_layers, batch_size, 6)).to(self.device)\n",
    "    h0 = torch.zeros((self.n_layers, batch_size, 6)).to(self.device)\n",
    "    return h0,c0\n",
    "  \n",
    "  def forward(self,x):\n",
    "    batch_size = x.shape[0]\n",
    "    h0,c0 = self.init_hidden(batch_size)\n",
    "    out,_ = self.lstm(x,(h0,c0))\n",
    "    out = self.drop(self.relu(self.fc1(out)))\n",
    "    out = self.drop(self.relu(self.fc2(out)))\n",
    "    return out  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = RIIDModelLSTM(device)\n",
    "model.state_dict(torch.load(\"../input/lstm-model/model2.pt\",map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    test_df = pd.merge(test_df, user_mean_final, on=['user_id'],  how=\"left\")\n",
    "    test_df = pd.merge(test_df, content_mean_final, on=['content_id'],  how=\"left\")\n",
    "    \n",
    "    test_df['answered_correctly_user_mean'].fillna(0.6,  inplace=True)\n",
    "    test_df['answered_correctly_content_mean'].fillna(0.6,  inplace=True)\n",
    "    test_df['sum_correct'].fillna(0.1, inplace=True)\n",
    "    test_df['count'].fillna(0.1, inplace=True)\n",
    "    test_df['prior_question_elapsed_time'].fillna(elapsed_time_mean_final, inplace = True)\n",
    "    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "    test_df[\"prior_question_had_explanation_enc\"] = lencoder.transform(test_df[\"prior_question_had_explanation\"])\n",
    "\n",
    "    # fit transform cnn\n",
    "    X = scaler.transform(test_df[['answered_correctly_user_mean', 'answered_correctly_content_mean', 'sum_correct', 'count',\n",
    "                                  'prior_question_elapsed_time', 'prior_question_had_explanation_enc']])\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    X = torch.tensor(X,dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        out = model(X)\n",
    "        out = nn.Sigmoid()(out).view(-1)\n",
    "    test_df['answered_correctly'] = out.cpu().detach().numpy()\n",
    "    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
