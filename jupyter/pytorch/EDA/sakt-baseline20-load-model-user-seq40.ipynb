{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:35.036742Z",
     "iopub.status.busy": "2020-11-24T00:19:35.035942Z",
     "iopub.status.idle": "2020-11-24T00:19:37.616611Z",
     "shell.execute_reply": "2020-11-24T00:19:37.615947Z"
    },
    "papermill": {
     "duration": 2.614469,
     "end_time": "2020-11-24T00:19:37.616744",
     "exception": false,
     "start_time": "2020-11-24T00:19:35.002275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from itertools import repeat, chain, islice\n",
    "from torch.utils import data\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029585,
     "end_time": "2020-11-24T00:19:37.675917",
     "exception": false,
     "start_time": "2020-11-24T00:19:37.646332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ARGS参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:38.135718Z",
     "iopub.status.busy": "2020-11-24T00:19:38.134206Z",
     "iopub.status.idle": "2020-11-24T00:19:38.142201Z",
     "shell.execute_reply": "2020-11-24T00:19:38.144457Z"
    },
    "papermill": {
     "duration": 0.439406,
     "end_time": "2020-11-24T00:19:38.144847",
     "exception": false,
     "start_time": "2020-11-24T00:19:37.705441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    name = 'train'\n",
    "    model = 'SAKT'\n",
    "    num_layers = 1\n",
    "    hidden_dim=100\n",
    "    input_dim = 100\n",
    "    dropout = 0.2\n",
    "    num_head = 5\n",
    "    \n",
    "    random_seed = 1\n",
    "    num_epochs = 1\n",
    "    lr = 0.01\n",
    "    seq_size = 40\n",
    "    warm_up_step_count = 4000\n",
    "    eval_steps = 500\n",
    "    train_steps = 500\n",
    "    train_batch=128\n",
    "    num_workers=1\n",
    "    \n",
    "    \n",
    "ARGS = Args()\n",
    "ARGS.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:38.244852Z",
     "iopub.status.busy": "2020-11-24T00:19:38.243875Z",
     "iopub.status.idle": "2020-11-24T00:19:38.246170Z",
     "shell.execute_reply": "2020-11-24T00:19:38.247263Z"
    },
    "papermill": {
     "duration": 0.051064,
     "end_time": "2020-11-24T00:19:38.247504",
     "exception": false,
     "start_time": "2020-11-24T00:19:38.196440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "\n",
    "QUESTION_NUM = {\n",
    "    'riii':13523\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:38.350220Z",
     "iopub.status.busy": "2020-11-24T00:19:38.349261Z",
     "iopub.status.idle": "2020-11-24T00:19:38.352101Z",
     "shell.execute_reply": "2020-11-24T00:19:38.352948Z"
    },
    "papermill": {
     "duration": 0.055427,
     "end_time": "2020-11-24T00:19:38.353136",
     "exception": false,
     "start_time": "2020-11-24T00:19:38.297709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = '/Users/hesu/Documents/KT/riiid/train.csv'\n",
    "que_csv = '/Users/hesu/Documents/KT/riiid/questions.csv'\n",
    "train_pkl_path = '/Users/hesu/Documents/KT/riiid/user_seq/user_seq40_timestamp.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:38.473256Z",
     "iopub.status.busy": "2020-11-24T00:19:38.471788Z",
     "iopub.status.idle": "2020-11-24T00:19:39.280595Z",
     "shell.execute_reply": "2020-11-24T00:19:39.279243Z"
    },
    "papermill": {
     "duration": 0.874583,
     "end_time": "2020-11-24T00:19:39.280729",
     "exception": false,
     "start_time": "2020-11-24T00:19:38.406146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pkl = pd.read_pickle(train_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:39.359608Z",
     "iopub.status.busy": "2020-11-24T00:19:39.358581Z",
     "iopub.status.idle": "2020-11-24T00:19:39.368706Z",
     "shell.execute_reply": "2020-11-24T00:19:39.369232Z"
    },
    "papermill": {
     "duration": 0.058916,
     "end_time": "2020-11-24T00:19:39.369375",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.310459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id_seq</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>timestamp_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>5693,5717,129,7861,7923,157,52,51,7897,7864,13...</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,1,1,0,0,0,...</td>\n",
       "      <td>0,56943,118363,131167,137965,157063,176092,194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>7901,21400,176,14802,2066,15588,15587,16888,16...</td>\n",
       "      <td>1,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0</td>\n",
       "      <td>0,32683,62000,83632,189483,189483,189483,25879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2746</td>\n",
       "      <td>18797,14282,19500,237,13928,383,406,874,532,14...</td>\n",
       "      <td>0,0,0,1,0,1,1,1,1,0,1,1,0</td>\n",
       "      <td>0,21592,49069,72254,91945,111621,134341,234605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5382</td>\n",
       "      <td>997,902,262,447,380,829,452,6439,18863,5413,91...</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,1,0,1,0,...</td>\n",
       "      <td>389881333,389964165,390022375,390096159,390240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8623</td>\n",
       "      <td>13585,19,10596,21488,7914,195,23929,7975,131,7...</td>\n",
       "      <td>0,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,0,0,0,0,1,0,1,...</td>\n",
       "      <td>405393099,405438225,405472251,405560264,405607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8701</td>\n",
       "      <td>3902,6672,4964,19667,8280,17488,17526,14278,11...</td>\n",
       "      <td>1,1,1,0,1,0,0,0,1,0,0</td>\n",
       "      <td>0,17833,45872,74561,121601,141679,183773,11482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12741</td>\n",
       "      <td>24224,10699,10700,16152,2627,2628,24250,10726,...</td>\n",
       "      <td>0,1,1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,0,1,1,1,1,1,...</td>\n",
       "      <td>4461666848,4461666848,4461666848,4461969611,44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13134</td>\n",
       "      <td>3116,3350,3349,3351,13063,13064,13062,3178,167...</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,...</td>\n",
       "      <td>17787213345,17787349676,17787349676,1778734967...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24418</td>\n",
       "      <td>5045,8247,5736,17300,3777,6136,5620,4128,9128,...</td>\n",
       "      <td>1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,...</td>\n",
       "      <td>13719934601,13719969208,13719994486,1372003782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24600</td>\n",
       "      <td>15587,2066,15588,16888,16887,16889,16471,16472...</td>\n",
       "      <td>0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,...</td>\n",
       "      <td>148601,148601,148601,219354,219354,219354,2697...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     content_id_seq  \\\n",
       "0      115  5693,5717,129,7861,7923,157,52,51,7897,7864,13...   \n",
       "1      124  7901,21400,176,14802,2066,15588,15587,16888,16...   \n",
       "2     2746  18797,14282,19500,237,13928,383,406,874,532,14...   \n",
       "3     5382  997,902,262,447,380,829,452,6439,18863,5413,91...   \n",
       "4     8623  13585,19,10596,21488,7914,195,23929,7975,131,7...   \n",
       "5     8701  3902,6672,4964,19667,8280,17488,17526,14278,11...   \n",
       "6    12741  24224,10699,10700,16152,2627,2628,24250,10726,...   \n",
       "7    13134  3116,3350,3349,3351,13063,13064,13062,3178,167...   \n",
       "8    24418  5045,8247,5736,17300,3777,6136,5620,4128,9128,...   \n",
       "9    24600  15587,2066,15588,16888,16887,16889,16471,16472...   \n",
       "\n",
       "                                  answered_correctly  \\\n",
       "0  1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,1,1,0,0,0,...   \n",
       "1    1,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0   \n",
       "2                          0,0,0,1,0,1,1,1,1,0,1,1,0   \n",
       "3  1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,1,0,1,0,...   \n",
       "4  0,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,0,0,0,0,1,0,1,...   \n",
       "5                              1,1,1,0,1,0,0,0,1,0,0   \n",
       "6  0,1,1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,0,1,1,1,1,1,...   \n",
       "7  1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,...   \n",
       "8  1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,...   \n",
       "9  0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,...   \n",
       "\n",
       "                                       timestamp_seq  \n",
       "0  0,56943,118363,131167,137965,157063,176092,194...  \n",
       "1  0,32683,62000,83632,189483,189483,189483,25879...  \n",
       "2  0,21592,49069,72254,91945,111621,134341,234605...  \n",
       "3  389881333,389964165,390022375,390096159,390240...  \n",
       "4  405393099,405438225,405472251,405560264,405607...  \n",
       "5  0,17833,45872,74561,121601,141679,183773,11482...  \n",
       "6  4461666848,4461666848,4461666848,4461969611,44...  \n",
       "7  17787213345,17787349676,17787349676,1778734967...  \n",
       "8  13719934601,13719969208,13719994486,1372003782...  \n",
       "9  148601,148601,148601,219354,219354,219354,2697...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pkl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03001,
     "end_time": "2020-11-24T00:19:39.430290",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.400280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:39.497022Z",
     "iopub.status.busy": "2020-11-24T00:19:39.495002Z",
     "iopub.status.idle": "2020-11-24T00:19:39.497869Z",
     "shell.execute_reply": "2020-11-24T00:19:39.498419Z"
    },
    "papermill": {
     "duration": 0.03765,
     "end_time": "2020-11-24T00:19:39.498564",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.460914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_data = UserSepDataSet_Rii_Test(valid, user_dict2, is_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030971,
     "end_time": "2020-11-24T00:19:39.559852",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.528881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SAKT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.032511,
     "end_time": "2020-11-24T00:19:39.624510",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.591999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:39.696093Z",
     "iopub.status.busy": "2020-11-24T00:19:39.695274Z",
     "iopub.status.idle": "2020-11-24T00:19:39.699778Z",
     "shell.execute_reply": "2020-11-24T00:19:39.699148Z"
    },
    "papermill": {
     "duration": 0.043877,
     "end_time": "2020-11-24T00:19:39.699899",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.656022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:39.769086Z",
     "iopub.status.busy": "2020-11-24T00:19:39.768210Z",
     "iopub.status.idle": "2020-11-24T00:19:39.772584Z",
     "shell.execute_reply": "2020-11-24T00:19:39.772049Z"
    },
    "papermill": {
     "duration": 0.04242,
     "end_time": "2020-11-24T00:19:39.772677",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.730257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:39.864082Z",
     "iopub.status.busy": "2020-11-24T00:19:39.853566Z",
     "iopub.status.idle": "2020-11-24T00:19:39.880583Z",
     "shell.execute_reply": "2020-11-24T00:19:39.880043Z"
    },
    "papermill": {
     "duration": 0.076765,
     "end_time": "2020-11-24T00:19:39.880703",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.803938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model, bias=False), 4) # Q, K, V, last\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "class SAKTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Encoder block of SAKT\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._self_attn = MultiHeadedAttention(num_head, hidden_dim, dropout)\n",
    "        self._ffn = PositionwiseFeedForward(hidden_dim, hidden_dim, dropout)\n",
    "        self._layernorms = clones(nn.LayerNorm(hidden_dim, eps=1e-6), 2)\n",
    "\n",
    "    def forward(self, query, key, mask=None):\n",
    "        \"\"\"\n",
    "        query: question embeddings\n",
    "        key: interaction embeddings\n",
    "        \"\"\"\n",
    "        # self-attention block\n",
    "        output = self._self_attn(query=query, key=key, value=key, mask=mask)\n",
    "        output = self._layernorms[0](key + output)\n",
    "        # feed-forward block\n",
    "        output = self._layernorms[1](output + self._ffn(output))\n",
    "        return output\n",
    "\n",
    "\n",
    "class SAKT(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based\n",
    "    all hidden dimensions (d_k, d_v, ...) are the same as hidden_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, question_num, num_layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._question_num = question_num\n",
    "        # question_num的值是110\n",
    "        # Blocks\n",
    "        self._layers = clones(SAKTLayer(hidden_dim, num_head, dropout), num_layers)\n",
    "\n",
    "        # prediction layer\n",
    "        self._prediction = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Embedding layers\n",
    "        self._positional_embedding = nn.Embedding(ARGS.seq_size+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        self._interaction_embedding = nn.Embedding(2*question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        # 这个就是包含了qid对错信息的矩阵\n",
    "        self._question_embedding = nn.Embedding(question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "\n",
    "    def _transform_interaction_to_question_id(self, interaction):\n",
    "        \"\"\"\n",
    "        get question_id from interaction index\n",
    "        if interaction index is a number in [0, question_num], then leave it as-is\n",
    "        if interaction index is bigger than question_num (in [question_num + 1, 2 * question_num]\n",
    "        then subtract question_num\n",
    "        interaction: integer tensor of shape (batch_size, sequence_size)\n",
    "        \"\"\"\n",
    "        return interaction - self._question_num * (interaction > self._question_num).long()\n",
    "\n",
    "    def _get_position_index(self, question_id):\n",
    "        \"\"\"\n",
    "        [0, 0, 0, 4, 12] -> [0, 0, 0, 1, 2]\n",
    "        \"\"\"\n",
    "        batch_size = question_id.shape[0]\n",
    "        position_indices = []\n",
    "        for i in range(batch_size):\n",
    "            non_padding_num = (question_id[i] != PAD_INDEX).sum(-1).item()\n",
    "            position_index = [0] * (ARGS.seq_size - non_padding_num) + list(range(1, non_padding_num+1))\n",
    "            position_indices.append(position_index)\n",
    "        return torch.tensor(position_indices, dtype=int).to(ARGS.device)\n",
    "\n",
    "    def forward(self, interaction_id, target_id):\n",
    "        \"\"\"\n",
    "        Query: Question (skill, exercise, ...) embedding\n",
    "        Key, Value: Interaction embedding + positional embedding\n",
    "        \"\"\"\n",
    "        question_id = self._transform_interaction_to_question_id(interaction_id)\n",
    "        # 这个question_id就是把以前把统一qid由于对错不同对应不同id，转换成同一qid\n",
    "        # 也就是把qid数值大于q_num的，减去q_num\n",
    "        question_id = torch.cat([question_id[:, 1:], target_id], dim=-1)\n",
    "        # question_id的原来的维度是(batch, seq_len)，\n",
    "        # 然后那两个:，第一个表示在第一个维度全选\n",
    "        # 第二个1:，表示第二个维度从第一个元素选起，这主要是为了和target_id合并在一起\n",
    "\n",
    "        # 这时question_id和interaction_id存在着一个错位的问题，\n",
    "        # 也就是question_id包含了当前target_id,而interaction_id中不包含\n",
    "\n",
    "        interaction_vector = self._interaction_embedding(interaction_id)\n",
    "        question_vector = self._question_embedding(question_id)\n",
    "\n",
    "        position_index = self._get_position_index(question_id)\n",
    "        # 对于question_id获取position的下标\n",
    "        position_vector = self._positional_embedding(position_index)\n",
    "\n",
    "        mask = get_pad_mask(question_id, PAD_INDEX) & get_subsequent_mask(question_id)\n",
    "        x = interaction_vector + position_vector\n",
    "        # 这个position_vector只加给了interaction_vector向量\n",
    "        # x的维度是(batch, seq_len, hidden)\n",
    "        for layer in self._layers:\n",
    "            x = layer(query=question_vector, key=x, mask=mask)\n",
    "\n",
    "        output = self._prediction(x)\n",
    "        # 这里的output为什么会是一个三维的向量呢\n",
    "        output = output[:, -1, :]\n",
    "        # output的最初维度是(batch, seq_len, 1)\n",
    "        # 然后用[:,-1,:]只取seq_len的最后一个值\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:39.947135Z",
     "iopub.status.busy": "2020-11-24T00:19:39.946392Z",
     "iopub.status.idle": "2020-11-24T00:19:39.955643Z",
     "shell.execute_reply": "2020-11-24T00:19:39.955050Z"
    },
    "papermill": {
     "duration": 0.044653,
     "end_time": "2020-11-24T00:19:39.955748",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.911095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed_all(ARGS.random_seed)\n",
    "random.seed(ARGS.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.024710Z",
     "iopub.status.busy": "2020-11-24T00:19:40.022704Z",
     "iopub.status.idle": "2020-11-24T00:19:40.025421Z",
     "shell.execute_reply": "2020-11-24T00:19:40.025967Z"
    },
    "papermill": {
     "duration": 0.038804,
     "end_time": "2020-11-24T00:19:40.026086",
     "exception": false,
     "start_time": "2020-11-24T00:19:39.987282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  model = SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "#                      ARGS.num_head, ARGS.dropout).to(ARGS.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.030515,
     "end_time": "2020-11-24T00:19:40.087135",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.056620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031859,
     "end_time": "2020-11-24T00:19:40.150208",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.118349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.03301,
     "end_time": "2020-11-24T00:19:40.216326",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.183316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.032932,
     "end_time": "2020-11-24T00:19:40.282687",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.249755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.368094Z",
     "iopub.status.busy": "2020-11-24T00:19:40.366691Z",
     "iopub.status.idle": "2020-11-24T00:19:40.370092Z",
     "shell.execute_reply": "2020-11-24T00:19:40.369585Z"
    },
    "papermill": {
     "duration": 0.05555,
     "end_time": "2020-11-24T00:19:40.370199",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.314649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps\n",
    "        ])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "               (self.model_size ** (-0.5) *\n",
    "                min(step ** (-0.5), step * self.warmup ** (-1.5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.471830Z",
     "iopub.status.busy": "2020-11-24T00:19:40.450987Z",
     "iopub.status.idle": "2020-11-24T00:19:40.483498Z",
     "shell.execute_reply": "2020-11-24T00:19:40.482963Z"
    },
    "papermill": {
     "duration": 0.081845,
     "end_time": "2020-11-24T00:19:40.483612",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.401767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoamOptimizer:\n",
    "    def __init__(self, model, lr, model_size, warmup):\n",
    "        self._adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self._opt = NoamOpt(\n",
    "            model_size=model_size, factor=1, warmup=warmup, optimizer=self._adam)\n",
    "\n",
    "    def step(self, loss):\n",
    "        self._opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self._opt.step()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, warm_up_step_count,\n",
    "                 d_model, num_epochs, weight_path, lr,\n",
    "                 train_data, val_data, test_data=None):\n",
    "        self._device = device\n",
    "        self._num_epochs = num_epochs\n",
    "        self._weight_path = weight_path\n",
    "\n",
    "        self._model = model\n",
    "        self._loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self._model.to(device)\n",
    "\n",
    "        self._train_data = train_data\n",
    "        self._val_data = val_data\n",
    "        self._test_data = test_data\n",
    "\n",
    "        self._opt = NoamOptimizer(model=model, lr=lr, model_size=d_model, warmup=warm_up_step_count)\n",
    "\n",
    "        self.step = 0\n",
    "        self._threshold = 0.5\n",
    "        self.max_step = 0\n",
    "        self.max_acc = 0.0\n",
    "        self.max_auc = 0.0\n",
    "\n",
    "        self.test_acc = 0.0\n",
    "        self.test_auc = 0.0\n",
    "\n",
    "    # train model and choose weight with max auc on validation dataset\n",
    "    def train(self):\n",
    "        train_gen = self._train_data\n",
    "        val_gen = self._val_data\n",
    "\n",
    "        # will train self._num_epochs copies of train data\n",
    "        to_train = chain.from_iterable(repeat(train_gen, self._num_epochs))\n",
    "        # consisting of total_steps batches\n",
    "        total_steps = len(train_gen) * self._num_epochs\n",
    "        print(\"total_steps:\",total_steps)\n",
    "\n",
    "        self.step = 0\n",
    "        while self.step < total_steps:\n",
    "            rem_steps = total_steps - self.step\n",
    "            num_steps = min(rem_steps, ARGS.train_steps)\n",
    "            self.step += num_steps\n",
    "\n",
    "            # take num_steps batches from to_train stream\n",
    "            train_batches = islice(to_train, num_steps)\n",
    "            # print(f'Step: {self.step}')\n",
    "#            print(f\"Current Training step is: {self.step}\")\n",
    "            self._train(train_batches, num_steps)\n",
    "            if self.step % ARGS.eval_steps == 0:\n",
    "                cur_weight = self._model.state_dict()\n",
    "#                 torch.save(cur_weight, f'{self._weight_path}{self.step}.pt')\n",
    "                self._test('Validation', val_gen)\n",
    "            # print(f'Current best weight: {self.max_step}.pt, best auc: {self.max_auc:.4f}')\n",
    "            # remove all weight file except {self.max_step}.pt\n",
    "                print(f\"Validation-- Best validaction acc is: {self.max_acc:.4f},\"\n",
    "                  f\"Best auc is:{self.max_auc:.4f}.\\n\")\n",
    "#             weight_list = os.listdir(self._weight_path)\n",
    "            # for w in weight_list:\n",
    "            #     if int(w[:-3]) != self.max_step:\n",
    "            #         os.unlink(f'{self._weight_path}{w}')\n",
    "        self._test('Validation', val_gen)\n",
    "    # get test results\n",
    "    def test(self, weight_num):\n",
    "        test_gen = data.DataLoader(\n",
    "            dataset=self._test_data, shuffle=False,\n",
    "            batch_size=ARGS.test_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "        # load best weight\n",
    "        if self.max_step != 0:\n",
    "            weight_num = self.max_step\n",
    "        weight_path = f'{ARGS.weight_path}{weight_num}.pt'\n",
    "        print(f'best weight: {weight_path}')\n",
    "        self._model.load_state_dict(torch.load(weight_path))\n",
    "        self._test('Test', test_gen)\n",
    "\n",
    "    def _forward(self, batch):\n",
    "#        batch = {k: t.to(self._device) for k, t in batch.items()}\n",
    "#        label = batch['label']  # shape: (batch_size, 1)\n",
    "\n",
    "#        output = self._model(batch['input'], batch['target_id'])\n",
    "\n",
    "        batch = tuple(t.to(self._device) for t in batch)\n",
    "        question_id, target_id, label = batch\n",
    "\n",
    "        output = self._model(question_id, target_id)\n",
    "        pred = (torch.sigmoid(output) >= self._threshold).long()  # shape: (batch_size, 1)\n",
    "        # 感觉这里的sigmoid加在output之前是不是会更好\n",
    "\n",
    "        return label, output, pred\n",
    "\n",
    "    def _get_loss(self, label, output):\n",
    "        # 这里的label我可以理解为是一个[0,1]序列，但是output却是上面_forward的output，不是一个（0，1）范围的值\n",
    "        # 是因为loss_fn里面有sigmoid\n",
    "        loss = self._loss_fn(output, label.float())\n",
    "        return loss.mean()\n",
    "\n",
    "    # takes iterator\n",
    "    def _train(self, batch_iter, num_batches):\n",
    "        start_time = time.time()\n",
    "        self._model.train()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        for batch in tqdm(batch_iter, total=num_batches):\n",
    "            label, out, pred = self._forward(batch)\n",
    "            train_loss = self._get_loss(label, out)\n",
    "            losses.append(train_loss.item())\n",
    "\n",
    "            self._opt.step(train_loss)\n",
    "\n",
    "            num_corrects += (pred == label).sum().item()\n",
    "            num_total += len(label)\n",
    "\n",
    "            labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "            outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / num_total\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        if self.step % ARGS.train_steps:\n",
    "            print(f\"Current Training step is: {self.step}\")\n",
    "            print(f'Training correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "            print(f'[Training]     time: {training_time:.2f}, loss: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "    # takes iterable\n",
    "    def _test(self, name, batches):\n",
    "        start_time = time.time()\n",
    "        self._model.eval()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(batches):\n",
    "                label, out, pred = self._forward(batch)\n",
    "                test_loss = self._get_loss(label, out)\n",
    "                losses.append(test_loss.item())\n",
    "\n",
    "                num_corrects += (pred == label).sum().item()\n",
    "                num_total += len(label)\n",
    "\n",
    "                labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "                outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / num_total\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        # training_time = time.time() - start_time\n",
    "\n",
    "        print(f'correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "        print(f' loss is: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "        if name == 'Validation':\n",
    "            if self.max_auc < auc:\n",
    "                self.max_auc = auc\n",
    "                self.max_acc = acc\n",
    "                self.max_step = self.step\n",
    "                torch.save(self._model.state_dict(), self._weight_path)\n",
    "\n",
    "        elif name == 'Test':\n",
    "            self.test_acc = acc\n",
    "            self.test_auc = auc\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.552942Z",
     "iopub.status.busy": "2020-11-24T00:19:40.551054Z",
     "iopub.status.idle": "2020-11-24T00:19:40.553985Z",
     "shell.execute_reply": "2020-11-24T00:19:40.554636Z"
    },
    "papermill": {
     "duration": 0.03963,
     "end_time": "2020-11-24T00:19:40.554785",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.515155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataloader = data.DataLoader(\n",
    "#             dataset=train_data, shuffle=True,\n",
    "#             batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "# valid_dataloader = data.DataLoader(\n",
    "#             dataset=val_data, shuffle=False,\n",
    "#             batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.623056Z",
     "iopub.status.busy": "2020-11-24T00:19:40.622291Z",
     "iopub.status.idle": "2020-11-24T00:19:40.626482Z",
     "shell.execute_reply": "2020-11-24T00:19:40.625966Z"
    },
    "papermill": {
     "duration": 0.039627,
     "end_time": "2020-11-24T00:19:40.626590",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.586963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.694985Z",
     "iopub.status.busy": "2020-11-24T00:19:40.693997Z",
     "iopub.status.idle": "2020-11-24T00:19:40.697081Z",
     "shell.execute_reply": "2020-11-24T00:19:40.696462Z"
    },
    "papermill": {
     "duration": 0.039322,
     "end_time": "2020-11-24T00:19:40.697191",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.657869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# del(train_data)\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.763395Z",
     "iopub.status.busy": "2020-11-24T00:19:40.762503Z",
     "iopub.status.idle": "2020-11-24T00:19:40.765597Z",
     "shell.execute_reply": "2020-11-24T00:19:40.764990Z"
    },
    "papermill": {
     "duration": 0.03742,
     "end_time": "2020-11-24T00:19:40.765689",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.728269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(model,ARGS.device, ARGS.warm_up_step_count,\n",
    "#                  ARGS.hidden_dim, ARGS.num_epochs, 'rid_model.pt',\n",
    "#                  ARGS.lr, train_dataloader, valid_dataloader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.834371Z",
     "iopub.status.busy": "2020-11-24T00:19:40.833464Z",
     "iopub.status.idle": "2020-11-24T00:19:40.836774Z",
     "shell.execute_reply": "2020-11-24T00:19:40.836028Z"
    },
    "papermill": {
     "duration": 0.039017,
     "end_time": "2020-11-24T00:19:40.836892",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.797875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:40.906365Z",
     "iopub.status.busy": "2020-11-24T00:19:40.905492Z",
     "iopub.status.idle": "2020-11-24T00:19:40.908434Z",
     "shell.execute_reply": "2020-11-24T00:19:40.907924Z"
    },
    "papermill": {
     "duration": 0.039412,
     "end_time": "2020-11-24T00:19:40.908558",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.869146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del(train_dataloader)\n",
    "# del(valid_dataloader)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031614,
     "end_time": "2020-11-24T00:19:40.971875",
     "exception": false,
     "start_time": "2020-11-24T00:19:40.940261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:41.040193Z",
     "iopub.status.busy": "2020-11-24T00:19:41.039317Z",
     "iopub.status.idle": "2020-11-24T00:19:41.043447Z",
     "shell.execute_reply": "2020-11-24T00:19:41.042834Z"
    },
    "papermill": {
     "duration": 0.039413,
     "end_time": "2020-11-24T00:19:41.043553",
     "exception": false,
     "start_time": "2020-11-24T00:19:41.004140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:41.115923Z",
     "iopub.status.busy": "2020-11-24T00:19:41.115246Z",
     "iopub.status.idle": "2020-11-24T00:19:46.327412Z",
     "shell.execute_reply": "2020-11-24T00:19:46.328192Z"
    },
    "papermill": {
     "duration": 5.252134,
     "end_time": "2020-11-24T00:19:46.328337",
     "exception": false,
     "start_time": "2020-11-24T00:19:41.076203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKT(\n",
       "  (_layers): ModuleList(\n",
       "    (0): SAKTLayer(\n",
       "      (_self_attn): MultiHeadedAttention(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (2): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (3): Linear(in_features=100, out_features=100, bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_ffn): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (w_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_layernorms): ModuleList(\n",
       "        (0): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_prediction): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (_positional_embedding): Embedding(41, 100, padding_idx=0)\n",
       "  (_interaction_embedding): Embedding(27047, 100, padding_idx=0)\n",
       "  (_question_embedding): Embedding(13524, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)\n",
    "model.load_state_dict(torch.load('/Users/hesu/Documents/KT/riiid/model/user_seq40_model.pt',map_location=ARGS.device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:46.474428Z",
     "iopub.status.busy": "2020-11-24T00:19:46.473445Z",
     "iopub.status.idle": "2020-11-24T00:19:46.475914Z",
     "shell.execute_reply": "2020-11-24T00:19:46.476453Z"
    },
    "papermill": {
     "duration": 0.042182,
     "end_time": "2020-11-24T00:19:46.476597",
     "exception": false,
     "start_time": "2020-11-24T00:19:46.434415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Rii_dataset(Dataset):\n",
    "    def __init__(self,df ):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        content_id_seq = torch.from_numpy(self.df.at[index,'content_id_seq_input'])\n",
    "        content_id_seq = content_id_seq.long()\n",
    "        return content_id_seq, torch.LongTensor([self.df.at[index,'content_id']])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:46.555244Z",
     "iopub.status.busy": "2020-11-24T00:19:46.554344Z",
     "iopub.status.idle": "2020-11-24T00:19:46.557481Z",
     "shell.execute_reply": "2020-11-24T00:19:46.556926Z"
    },
    "papermill": {
     "duration": 0.048238,
     "end_time": "2020-11-24T00:19:46.557605",
     "exception": false,
     "start_time": "2020-11-24T00:19:46.509367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_np(nums, ind):\n",
    "\n",
    "    nums = nums[:ind]\n",
    "    if nums.size == 0:\n",
    "        return np.array([0]*Args.seq_size)\n",
    "\n",
    "    if nums.size > Args.seq_size:\n",
    "        nums = nums[-Args.seq_size:]\n",
    "    else:\n",
    "        pad_counts = Args.seq_size - len(nums)\n",
    "        nums = np.pad(nums,(pad_counts,0),'constant',constant_values=(0,0))\n",
    "    return nums\n",
    "\n",
    "\n",
    "\n",
    "def get_index(row):\n",
    "    ind = np.searchsorted(row['timestamp_seq'],row['timestamp'])\n",
    "    return ind\n",
    "\n",
    "def pad_seq(df):\n",
    "    df['content_id'] = np.array(df['content_id'])\n",
    "\n",
    "    df['timestamp_seq'] = df['timestamp_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int64))\n",
    "    df['ind'] = df.apply(lambda x: get_index(x), axis=1)\n",
    "    \n",
    "    df['content_id_seq'] = df['content_id_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['content_id_seq_input'] = df.apply(lambda x: pad_np(x.content_id_seq, x.ind), axis=1)\n",
    "    \n",
    "    df['answered_correctly'] = df['answered_correctly'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['answered_correctly_input'] = df.apply(lambda x: pad_np(x.answered_correctly,x.ind), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def pad_seq2(df):\n",
    "    df['content_id'] = np.array(df['content_id'])\n",
    "    print(type(df['timestamp_seq'] ))\n",
    "#     df['timestamp_seq'] = df['timestamp_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int64))\n",
    "    df['index'] = df.apply(lambda x: get_index(x), axis=1)\n",
    "    \n",
    "    df['content_id_seq'] = df['content_id_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['content_id_seq_input'] = df.apply(lambda x: pad_np(x.content_id_seq, x.index), axis=1)\n",
    "\n",
    "    df['answered_correctly'] = df['answered_correctly'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['answered_correctly_input'] = df.apply(lambda x: pad_np(x['answered_correctly',x['index']]))\n",
    "#     df['answered_correctly'] = df['answered_correctly'].apply(lambda x: pad_np(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (19651, 5)\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "test_df = pd.read_csv('/Users/hesu/Documents/KT/riiid/valid.csv')\n",
    "test_df['content_id'] = test_df['content_id'] + 1\n",
    "\n",
    "\n",
    "test_df = test_df.loc[:,['content_id','content_type_id',\n",
    "                             'row_id','user_id','timestamp']]\n",
    "\n",
    "test_df = test_df.loc[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "print(\"test_df:\", test_df.shape)\n",
    "\n",
    "test_df = pd.merge(test_df, train_pkl, on='user_id',how='left').fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>content_id_seq</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>timestamp_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1220</td>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>91216</td>\n",
       "      <td>2868613211</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1173</td>\n",
       "      <td>0</td>\n",
       "      <td>10001</td>\n",
       "      <td>91216</td>\n",
       "      <td>2868700426</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>10002</td>\n",
       "      <td>91216</td>\n",
       "      <td>2868748313</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6470</td>\n",
       "      <td>0</td>\n",
       "      <td>10003</td>\n",
       "      <td>91216</td>\n",
       "      <td>2874335350</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5251</td>\n",
       "      <td>0</td>\n",
       "      <td>10004</td>\n",
       "      <td>91216</td>\n",
       "      <td>2912644354</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>10005</td>\n",
       "      <td>91216</td>\n",
       "      <td>2912756715</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5157</td>\n",
       "      <td>0</td>\n",
       "      <td>10006</td>\n",
       "      <td>91216</td>\n",
       "      <td>2912855281</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3642</td>\n",
       "      <td>0</td>\n",
       "      <td>10007</td>\n",
       "      <td>91216</td>\n",
       "      <td>2912982177</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4410</td>\n",
       "      <td>0</td>\n",
       "      <td>10008</td>\n",
       "      <td>91216</td>\n",
       "      <td>2913096884</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4293</td>\n",
       "      <td>0</td>\n",
       "      <td>10010</td>\n",
       "      <td>91216</td>\n",
       "      <td>2913266013</td>\n",
       "      <td>3896,6250,4216,8717,3921,3666,5216,22946,18773...</td>\n",
       "      <td>1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...</td>\n",
       "      <td>18773577303,18773645331,18773719658,1877384799...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  content_type_id  row_id  user_id   timestamp  \\\n",
       "0        1220                0   10000    91216  2868613211   \n",
       "1        1173                0   10001    91216  2868700426   \n",
       "2         231                0   10002    91216  2868748313   \n",
       "3        6470                0   10003    91216  2874335350   \n",
       "4        5251                0   10004    91216  2912644354   \n",
       "5        8192                0   10005    91216  2912756715   \n",
       "6        5157                0   10006    91216  2912855281   \n",
       "7        3642                0   10007    91216  2912982177   \n",
       "8        4410                0   10008    91216  2913096884   \n",
       "9        4293                0   10010    91216  2913266013   \n",
       "\n",
       "                                      content_id_seq  \\\n",
       "0  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "1  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "2  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "3  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "4  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "5  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "6  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "7  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "8  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "9  3896,6250,4216,8717,3921,3666,5216,22946,18773...   \n",
       "\n",
       "                                  answered_correctly  \\\n",
       "0  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "1  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "2  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "3  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "4  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "5  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "6  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "7  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "8  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "9  1,1,1,1,1,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,0,...   \n",
       "\n",
       "                                       timestamp_seq  \n",
       "0  18773577303,18773645331,18773719658,1877384799...  \n",
       "1  18773577303,18773645331,18773719658,1877384799...  \n",
       "2  18773577303,18773645331,18773719658,1877384799...  \n",
       "3  18773577303,18773645331,18773719658,1877384799...  \n",
       "4  18773577303,18773645331,18773719658,1877384799...  \n",
       "5  18773577303,18773645331,18773719658,1877384799...  \n",
       "6  18773577303,18773645331,18773719658,1877384799...  \n",
       "7  18773577303,18773645331,18773719658,1877384799...  \n",
       "8  18773577303,18773645331,18773719658,1877384799...  \n",
       "9  18773577303,18773645331,18773719658,1877384799...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pad_seq(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 154/154 [00:02<00:00, 57.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: [[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Test running time: 0:00:07.689436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "test_dataset = Rii_dataset(test_df)\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "            dataset=test_dataset, shuffle=False,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "        question_id, target_id = batch\n",
    "        output = model(question_id, target_id)\n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        preds.append(pred)\n",
    "\n",
    "preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "print(\"preds:\",preds)\n",
    "test_df['answered_correctly'] =  preds\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "print(\"Test running time:\", end-start)\n",
    "\n",
    "\n",
    "# for row in test_df.itertuples():\n",
    "#     user_id = getattr(row, \"user_id\")\n",
    "#     content_id = getattr(row, \"content_id\")\n",
    "#     content_id_seq = getattr(row, \"content_id_seq\")\n",
    "    \n",
    "#     print(len(content_id_seq))\n",
    "#     a = torch.LongTensor([content_id])\n",
    "#     b = torch.from_numpy(content_id_seq)\n",
    "#     b = b.long()\n",
    "#     print(\"content_id is:\",content_id)\n",
    "#     print(\"content_id_seq:\",content_id_seq)\n",
    "#     print(\"a is:\",a)\n",
    "#     print(\"b is:\",b)\n",
    "#     print(\"\\n\\n\")\n",
    "#     print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:46.633143Z",
     "iopub.status.busy": "2020-11-24T00:19:46.632139Z",
     "iopub.status.idle": "2020-11-24T00:19:46.635091Z",
     "shell.execute_reply": "2020-11-24T00:19:46.634577Z"
    },
    "papermill": {
     "duration": 0.044446,
     "end_time": "2020-11-24T00:19:46.635195",
     "exception": false,
     "start_time": "2020-11-24T00:19:46.590749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "\n",
    "# test_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_test.csv')\n",
    "# test_df['content_id'] = test_df['content_id'] + 1\n",
    "\n",
    "\n",
    "# test_df = test_df.loc[:,['content_id','content_type_id',\n",
    "#                              'row_id','user_id']]\n",
    "\n",
    "# test_df = test_df.loc[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "# print(\"test_df:\", test_df.shape)\n",
    "\n",
    "# test_df = pd.merge(test_df, train_pkl, on='user_id',how='left').fillna('0')\n",
    "\n",
    "# test_df = pad_seq(test_df)\n",
    "\n",
    "# test_dataset = Rii_dataset(test_df)\n",
    "\n",
    "# test_dataloader = data.DataLoader(\n",
    "#             dataset=test_dataset, shuffle=False,\n",
    "#             batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "# preds = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader):\n",
    "#         batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "#         question_id, target_id = batch\n",
    "#         output = model(question_id, target_id)\n",
    "#         pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "#         preds.append(pred)\n",
    "\n",
    "# preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "# print(\"preds:\",preds)\n",
    "# test_df['answered_correctly'] =  preds\n",
    "\n",
    "# end = datetime.datetime.now()\n",
    "# print(\"Test running time:\", end-start)\n",
    "\n",
    "\n",
    "# for row in test_df.itertuples():\n",
    "#     user_id = getattr(row, \"user_id\")\n",
    "#     content_id = getattr(row, \"content_id\")\n",
    "#     content_id_seq = getattr(row, \"content_id_seq\")\n",
    "    \n",
    "#     print(len(content_id_seq))\n",
    "#     a = torch.LongTensor([content_id])\n",
    "#     b = torch.from_numpy(content_id_seq)\n",
    "#     b = b.long()\n",
    "#     print(\"content_id is:\",content_id)\n",
    "#     print(\"content_id_seq:\",content_id_seq)\n",
    "#     print(\"a is:\",a)\n",
    "#     print(\"b is:\",b)\n",
    "#     print(\"\\n\\n\")\n",
    "#     print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:46.707475Z",
     "iopub.status.busy": "2020-11-24T00:19:46.706704Z",
     "iopub.status.idle": "2020-11-24T00:19:46.709110Z",
     "shell.execute_reply": "2020-11-24T00:19:46.709706Z"
    },
    "papermill": {
     "duration": 0.04151,
     "end_time": "2020-11-24T00:19:46.709820",
     "exception": false,
     "start_time": "2020-11-24T00:19:46.668310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:46.793016Z",
     "iopub.status.busy": "2020-11-24T00:19:46.792030Z",
     "iopub.status.idle": "2020-11-24T00:19:48.332721Z",
     "shell.execute_reply": "2020-11-24T00:19:48.333273Z"
    },
    "papermill": {
     "duration": 1.589606,
     "end_time": "2020-11-24T00:19:48.333434",
     "exception": false,
     "start_time": "2020-11-24T00:19:46.743828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 139.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 159.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 142.10it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for(test_df, sample_prediction_df) in iter_test:\n",
    "    try:\n",
    "        test_df['content_id'] = test_df['content_id'] + 1\n",
    "        test_df = test_df.loc[:,['content_id','content_type_id',\n",
    "                             'row_id','user_id']]\n",
    "\n",
    "        test_df = test_df.loc[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "\n",
    "        test_df = pd.merge(test_df, train_pkl, on='user_id',how='left').fillna('0')\n",
    "        test_df = pad_seq(test_df)\n",
    "\n",
    "        test_dataset = Rii_dataset(test_df)\n",
    "        test_dataloader = data.DataLoader(\n",
    "            dataset=test_dataset, shuffle=False,batch_size=ARGS.train_batch)\n",
    "\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader):\n",
    "                batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "                question_id, target_id = batch\n",
    "                output = model(question_id, target_id)\n",
    "                pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "                preds.append(pred)\n",
    "\n",
    "        preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "#         print(\"preds:\",preds)\n",
    "        test_df['answered_correctly'] =  preds\n",
    "        env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "    except:\n",
    "        print(test_df)\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:48.421030Z",
     "iopub.status.busy": "2020-11-24T00:19:48.420229Z",
     "iopub.status.idle": "2020-11-24T00:19:48.423677Z",
     "shell.execute_reply": "2020-11-24T00:19:48.424226Z"
    },
    "papermill": {
     "duration": 0.050283,
     "end_time": "2020-11-24T00:19:48.424358",
     "exception": false,
     "start_time": "2020-11-24T00:19:48.374075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./submission.csv\")\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T00:19:48.511810Z",
     "iopub.status.busy": "2020-11-24T00:19:48.510932Z",
     "iopub.status.idle": "2020-11-24T00:19:48.514579Z",
     "shell.execute_reply": "2020-11-24T00:19:48.515132Z"
    },
    "papermill": {
     "duration": 0.052659,
     "end_time": "2020-11-24T00:19:48.515261",
     "exception": false,
     "start_time": "2020-11-24T00:19:48.462602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  answered_correctly\n",
       "0         0                   1\n",
       "1         1                   1\n",
       "2         2                   1\n",
       "3         3                   1\n",
       "4         4                   0\n",
       "..      ...                 ...\n",
       "99      104                   1\n",
       "100     105                   1\n",
       "101     106                   1\n",
       "102     107                   1\n",
       "103     108                   1\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.039401,
     "end_time": "2020-11-24T00:19:48.595092",
     "exception": false,
     "start_time": "2020-11-24T00:19:48.555691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "duration": 18.807041,
   "end_time": "2020-11-24T00:19:49.046083",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-24T00:19:30.239042",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
