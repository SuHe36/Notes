{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-17T08:32:46.776710Z",
     "iopub.status.busy": "2020-12-17T08:32:46.775567Z",
     "iopub.status.idle": "2020-12-17T08:32:46.810235Z",
     "shell.execute_reply": "2020-12-17T08:32:46.811135Z"
    },
    "papermill": {
     "duration": 0.100008,
     "end_time": "2020-12-17T08:32:46.811410",
     "exception": false,
     "start_time": "2020-12-17T08:32:46.711402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/saktques/question_cmnts.csv\n",
      "/kaggle/input/saktmodel/valid_2.csv\n",
      "/kaggle/input/saktmodel/best_model_ela_part.pt\n",
      "/kaggle/input/saktmodel/train_200_valid_2.csv\n",
      "/kaggle/input/saktmodel/train_100_valid_2.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/example_test.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/questions.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/train.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/lectures.csv\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/riiid-test-answer-prediction/riiideducation/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-17T08:32:46.936148Z",
     "iopub.status.busy": "2020-12-17T08:32:46.935050Z",
     "iopub.status.idle": "2020-12-17T08:32:49.875339Z",
     "shell.execute_reply": "2020-12-17T08:32:49.876723Z"
    },
    "papermill": {
     "duration": 3.007157,
     "end_time": "2020-12-17T08:32:49.876952",
     "exception": false,
     "start_time": "2020-12-17T08:32:46.869795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:32:50.000575Z",
     "iopub.status.busy": "2020-12-17T08:32:49.998516Z",
     "iopub.status.idle": "2020-12-17T08:32:50.001399Z",
     "shell.execute_reply": "2020-12-17T08:32:50.002155Z"
    },
    "papermill": {
     "duration": 0.064802,
     "end_time": "2020-12-17T08:32:50.002340",
     "exception": false,
     "start_time": "2020-12-17T08:32:49.937538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#HDKIM\n",
    "MAX_SEQ = 160\n",
    "#HDKIMHDKIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.066363,
     "end_time": "2020-12-17T08:32:50.123017",
     "exception": false,
     "start_time": "2020-12-17T08:32:50.056654",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:32:50.300019Z",
     "iopub.status.busy": "2020-12-17T08:32:50.298945Z",
     "iopub.status.idle": "2020-12-17T08:33:42.464981Z",
     "shell.execute_reply": "2020-12-17T08:33:42.464361Z"
    },
    "papermill": {
     "duration": 52.282765,
     "end_time": "2020-12-17T08:33:42.465107",
     "exception": false,
     "start_time": "2020-12-17T08:32:50.182342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 s, sys: 1.71 s, total: 29 s\n",
      "Wall time: 52.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>841499248</td>\n",
       "      <td>6054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1722355108</td>\n",
       "      <td>4260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1973833483</td>\n",
       "      <td>5629</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>488555728</td>\n",
       "      <td>5527</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1413146787</td>\n",
       "      <td>7900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp     user_id  content_id  content_type_id  answered_correctly  \\\n",
       "0          0   841499248        6054                0                   0   \n",
       "1          0  1722355108        4260                0                   1   \n",
       "2          0  1973833483        5629                0                   1   \n",
       "3          0   488555728        5527                0                   1   \n",
       "4          0  1413146787        7900                0                   1   \n",
       "\n",
       "   prior_question_elapsed_time  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {'timestamp': 'int64', \n",
    "         'user_id': 'int64' ,\n",
    "         'content_id': 'int16',\n",
    "         'content_type_id': 'int8',\n",
    "         'answered_correctly':'int8',\n",
    "         'prior_question_elapsed_time':'float64'}\n",
    "\n",
    "train_df = pd.read_csv('/kaggle/input/saktmodel/train_200_valid_2.csv', usecols=[1,2,3,4,7,8], dtype=dtype)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:42.549938Z",
     "iopub.status.busy": "2020-12-17T08:33:42.549191Z",
     "iopub.status.idle": "2020-12-17T08:33:50.130759Z",
     "shell.execute_reply": "2020-12-17T08:33:50.131570Z"
    },
    "papermill": {
     "duration": 7.627698,
     "end_time": "2020-12-17T08:33:50.131816",
     "exception": false,
     "start_time": "2020-12-17T08:33:42.504118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df.content_type_id == False]\n",
    "\n",
    "#arrange by timestamp\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:50.252407Z",
     "iopub.status.busy": "2020-12-17T08:33:50.251394Z",
     "iopub.status.idle": "2020-12-17T08:33:51.975641Z",
     "shell.execute_reply": "2020-12-17T08:33:51.974985Z"
    },
    "papermill": {
     "duration": 1.789891,
     "end_time": "2020-12-17T08:33:51.975772",
     "exception": false,
     "start_time": "2020-12-17T08:33:50.185881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>866605366</td>\n",
       "      <td>6267</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1436067548</td>\n",
       "      <td>3709</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2119645200</td>\n",
       "      <td>7900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2019867894</td>\n",
       "      <td>4421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1801712607</td>\n",
       "      <td>5137</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>863504442</td>\n",
       "      <td>5554</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>220576717</td>\n",
       "      <td>4660</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>108605579</td>\n",
       "      <td>5067</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>811433702</td>\n",
       "      <td>4517</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>38532797</td>\n",
       "      <td>6479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp     user_id  content_id  content_type_id  answered_correctly  \\\n",
       "0          0   866605366        6267                0                   1   \n",
       "1          0  1436067548        3709                0                   1   \n",
       "2          0  2119645200        7900                0                   1   \n",
       "3          0  2019867894        4421                0                   0   \n",
       "4          0  1801712607        5137                0                   1   \n",
       "5          0   863504442        5554                0                   1   \n",
       "6          0   220576717        4660                0                   1   \n",
       "7          0   108605579        5067                0                   0   \n",
       "8          0   811433702        4517                0                   0   \n",
       "9          0    38532797        6479                0                   0   \n",
       "\n",
       "   prior_question_elapsed_time  \n",
       "0                          NaN  \n",
       "1                          NaN  \n",
       "2                          NaN  \n",
       "3                          NaN  \n",
       "4                          NaN  \n",
       "5                          NaN  \n",
       "6                          NaN  \n",
       "7                          NaN  \n",
       "8                          NaN  \n",
       "9                          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid = pd.read_csv('/kaggle/input/saktmodel/valid_2.csv', usecols=[ 2, 3,4,5,8,9], dtype=dtype)\n",
    "valid = valid[valid.content_type_id == False]\n",
    "\n",
    "valid.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.067721Z",
     "iopub.status.busy": "2020-12-17T08:33:52.066981Z",
     "iopub.status.idle": "2020-12-17T08:33:52.078203Z",
     "shell.execute_reply": "2020-12-17T08:33:52.078831Z"
    },
    "papermill": {
     "duration": 0.061701,
     "end_time": "2020-12-17T08:33:52.079006",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.017305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_com = pd.read_csv('/kaggle/input/saktques/question_cmnts.csv')\n",
    "question_com.columns = ['question_id', 'community']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.168010Z",
     "iopub.status.busy": "2020-12-17T08:33:52.167106Z",
     "iopub.status.idle": "2020-12-17T08:33:52.171363Z",
     "shell.execute_reply": "2020-12-17T08:33:52.171926Z"
    },
    "papermill": {
     "duration": 0.051411,
     "end_time": "2020-12-17T08:33:52.172212",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.120801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# question_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.041603,
     "end_time": "2020-12-17T08:33:52.255964",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.214361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.367879Z",
     "iopub.status.busy": "2020-12-17T08:33:52.366903Z",
     "iopub.status.idle": "2020-12-17T08:33:52.377167Z",
     "shell.execute_reply": "2020-12-17T08:33:52.378432Z"
    },
    "papermill": {
     "duration": 0.077346,
     "end_time": "2020-12-17T08:33:52.378697",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.301351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# question_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.486234Z",
     "iopub.status.busy": "2020-12-17T08:33:52.485442Z",
     "iopub.status.idle": "2020-12-17T08:33:52.504469Z",
     "shell.execute_reply": "2020-12-17T08:33:52.503855Z"
    },
    "papermill": {
     "duration": 0.067889,
     "end_time": "2020-12-17T08:33:52.504588",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.436699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')\n",
    "question_df['part'].fillna(8, inplace=True)\n",
    "question_df['part'] = question_df['part']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.600303Z",
     "iopub.status.busy": "2020-12-17T08:33:52.599042Z",
     "iopub.status.idle": "2020-12-17T08:33:52.603987Z",
     "shell.execute_reply": "2020-12-17T08:33:52.604495Z"
    },
    "papermill": {
     "duration": 0.05852,
     "end_time": "2020-12-17T08:33:52.604669",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.546149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51 131 162 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131 36 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131 101 162 92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131 149 162 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>131 5 162 38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>131 149 162 81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10 94 162 92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61 110 162 29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>131 13 162 92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10 164 81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_id  bundle_id  correct_answer  part            tags\n",
       "0            0          0               0     0   51 131 162 38\n",
       "1            1          1               1     0       131 36 81\n",
       "2            2          2               0     0  131 101 162 92\n",
       "3            3          3               0     0  131 149 162 29\n",
       "4            4          4               3     0    131 5 162 38\n",
       "5            5          5               2     0  131 149 162 81\n",
       "6            6          6               2     0    10 94 162 92\n",
       "7            7          7               0     0   61 110 162 29\n",
       "8            8          8               3     0   131 13 162 92\n",
       "9            9          9               3     0       10 164 81"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.696579Z",
     "iopub.status.busy": "2020-12-17T08:33:52.695407Z",
     "iopub.status.idle": "2020-12-17T08:33:52.708713Z",
     "shell.execute_reply": "2020-12-17T08:33:52.708105Z"
    },
    "papermill": {
     "duration": 0.062573,
     "end_time": "2020-12-17T08:33:52.708841",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.646268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_df = pd.merge(question_df, question_com, on='question_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.799787Z",
     "iopub.status.busy": "2020-12-17T08:33:52.798729Z",
     "iopub.status.idle": "2020-12-17T08:33:52.810059Z",
     "shell.execute_reply": "2020-12-17T08:33:52.810633Z"
    },
    "papermill": {
     "duration": 0.060235,
     "end_time": "2020-12-17T08:33:52.810792",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.750557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10033</th>\n",
       "      <td>10033</td>\n",
       "      <td>10033</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id  bundle_id  correct_answer  part tags  community\n",
       "10033        10033      10033               2     5  NaN          4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df.loc[question_df['community']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:52.998882Z",
     "iopub.status.busy": "2020-12-17T08:33:52.997944Z",
     "iopub.status.idle": "2020-12-17T08:33:53.001661Z",
     "shell.execute_reply": "2020-12-17T08:33:53.002204Z"
    },
    "papermill": {
     "duration": 0.143234,
     "end_time": "2020-12-17T08:33:53.002348",
     "exception": false,
     "start_time": "2020-12-17T08:33:52.859114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del question_com\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:53.108631Z",
     "iopub.status.busy": "2020-12-17T08:33:53.107671Z",
     "iopub.status.idle": "2020-12-17T08:33:53.112091Z",
     "shell.execute_reply": "2020-12-17T08:33:53.112669Z"
    },
    "papermill": {
     "duration": 0.066804,
     "end_time": "2020-12-17T08:33:53.112818",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.046014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>bundle_id</th>\n",
       "      <th>correct_answer</th>\n",
       "      <th>part</th>\n",
       "      <th>tags</th>\n",
       "      <th>community</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51 131 162 38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>131 36 81</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131 101 162 92</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>131 149 162 29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>131 5 162 38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13518</th>\n",
       "      <td>13518</td>\n",
       "      <td>13518</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>13519</td>\n",
       "      <td>13519</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>13520</td>\n",
       "      <td>13520</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>13521</td>\n",
       "      <td>13521</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>13522</td>\n",
       "      <td>13522</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13523 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_id  bundle_id  correct_answer  part            tags  community\n",
       "0                0          0               0     0   51 131 162 38          2\n",
       "1                1          1               1     0       131 36 81          2\n",
       "2                2          2               0     0  131 101 162 92          2\n",
       "3                3          3               0     0  131 149 162 29          2\n",
       "4                4          4               3     0    131 5 162 38          2\n",
       "...            ...        ...             ...   ...             ...        ...\n",
       "13518        13518      13518               3     4              14          0\n",
       "13519        13519      13519               3     4               8          1\n",
       "13520        13520      13520               2     4              73          1\n",
       "13521        13521      13521               0     4             125          0\n",
       "13522        13522      13522               3     4              55          1\n",
       "\n",
       "[13523 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:53.209514Z",
     "iopub.status.busy": "2020-12-17T08:33:53.208679Z",
     "iopub.status.idle": "2020-12-17T08:33:53.213591Z",
     "shell.execute_reply": "2020-12-17T08:33:53.214168Z"
    },
    "papermill": {
     "duration": 0.056784,
     "end_time": "2020-12-17T08:33:53.214320",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.157536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part is: [0 1 2 3 4 5 6]\n",
      "number part skills 7\n"
     ]
    }
   ],
   "source": [
    "part_skill = question_df['part'].unique()\n",
    "print(\"part is:\",part_skill)\n",
    "n_part_skill = len(part_skill)\n",
    "print(\"number part skills\", n_part_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:53.313482Z",
     "iopub.status.busy": "2020-12-17T08:33:53.311724Z",
     "iopub.status.idle": "2020-12-17T08:33:53.317204Z",
     "shell.execute_reply": "2020-12-17T08:33:53.316450Z"
    },
    "papermill": {
     "duration": 0.058308,
     "end_time": "2020-12-17T08:33:53.317335",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.259027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community is: [2 1 0 3 4]\n",
      "number community skills is: 5\n"
     ]
    }
   ],
   "source": [
    "com_skill = question_df['community'].unique()\n",
    "print(\"community is:\", com_skill)\n",
    "n_com_skill = len(com_skill)\n",
    "print(\"number community skills is:\", n_com_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:53.418798Z",
     "iopub.status.busy": "2020-12-17T08:33:53.416115Z",
     "iopub.status.idle": "2020-12-17T08:33:53.494109Z",
     "shell.execute_reply": "2020-12-17T08:33:53.494785Z"
    },
    "papermill": {
     "duration": 0.132529,
     "end_time": "2020-12-17T08:33:53.494950",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.362421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24430.802356914817"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elapsed_mean = train_df.prior_question_elapsed_time.mean()\n",
    "elapsed_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:53.606239Z",
     "iopub.status.busy": "2020-12-17T08:33:53.605004Z",
     "iopub.status.idle": "2020-12-17T08:33:53.673987Z",
     "shell.execute_reply": "2020-12-17T08:33:53.674528Z"
    },
    "papermill": {
     "duration": 0.1275,
     "end_time": "2020-12-17T08:33:53.674720",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.547220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:53.774147Z",
     "iopub.status.busy": "2020-12-17T08:33:53.773190Z",
     "iopub.status.idle": "2020-12-17T08:33:53.776905Z",
     "shell.execute_reply": "2020-12-17T08:33:53.776331Z"
    },
    "papermill": {
     "duration": 0.05586,
     "end_time": "2020-12-17T08:33:53.777028",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.721168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_elapsed_time(ela):\n",
    "    ela = ela // 1000\n",
    "    if ela > 300:\n",
    "        return 300\n",
    "    else:\n",
    "        return ela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:33:55.697667Z",
     "iopub.status.busy": "2020-12-17T08:33:55.696307Z",
     "iopub.status.idle": "2020-12-17T08:34:27.711346Z",
     "shell.execute_reply": "2020-12-17T08:34:27.712016Z"
    },
    "papermill": {
     "duration": 33.889052,
     "end_time": "2020-12-17T08:34:27.712177",
     "exception": false,
     "start_time": "2020-12-17T08:33:53.823125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['prior_question_elapsed_time'] = train_df['prior_question_elapsed_time'].apply(lambda x: get_elapsed_time(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:34:27.813913Z",
     "iopub.status.busy": "2020-12-17T08:34:27.812441Z",
     "iopub.status.idle": "2020-12-17T08:34:35.491762Z",
     "shell.execute_reply": "2020-12-17T08:34:35.491128Z"
    },
    "papermill": {
     "duration": 7.732808,
     "end_time": "2020-12-17T08:34:35.491896",
     "exception": false,
     "start_time": "2020-12-17T08:34:27.759088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_df, question_df, left_on='content_id',right_on='question_id',how='left')\n",
    "valid = pd.merge(valid, question_df, left_on='content_id',right_on='question_id',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.047555,
     "end_time": "2020-12-17T08:34:35.586464",
     "exception": false,
     "start_time": "2020-12-17T08:34:35.538909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046553,
     "end_time": "2020-12-17T08:34:35.680187",
     "exception": false,
     "start_time": "2020-12-17T08:34:35.633634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:34:35.780116Z",
     "iopub.status.busy": "2020-12-17T08:34:35.779206Z",
     "iopub.status.idle": "2020-12-17T08:34:35.783526Z",
     "shell.execute_reply": "2020-12-17T08:34:35.784126Z"
    },
    "papermill": {
     "duration": 0.056749,
     "end_time": "2020-12-17T08:34:35.784291",
     "exception": false,
     "start_time": "2020-12-17T08:34:35.727542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number skills 13523\n"
     ]
    }
   ],
   "source": [
    "# skills = train_df[\"content_id\"].unique()\n",
    "n_skill = 13523\n",
    "print(\"number skills\", n_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:34:35.885731Z",
     "iopub.status.busy": "2020-12-17T08:34:35.884741Z",
     "iopub.status.idle": "2020-12-17T08:34:36.164178Z",
     "shell.execute_reply": "2020-12-17T08:34:36.164757Z"
    },
    "papermill": {
     "duration": 0.333355,
     "end_time": "2020-12-17T08:34:36.164932",
     "exception": false,
     "start_time": "2020-12-17T08:34:35.831577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number ela skills 301\n",
      "ela is: [ 24.   5.  17.  83.  21.  51.  48.  29.  30.  69. 101.  34.  31.  55.\n",
      "  20.   6.  56.  42.  19.  27.  67.  36.  46.  25.  13.  26.  22.  50.\n",
      "  61.  70.  14.  47.  52.   0.  64.  76.  28.  86.  41.  15.  33.   1.\n",
      "  58.  23.  54.  82.  75.   3.  11.  59.   4.  45.  32.  37.   2.  16.\n",
      "  38.  74.  18.  71.  10.   9.  63.  81.   7.  60.  53.  62.  35.  72.\n",
      "  39.  65.  40.  68.  57.  43.  78.  12.  90.  49.  77.  93.   8.  87.\n",
      "  89.  44.  84. 121.  91.  79.  94. 109. 162. 300. 187. 188. 155. 170.\n",
      " 156. 160. 126. 100. 134. 217. 218.  73. 183. 216. 204.  80.  98. 108.\n",
      " 129.  96. 154. 148. 141. 241. 221. 124.  95. 202. 186. 180.  97. 127.\n",
      " 104.  85. 181. 208. 210. 172. 106. 266. 167. 232.  66. 115. 152. 143.\n",
      " 244.  88. 297. 193. 132. 133. 110. 116. 196. 215. 179. 219. 139. 228.\n",
      " 117. 105. 113.  99. 112. 102.  92. 225. 136. 174. 250. 159. 207. 138.\n",
      " 251. 213. 201. 175. 114. 199. 197. 192. 128. 107. 264. 246. 171. 125.\n",
      " 165. 120. 119. 149. 230. 135. 206. 111. 191. 158. 103. 209. 123. 131.\n",
      " 198. 286. 118. 157. 281. 194. 249. 223. 220. 146. 261. 214. 122. 203.\n",
      " 140. 277. 184. 130. 231. 161. 166. 173. 226. 147. 272. 242. 293. 276.\n",
      " 211. 282. 260. 200. 164. 137. 256. 145. 275. 178. 205. 176. 268. 294.\n",
      " 153. 235. 222. 168. 212. 262. 142. 258. 259. 195. 279. 238. 289. 227.\n",
      " 284. 150. 239. 288. 185. 254. 237. 240. 252. 189. 182. 257. 248. 224.\n",
      " 151. 265. 234. 190. 144. 229. 247. 169. 245. 298. 236. 274. 163. 233.\n",
      " 273. 292. 177. 267. 243. 296. 283. 299. 295. 255. 271. 280. 278. 253.\n",
      " 269. 291. 285. 270. 287. 263. 290.]\n"
     ]
    }
   ],
   "source": [
    "ela_skill = train_df['prior_question_elapsed_time'].unique()\n",
    "n_ela_skill = 301\n",
    "print(\"number ela skills\", n_ela_skill)\n",
    "print(\"ela is:\", ela_skill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046994,
     "end_time": "2020-12-17T08:34:36.259439",
     "exception": false,
     "start_time": "2020-12-17T08:34:36.212445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:34:36.361596Z",
     "iopub.status.busy": "2020-12-17T08:34:36.360590Z",
     "iopub.status.idle": "2020-12-17T08:34:37.140579Z",
     "shell.execute_reply": "2020-12-17T08:34:37.139956Z"
    },
    "papermill": {
     "duration": 0.833712,
     "end_time": "2020-12-17T08:34:37.140728",
     "exception": false,
     "start_time": "2020-12-17T08:34:36.307016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid['prior_question_elapsed_time'].fillna(elapsed_mean, inplace=True)\n",
    "valid['prior_question_elapsed_time'] = valid['prior_question_elapsed_time'].apply(lambda x: get_elapsed_time(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:34:37.268467Z",
     "iopub.status.busy": "2020-12-17T08:34:37.267379Z",
     "iopub.status.idle": "2020-12-17T08:36:04.855061Z",
     "shell.execute_reply": "2020-12-17T08:36:04.855727Z"
    },
    "papermill": {
     "duration": 87.665787,
     "end_time": "2020-12-17T08:36:04.855902",
     "exception": false,
     "start_time": "2020-12-17T08:34:37.190115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = train_df[['user_id', 'part','content_id','community', 'answered_correctly','prior_question_elapsed_time']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "            r['prior_question_elapsed_time'].values,\n",
    "            r['part'].values,\n",
    "            r['community'].values))\n",
    "\n",
    "\n",
    "\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:04.959423Z",
     "iopub.status.busy": "2020-12-17T08:36:04.958495Z",
     "iopub.status.idle": "2020-12-17T08:36:04.963030Z",
     "shell.execute_reply": "2020-12-17T08:36:04.962371Z"
    },
    "papermill": {
     "duration": 0.058571,
     "end_time": "2020-12-17T08:36:04.963167",
     "exception": false,
     "start_time": "2020-12-17T08:36:04.904596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#HDKIM\n",
    "import random\n",
    "random.seed(1)\n",
    "#HDKIMHDKIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:05.098330Z",
     "iopub.status.busy": "2020-12-17T08:36:05.090036Z",
     "iopub.status.idle": "2020-12-17T08:36:05.101502Z",
     "shell.execute_reply": "2020-12-17T08:36:05.100880Z"
    },
    "papermill": {
     "duration": 0.089834,
     "end_time": "2020-12-17T08:36:05.101638",
     "exception": false,
     "start_time": "2020-12-17T08:36:05.011804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAKTDataset(Dataset):\n",
    "    def __init__(self, group, n_skill,n_ela_skill, max_seq=MAX_SEQ): #HDKIM 100\n",
    "        super(SAKTDataset, self).__init__()\n",
    "        self.max_seq = max_seq\n",
    "        self.n_skill = n_skill\n",
    "        self.n_ela_skill = n_ela_skill\n",
    "        self.samples = group\n",
    "        \n",
    "#         self.user_ids = [x for x in group.index]\n",
    "        self.user_ids = []\n",
    "        for user_id in group.index:\n",
    "            q, qa,ela,part,com = group[user_id]\n",
    "            if len(q) < 2: #HDKIM 10\n",
    "                continue\n",
    "            self.user_ids.append(user_id)\n",
    "            \n",
    "            #HDKIM Memory reduction\n",
    "#             if len(q)>self.max_seq:\n",
    "#                 group[user_id] = (q[-self.max_seq:],qa[-self.max_seq:], ela[-self.max_seq:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        q_, qa_,ela_,part_,com_ = self.samples[user_id]\n",
    "        seq_len = len(q_)\n",
    "\n",
    "        q = np.ones(self.max_seq, dtype=int)*13523\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        ela = np.ones(self.max_seq, dtype=int)*301\n",
    "        part = np.ones(self.max_seq, dtype=int)*7\n",
    "        com = np.ones(self.max_seq, dtype=int)*4\n",
    "\n",
    "        if seq_len >= self.max_seq:\n",
    "            if random.random() >0.1:\n",
    "                start = random.randint(0, (seq_len-self.max_seq))\n",
    "                end = start + self.max_seq\n",
    "                q[:] = q_[start:end]\n",
    "                qa[:] = qa_[start:end]\n",
    "                ela[:] = ela_[start:end]\n",
    "                part[:] = part_[start:end]\n",
    "                com[:] = com_[start:end]\n",
    "\n",
    "            else:   \n",
    "                q[:] = q_[-self.max_seq:]\n",
    "                qa[:] = qa_[-self.max_seq:]\n",
    "                ela[:] = ela_[-self.max_seq:]\n",
    "                part[:] = part_[-self.max_seq:]\n",
    "                com[:] = com_[-self.max_seq:]\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            if random.random() > 0.1:\n",
    "                start = 0\n",
    "                end = random.randint(2, seq_len)\n",
    "                seq_len = end -start\n",
    "                q[-seq_len:] = q_[0:seq_len]\n",
    "                qa[-seq_len:] = qa_[0:seq_len]\n",
    "                ela[-seq_len:] = ela_[0:seq_len]\n",
    "                part[-seq_len:] = part_[0:seq_len]\n",
    "                com[-seq_len:] = com_[0:seq_len]\n",
    "                \n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_\n",
    "                ela[-seq_len:] = ela_   \n",
    "                part[-seq_len:] = part_   \n",
    "                com[-seq_len:] = com_   \n",
    "            \n",
    "        target_id = q[1:]\n",
    "        label = qa[1:]\n",
    "        ela_target = ela[1:]\n",
    "        part_target = part[1:]\n",
    "        com_target = com[1:]\n",
    "\n",
    "        x = np.ones(self.max_seq-1, dtype=int)*13523\n",
    "        x = q[:-1].copy()\n",
    "#         x += (qa[:-1] == 1) * self.n_skill\n",
    "        \n",
    "        ela_x = np.ones(self.max_seq-1, dtype=int)*301\n",
    "        ela_x = ela[:-1].copy()\n",
    "        \n",
    "        part_x = np.ones(self.max_seq-1, dtype=int)*7\n",
    "        part_x = part[:-1].copy()        \n",
    "        \n",
    "        ans_x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        ans_x = qa[:-1].copy()\n",
    "        \n",
    "        com_x = np.ones(self.max_seq-1, dtype=int)*4\n",
    "        com_x = com[:-1].copy()\n",
    "#         ela_x += (qa[:-1]==1) * self.n_ela_skill\n",
    "\n",
    "        return x, target_id,ela_x,ela_target,part_x,part_target,com_x,com_target,ans_x,label\n",
    "    # x和target_id都是来自于q，存在一个错位，x比target_id提前一个位置\n",
    "    # 所以我们可以尝试将ela 也分为ela_x和ela_target_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:05.218198Z",
     "iopub.status.busy": "2020-12-17T08:36:05.217138Z",
     "iopub.status.idle": "2020-12-17T08:36:09.260873Z",
     "shell.execute_reply": "2020-12-17T08:36:09.259423Z"
    },
    "papermill": {
     "duration": 4.109755,
     "end_time": "2020-12-17T08:36:09.261030",
     "exception": false,
     "start_time": "2020-12-17T08:36:05.151275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SAKTDataset(group, n_skill, n_ela_skill)\n",
    "dataloader = DataLoader(dataset, batch_size=2048, shuffle=True,num_workers=8)\n",
    "\n",
    "item = dataset.__getitem__(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:09.395527Z",
     "iopub.status.busy": "2020-12-17T08:36:09.382497Z",
     "iopub.status.idle": "2020-12-17T08:36:09.398634Z",
     "shell.execute_reply": "2020-12-17T08:36:09.397966Z"
    },
    "papermill": {
     "duration": 0.088989,
     "end_time": "2020-12-17T08:36:09.398751",
     "exception": false,
     "start_time": "2020-12-17T08:36:09.309762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, n_skill,n_ela_skill, max_seq=MAX_SEQ): #HDKIM 100\n",
    "        super(ValidDataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.n_ela_skill = n_ela_skill\n",
    "        self.n_skill = n_skill\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "\n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "        ela_target_id = test_info[\"prior_question_elapsed_time\"]\n",
    "        part_target_id = test_info[\"part\"]\n",
    "        com_target_id = test_info[\"community\"]\n",
    "\n",
    "        \n",
    "        label = test_info['answered_correctly']\n",
    "\n",
    "        q = np.ones(self.max_seq, dtype=int)*13523\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        ela = np.ones(self.max_seq, dtype=int)*301\n",
    "        part = np.ones(self.max_seq, dtype=int)*7\n",
    "        com = np.ones(self.max_seq, dtype=int)*4\n",
    "\n",
    "        if user_id in self.samples.index:\n",
    "            q_, qa_, ela_, part_,com_ = self.samples[user_id]\n",
    "            \n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "                ela = ela_[-self.max_seq:]\n",
    "                part = part_[-self.max_seq:]\n",
    "                com = com_[-self.max_seq:]\n",
    "                \n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_       \n",
    "                ela[-seq_len:] = ela_\n",
    "                part[-seq_len:] = part_\n",
    "                com[-seq_len:] = com_\n",
    "        \n",
    "        x = np.ones(self.max_seq-1, dtype=int)*13523\n",
    "        x = q[1:].copy()\n",
    "#         x += (qa[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append(q[2:], [target_id])\n",
    "        \n",
    "        ela_x = np.ones(self.max_seq-1, dtype=int)*301\n",
    "        ela_x = ela[1:].copy()\n",
    "#         ela_x += (qa[1:] == 1) * self.n_ela_skill\n",
    "        \n",
    "        ela_target = np.append(ela[2:],[ela_target_id])\n",
    "        \n",
    "        part_x = np.ones(self.max_seq-1, dtype=int)*7\n",
    "        part_x = part[1:].copy()\n",
    "        \n",
    "        part_target = np.append(part[2:],[part_target_id])\n",
    "\n",
    "        com_x = np.ones(self.max_seq-1, dtype=int)*4\n",
    "        com_x = com[1:].copy()\n",
    "        \n",
    "        com_target = np.append(com[2:],[com_target_id])\n",
    "        \n",
    "        ans_x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        ans_x = qa[1:].copy()\n",
    "#         return x, questions, ela_x, ela_target, np.array([label])\n",
    "        return torch.LongTensor(x), torch.LongTensor(questions),\\\n",
    "            torch.LongTensor(ela_x), torch.LongTensor(ela_target),\\\n",
    "            torch.LongTensor(part_x), torch.LongTensor(part_target),\\\n",
    "            torch.LongTensor(com_x), torch.LongTensor(com_target),\\\n",
    "            torch.LongTensor(ans_x),\\\n",
    "            torch.FloatTensor(np.array([label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:09.504483Z",
     "iopub.status.busy": "2020-12-17T08:36:09.503428Z",
     "iopub.status.idle": "2020-12-17T08:36:09.578855Z",
     "shell.execute_reply": "2020-12-17T08:36:09.578227Z"
    },
    "papermill": {
     "duration": 0.129783,
     "end_time": "2020-12-17T08:36:09.578989",
     "exception": false,
     "start_time": "2020-12-17T08:36:09.449206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = ValidDataset(group, valid, n_skill, n_ela_skill)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2048, shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.049988,
     "end_time": "2020-12-17T08:36:09.678804",
     "exception": false,
     "start_time": "2020-12-17T08:36:09.628816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.050586,
     "end_time": "2020-12-17T08:36:09.778862",
     "exception": false,
     "start_time": "2020-12-17T08:36:09.728276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:09.922197Z",
     "iopub.status.busy": "2020-12-17T08:36:09.920939Z",
     "iopub.status.idle": "2020-12-17T08:36:09.929366Z",
     "shell.execute_reply": "2020-12-17T08:36:09.928569Z"
    },
    "papermill": {
     "duration": 0.101255,
     "end_time": "2020-12-17T08:36:09.929502",
     "exception": false,
     "start_time": "2020-12-17T08:36:09.828247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, state_size=200):\n",
    "        super(FFN, self).__init__()\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.lr1 = nn.Linear(state_size, state_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr2 = nn.Linear(state_size, state_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def future_mask(seq_length):\n",
    "    future_mask = np.triu(np.ones((seq_length, seq_length)), k=1).astype('bool')\n",
    "    return torch.from_numpy(future_mask)\n",
    "\n",
    "\n",
    "class SAKTModel(nn.Module):\n",
    "    def __init__(self, n_skill,n_ela_skill,n_part_skill,n_com_skill,max_seq=MAX_SEQ, embed_dim=128): #HDKIM 100\n",
    "        super(SAKTModel, self).__init__()\n",
    "        self.n_skill = n_skill\n",
    "        self.n_ela_skill = n_ela_skill\n",
    "        self.n_part_skill = n_part_skill\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(2*n_skill+1, embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_seq-1, embed_dim)\n",
    "        self.e_embedding = nn.Embedding(n_skill+1, embed_dim)\n",
    "        \n",
    "        self.ela_ans_embedding = nn.Embedding(2*n_ela_skill+1, embed_dim)\n",
    "        self.ela_embedding = nn.Embedding(n_ela_skill+1, embed_dim)\n",
    "\n",
    "        self.part_embedding = nn.Embedding(n_part_skill+1, embed_dim)\n",
    "        self.com_embedding = nn.Embedding(n_com_skill+1, embed_dim)\n",
    "        \n",
    "        self.ans_embedding = nn.Embedding(2, embed_dim)\n",
    "        \n",
    "        self.multi_att = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=8, dropout=0.2)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.layer_normal = nn.LayerNorm(embed_dim) \n",
    "\n",
    "        self.ffn = FFN(embed_dim)\n",
    "        self.pred = nn.Linear(embed_dim, 1)\n",
    "    \n",
    "    def forward(self, x, question_ids, ela_x, ela_target_ids, \n",
    "                part_x, part_target_ids,com_x,com_target_ids,ans_x):\n",
    "        device = x.device   \n",
    "#         print(\"x shape is:{}\".format(x.shape))\n",
    "#         print(\"x is:{}\\n\".format(x))\n",
    "#         x = self.embedding(x)\n",
    "        x = self.e_embedding(x)\n",
    "        pos_id = torch.arange(x.size(1)).unsqueeze(0).to(device)\n",
    "        \n",
    "        ans_x = self.ans_embedding(ans_x)\n",
    "        pos_x = self.pos_embedding(pos_id)\n",
    "#         ela_x = self.ela_ans_embedding(ela_x)\n",
    "        ela_x = self.ela_embedding(ela_x)\n",
    "        part_x = self.part_embedding(part_x)\n",
    "        com_x = self.com_embedding(com_x)\n",
    "        \n",
    "        x = x + ela_x + pos_x + part_x + ans_x + com_x\n",
    "\n",
    "        e = self.e_embedding(question_ids)\n",
    "        ela = self.ela_embedding(ela_target_ids)\n",
    "        part = self.part_embedding(part_target_ids)\n",
    "        com = self.com_embedding(com_target_ids)\n",
    "        e = e + ela + part + com\n",
    "        \n",
    "        x = x.permute(1, 0, 2) # x: [bs, s_len, embed] => [s_len, bs, embed]\n",
    "        e = e.permute(1, 0, 2)\n",
    "        att_mask = future_mask(x.size(0)).to(device)\n",
    "        att_output, att_weight = self.multi_att(e, x, x, attn_mask=att_mask)\n",
    "        # 这个att_output其实是x的一个attention表示\n",
    "        att_output = self.layer_normal(att_output + e)\n",
    "        att_output = att_output.permute(1, 0, 2) # att_output: [s_len, bs, embed] => [bs, s_len, embed]\n",
    "\n",
    "        x = self.ffn(att_output)\n",
    "        x = self.layer_normal(x + att_output)\n",
    "        x = self.pred(x)\n",
    "\n",
    "        return x.squeeze(-1), att_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:10.428034Z",
     "iopub.status.busy": "2020-12-17T08:36:10.427096Z",
     "iopub.status.idle": "2020-12-17T08:36:15.209544Z",
     "shell.execute_reply": "2020-12-17T08:36:15.208699Z"
    },
    "papermill": {
     "duration": 5.229826,
     "end_time": "2020-12-17T08:36:15.209706",
     "exception": false,
     "start_time": "2020-12-17T08:36:09.979880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCEWithLogitsLoss()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = xm.xla_device()\n",
    "\n",
    "model = SAKTModel(n_skill+1,n_ela_skill+1,n_part_skill+1,n_com_skill, embed_dim=128)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.99, weight_decay=0.005)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:15.333220Z",
     "iopub.status.busy": "2020-12-17T08:36:15.332191Z",
     "iopub.status.idle": "2020-12-17T08:36:15.335786Z",
     "shell.execute_reply": "2020-12-17T08:36:15.335098Z"
    },
    "papermill": {
     "duration": 0.075384,
     "end_time": "2020-12-17T08:36:15.335906",
     "exception": false,
     "start_time": "2020-12-17T08:36:15.260522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        ela_x = item[2].to(device).long()\n",
    "        ela_target = item[3].to(device).long()\n",
    "        part_x = item[4].to(device).long()\n",
    "        part_target = item[5].to(device).long()\n",
    "        com_x = item[6].to(device).long()\n",
    "        com_target = item[7].to(device).long()            \n",
    "            \n",
    "        ans_x = item[8].to(device).long()\n",
    "        label = item[9].to(device).float()        \n",
    "        \n",
    "        optim.zero_grad()\n",
    "        output, atten_weight = model(x, target_id, ela_x, ela_target,\n",
    "                                     part_x, part_target,com_x, com_target,ans_x)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "#         xm.mark_step()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        output = output[:, -1]\n",
    "        label = label[:, -1] \n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.mean(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:15.460884Z",
     "iopub.status.busy": "2020-12-17T08:36:15.458699Z",
     "iopub.status.idle": "2020-12-17T08:36:15.461717Z",
     "shell.execute_reply": "2020-12-17T08:36:15.462247Z"
    },
    "papermill": {
     "duration": 0.076034,
     "end_time": "2020-12-17T08:36:15.462390",
     "exception": false,
     "start_time": "2020-12-17T08:36:15.386356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, test_dataloader, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(test_dataloader):\n",
    "            x = item[0].to(device).long()\n",
    "            target_id = item[1].to(device).long()\n",
    "            ela_x = item[2].to(device).long()\n",
    "            ela_target = item[3].to(device).long()\n",
    "            part_x = item[4].to(device).long()\n",
    "            part_target = item[5].to(device).long()\n",
    "            com_x = item[6].to(device).long()\n",
    "            com_target = item[7].to(device).long()            \n",
    "            \n",
    "            ans_x = item[8].to(device).long()\n",
    "            label = item[9].to(device).float()\n",
    "#             print(\"In evaluation x shape is:{}\\t taret_id shape is:{}\\t label shape is:{}\".format(x.shape, target_id.shape,label.shape))\n",
    "            \n",
    "            output, atten_weight = model(x, target_id, ela_x, ela_target,\n",
    "                                         part_x, part_target,com_x, com_target, ans_x)\n",
    "            \n",
    "            output_loss = output[:, -1:]\n",
    "#             print(\"Output shape is:{}\\tlabel shape is:{}\".format(output.shape, label.shape))\n",
    "            loss = criterion(output_loss, label)\n",
    "            eval_loss.append(loss.item())\n",
    "            \n",
    "            output = output[:,-1]\n",
    "            label = label[:, -1] \n",
    "            pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "            \n",
    "            num_corrects += (pred == label).sum().item()\n",
    "            num_total += len(label)\n",
    "\n",
    "            labels.extend(label.view(-1).data.cpu().numpy())\n",
    "            outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "#     print(\"In evaluate labels is:{}\\t outs is:{}\\t\".format(labels, outs))\n",
    "\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "#     auc = 0\n",
    "\n",
    "    loss = np.mean(eval_loss)   \n",
    "    \n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T08:36:15.575073Z",
     "iopub.status.busy": "2020-12-17T08:36:15.574270Z",
     "iopub.status.idle": "2020-12-17T11:45:09.621960Z",
     "shell.execute_reply": "2020-12-17T11:45:09.621313Z"
    },
    "papermill": {
     "duration": 11334.109323,
     "end_time": "2020-12-17T11:45:09.622090",
     "exception": false,
     "start_time": "2020-12-17T08:36:15.512767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2220: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0 train_loss - 0.23 acc - 0.628 auc - 0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:41<00:00,  1.20s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0 eval_loss - 0.63 eval acc - 0.643 eval auc - 0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2215: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 1 train_loss - 0.21 acc - 0.676 auc - 0.737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2029: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 2 train_loss - 0.20 acc - 0.686 auc - 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1956: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 3 train_loss - 0.20 acc - 0.687 auc - 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2105: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 4 train_loss - 0.20 acc - 0.688 auc - 0.754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1959: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 5 train_loss - 0.20 acc - 0.689 auc - 0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1829: 100%|██████████| 193/193 [01:29<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 6 train_loss - 0.20 acc - 0.689 auc - 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2198: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 7 train_loss - 0.20 acc - 0.690 auc - 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2122: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 8 train_loss - 0.20 acc - 0.691 auc - 0.757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1996: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 9 train_loss - 0.20 acc - 0.691 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1962: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 10 train_loss - 0.20 acc - 0.691 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:48<00:00,  1.22s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 10 eval_loss - 0.60 eval acc - 0.676 eval auc - 0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2259: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 11 train_loss - 0.20 acc - 0.691 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2144: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 12 train_loss - 0.20 acc - 0.692 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2043: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 13 train_loss - 0.20 acc - 0.691 auc - 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2072: 100%|██████████| 193/193 [01:31<00:00,  2.12it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 14 train_loss - 0.20 acc - 0.693 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2008: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 15 train_loss - 0.20 acc - 0.693 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1960: 100%|██████████| 193/193 [01:31<00:00,  2.12it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 16 train_loss - 0.20 acc - 0.691 auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2055: 100%|██████████| 193/193 [01:29<00:00,  2.15it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 17 train_loss - 0.20 acc - 0.692 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2118: 100%|██████████| 193/193 [01:29<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 18 train_loss - 0.20 acc - 0.692 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1830: 100%|██████████| 193/193 [01:30<00:00,  2.14it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 19 train_loss - 0.20 acc - 0.694 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1813: 100%|██████████| 193/193 [01:31<00:00,  2.12it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 20 train_loss - 0.20 acc - 0.693 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:48<00:00,  1.22s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 20 eval_loss - 0.60 eval acc - 0.677 eval auc - 0.751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1919: 100%|██████████| 193/193 [01:29<00:00,  2.15it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 21 train_loss - 0.20 acc - 0.692 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1964: 100%|██████████| 193/193 [01:28<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 22 train_loss - 0.20 acc - 0.693 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2072: 100%|██████████| 193/193 [01:26<00:00,  2.22it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 23 train_loss - 0.20 acc - 0.695 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2131: 100%|██████████| 193/193 [01:30<00:00,  2.13it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 24 train_loss - 0.20 acc - 0.692 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2089: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 25 train_loss - 0.20 acc - 0.693 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1962: 100%|██████████| 193/193 [01:28<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 26 train_loss - 0.20 acc - 0.693 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1902: 100%|██████████| 193/193 [01:30<00:00,  2.14it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 27 train_loss - 0.20 acc - 0.693 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1998: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 28 train_loss - 0.20 acc - 0.693 auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1894: 100%|██████████| 193/193 [01:28<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 29 train_loss - 0.20 acc - 0.693 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1855: 100%|██████████| 193/193 [01:31<00:00,  2.10it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 30 train_loss - 0.20 acc - 0.693 auc - 0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:42<00:00,  1.20s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 30 eval_loss - 0.59 eval acc - 0.679 eval auc - 0.752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1962: 100%|██████████| 193/193 [01:32<00:00,  2.09it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 31 train_loss - 0.20 acc - 0.694 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2251: 100%|██████████| 193/193 [01:27<00:00,  2.22it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 32 train_loss - 0.20 acc - 0.694 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1981: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 33 train_loss - 0.20 acc - 0.694 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2194: 100%|██████████| 193/193 [01:31<00:00,  2.11it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 34 train_loss - 0.20 acc - 0.694 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1957: 100%|██████████| 193/193 [01:29<00:00,  2.16it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 35 train_loss - 0.20 acc - 0.694 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2102: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 36 train_loss - 0.20 acc - 0.694 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1835: 100%|██████████| 193/193 [01:31<00:00,  2.12it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 37 train_loss - 0.20 acc - 0.694 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2048: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 38 train_loss - 0.20 acc - 0.694 auc - 0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2058: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 39 train_loss - 0.20 acc - 0.694 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1949: 100%|██████████| 193/193 [01:29<00:00,  2.15it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 40 train_loss - 0.20 acc - 0.695 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:43<00:00,  1.20s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 40 eval_loss - 0.59 eval acc - 0.680 eval auc - 0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1829: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 41 train_loss - 0.20 acc - 0.696 auc - 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1947: 100%|██████████| 193/193 [01:29<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 42 train_loss - 0.20 acc - 0.695 auc - 0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2123: 100%|██████████| 193/193 [01:27<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 43 train_loss - 0.20 acc - 0.695 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2096: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 44 train_loss - 0.20 acc - 0.696 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1937: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 45 train_loss - 0.20 acc - 0.695 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1975: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 46 train_loss - 0.20 acc - 0.695 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1722: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 47 train_loss - 0.20 acc - 0.697 auc - 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2178: 100%|██████████| 193/193 [01:31<00:00,  2.11it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 48 train_loss - 0.20 acc - 0.695 auc - 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2125: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 49 train_loss - 0.20 acc - 0.697 auc - 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2048: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 50 train_loss - 0.20 acc - 0.696 auc - 0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:46<00:00,  1.21s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 50 eval_loss - 0.59 eval acc - 0.686 eval auc - 0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1990: 100%|██████████| 193/193 [01:28<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 51 train_loss - 0.20 acc - 0.697 auc - 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1933: 100%|██████████| 193/193 [01:31<00:00,  2.12it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 52 train_loss - 0.20 acc - 0.697 auc - 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1751: 100%|██████████| 193/193 [01:26<00:00,  2.24it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 53 train_loss - 0.20 acc - 0.698 auc - 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1883: 100%|██████████| 193/193 [01:28<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 54 train_loss - 0.20 acc - 0.697 auc - 0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2096: 100%|██████████| 193/193 [01:26<00:00,  2.23it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 55 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1927: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 56 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2086: 100%|██████████| 193/193 [01:29<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 57 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1819: 100%|██████████| 193/193 [01:29<00:00,  2.16it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 58 train_loss - 0.20 acc - 0.698 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2066: 100%|██████████| 193/193 [01:26<00:00,  2.24it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 59 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1929: 100%|██████████| 193/193 [01:26<00:00,  2.22it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 60 train_loss - 0.20 acc - 0.698 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:40<00:00,  1.20s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 60 eval_loss - 0.58 eval acc - 0.690 eval auc - 0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1927: 100%|██████████| 193/193 [01:29<00:00,  2.16it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 61 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2060: 100%|██████████| 193/193 [01:26<00:00,  2.24it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 62 train_loss - 0.20 acc - 0.698 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1967: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 63 train_loss - 0.20 acc - 0.699 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2175: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 64 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2173: 100%|██████████| 193/193 [01:33<00:00,  2.07it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 65 train_loss - 0.20 acc - 0.699 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2076: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 66 train_loss - 0.20 acc - 0.698 auc - 0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1689: 100%|██████████| 193/193 [01:28<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 67 train_loss - 0.20 acc - 0.700 auc - 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1948: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 68 train_loss - 0.20 acc - 0.701 auc - 0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1978: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 69 train_loss - 0.20 acc - 0.700 auc - 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2096: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 70 train_loss - 0.20 acc - 0.699 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:40<00:00,  1.20s/it]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 70 eval_loss - 0.58 eval acc - 0.690 eval auc - 0.760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1810: 100%|██████████| 193/193 [01:28<00:00,  2.17it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 71 train_loss - 0.20 acc - 0.700 auc - 0.770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2038: 100%|██████████| 193/193 [01:31<00:00,  2.12it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 72 train_loss - 0.20 acc - 0.698 auc - 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2113: 100%|██████████| 193/193 [01:26<00:00,  2.23it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 73 train_loss - 0.20 acc - 0.699 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1940: 100%|██████████| 193/193 [01:27<00:00,  2.19it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 74 train_loss - 0.20 acc - 0.699 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1766: 100%|██████████| 193/193 [01:26<00:00,  2.23it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 75 train_loss - 0.20 acc - 0.700 auc - 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1938: 100%|██████████| 193/193 [01:27<00:00,  2.21it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 76 train_loss - 0.20 acc - 0.700 auc - 0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1970: 100%|██████████| 193/193 [01:28<00:00,  2.18it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 77 train_loss - 0.20 acc - 0.700 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.2047: 100%|██████████| 193/193 [01:33<00:00,  2.06it/s]\n",
      "  0%|          | 0/193 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 78 train_loss - 0.20 acc - 0.699 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss - 0.1945: 100%|██████████| 193/193 [01:27<00:00,  2.20it/s]\n",
      "  0%|          | 0/385 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 79 train_loss - 0.20 acc - 0.700 auc - 0.768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 385/385 [07:39<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 79 eval_loss - 0.58 eval acc - 0.690 eval auc - 0.760\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "best_auc = 0.0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss, acc, auc = train_epoch(model, dataloader, optimizer, criterion, device)\n",
    "    print(\"epoch - {} train_loss - {:.2f} acc - {:.3f} auc - {:.3f}\".format(epoch, loss, acc, auc))\n",
    "    \n",
    "    if epoch %10 == 0 or epoch == 79:\n",
    "        eval_loss, eval_acc, eval_auc = evaluate_epoch(model, test_dataloader, criterion, device)\n",
    "        print(\"epoch - {} eval_loss - {:.2f} eval acc - {:.3f} eval auc - {:.3f}\".format(epoch, eval_loss, eval_acc, eval_auc))\n",
    "        if best_auc < eval_auc: \n",
    "            best_auc = eval_auc\n",
    "            torch.save(model.state_dict(),'best_model.pt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 13.999749,
     "end_time": "2020-12-17T11:45:38.066811",
     "exception": false,
     "start_time": "2020-12-17T11:45:24.067062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:46:07.599646Z",
     "iopub.status.busy": "2020-12-17T11:46:07.598758Z",
     "iopub.status.idle": "2020-12-17T11:46:07.602335Z",
     "shell.execute_reply": "2020-12-17T11:46:07.602924Z"
    },
    "papermill": {
     "duration": 14.022931,
     "end_time": "2020-12-17T11:46:07.603107",
     "exception": false,
     "start_time": "2020-12-17T11:45:53.580176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del dataset\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 14.257091,
     "end_time": "2020-12-17T11:46:35.810728",
     "exception": false,
     "start_time": "2020-12-17T11:46:21.553637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:47:05.271450Z",
     "iopub.status.busy": "2020-12-17T11:47:05.270352Z",
     "iopub.status.idle": "2020-12-17T11:47:05.274114Z",
     "shell.execute_reply": "2020-12-17T11:47:05.273413Z"
    },
    "papermill": {
     "duration": 14.88804,
     "end_time": "2020-12-17T11:47:05.274247",
     "exception": false,
     "start_time": "2020-12-17T11:46:50.386207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, samples, test_df, n_skill, n_ela_skill,n_part_skill,max_seq=MAX_SEQ): #HDKIM 100\n",
    "        super(TestDataset, self).__init__()\n",
    "        self.samples = samples\n",
    "        self.user_ids = [x for x in test_df[\"user_id\"].unique()]\n",
    "        self.test_df = test_df\n",
    "        self.n_ela_skill = n_ela_skill\n",
    "        self.n_part_skill = n_part_skill\n",
    "        self.n_skill = n_skill\n",
    "        self.max_seq = max_seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.test_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        test_info = self.test_df.iloc[index]\n",
    "\n",
    "        user_id = test_info[\"user_id\"]\n",
    "        target_id = test_info[\"content_id\"]\n",
    "        ela_target_id = test_info[\"prior_question_elapsed_time\"]\n",
    "        part_target_id = test_info[\"part\"]\n",
    "        com_target_id = test_info[\"community\"]\n",
    "\n",
    "        q = np.ones(self.max_seq, dtype=int)*13523\n",
    "        qa = np.zeros(self.max_seq, dtype=int)\n",
    "        ela = np.ones(self.max_seq, dtype=int)*301\n",
    "        part = np.ones(self.max_seq, dtype=int)*7\n",
    "        com = np.ones(self.max_seq, dtype=int)*4\n",
    "\n",
    "        if user_id in self.samples.index:\n",
    "#             print(\"self.samples[user_id] is:{}\\n length is:{}\".format(\n",
    "#                 self.samples[user_id], len(self.samples[user_id])))\n",
    "            q_, qa_, ela_,part_,com_ = self.samples[user_id]\n",
    "            seq_len = len(q_)\n",
    "\n",
    "            if seq_len >= self.max_seq:\n",
    "                q = q_[-self.max_seq:]\n",
    "                qa = qa_[-self.max_seq:]\n",
    "                ela = ela_[-self.max_seq:]\n",
    "                part = part_[-self.max_seq:]\n",
    "                com = com_[-self.max_seq:]\n",
    "\n",
    "            else:\n",
    "                q[-seq_len:] = q_\n",
    "                qa[-seq_len:] = qa_          \n",
    "                ela[-seq_len:] = ela_\n",
    "                part[-seq_len:] = part_\n",
    "                com[-seq_len:] = com_\n",
    "\n",
    "                \n",
    "        x = np.ones(self.max_seq-1, dtype=int)*13523\n",
    "        x = q[1:].copy()\n",
    "#         x += (qa[1:] == 1) * self.n_skill\n",
    "        \n",
    "        questions = np.append(q[2:], [target_id])\n",
    "        \n",
    "        ela_x = np.ones(self.max_seq-1, dtype=int)*301\n",
    "        ela_x = ela[1:].copy()\n",
    "#         ela_x += (qa[1:] == 1) * self.n_ela_skill\n",
    "        \n",
    "        ela_target = np.append(ela[2:],[ela_target_id])  \n",
    "        \n",
    "        part_x = np.ones(self.max_seq-1, dtype=int)*7\n",
    "        part_x = part[1:].copy()\n",
    "        \n",
    "        part_target = np.append(part[2:],[part_target_id])     \n",
    "        \n",
    "        com_x = np.ones(self.max_seq-1, dtype=int)*4\n",
    "        com_x = com[1:].copy()\n",
    "        \n",
    "        com_target = np.append(com[2:],[com_target_id])        \n",
    "        \n",
    "        ans_x = np.zeros(self.max_seq-1, dtype=int)\n",
    "        ans_x = qa[1:].copy()\n",
    "        return torch.LongTensor(x), torch.LongTensor(questions),\\\n",
    "            torch.LongTensor(ela_x), torch.LongTensor(ela_target),\\\n",
    "            torch.LongTensor(part_x), torch.LongTensor(part_target),\\\n",
    "            torch.LongTensor(com_x), torch.LongTensor(com_target),\\\n",
    "            torch.LongTensor(ans_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:47:33.489912Z",
     "iopub.status.busy": "2020-12-17T11:47:33.488993Z",
     "iopub.status.idle": "2020-12-17T11:47:33.588533Z",
     "shell.execute_reply": "2020-12-17T11:47:33.589120Z"
    },
    "papermill": {
     "duration": 14.540403,
     "end_time": "2020-12-17T11:47:33.589269",
     "exception": false,
     "start_time": "2020-12-17T11:47:19.048866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKTModel(\n",
       "  (embedding): Embedding(27049, 128)\n",
       "  (pos_embedding): Embedding(159, 128)\n",
       "  (e_embedding): Embedding(13525, 128)\n",
       "  (ela_ans_embedding): Embedding(605, 128)\n",
       "  (ela_embedding): Embedding(303, 128)\n",
       "  (part_embedding): Embedding(9, 128)\n",
       "  (com_embedding): Embedding(6, 128)\n",
       "  (ans_embedding): Embedding(2, 128)\n",
       "  (multi_att): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (layer_normal): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (ffn): FFN(\n",
       "    (lr1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (lr2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pred): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SAKTModel(n_skill+1,n_ela_skill+1,n_part_skill+1,n_com_skill,embed_dim=128)\n",
    "model.load_state_dict(torch.load('best_model.pt',map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-17T11:48:02.478451Z",
     "iopub.status.busy": "2020-12-17T11:48:02.477624Z",
     "iopub.status.idle": "2020-12-17T11:48:03.344526Z",
     "shell.execute_reply": "2020-12-17T11:48:03.343889Z"
    },
    "papermill": {
     "duration": 15.659534,
     "end_time": "2020-12-17T11:48:03.344701",
     "exception": false,
     "start_time": "2020-12-17T11:47:47.685167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 60.50it/s]\n",
      "1it [00:00,  8.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 41.23it/s]\n",
      "2it [00:00,  8.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 51.98it/s]\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.1\n",
      "31.1\n",
      "31.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 35.86it/s]\n",
      "4it [00:00,  4.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import riiideducation\n",
    "\n",
    "env = riiideducation.make_env()\n",
    "iter_test = env.iter_test()\n",
    "import psutil\n",
    "model.eval()\n",
    "\n",
    "#HDKIM\n",
    "prev_test_df = None\n",
    "#HDKIMHDKIM\n",
    "\n",
    "for (test_df, sample_prediction_df) in tqdm(iter_test):\n",
    "    #HDKIM\n",
    "    if (prev_test_df is not None) & (psutil.virtual_memory().percent<90):\n",
    "        print(psutil.virtual_memory().percent)\n",
    "        prev_test_df['answered_correctly'] = eval(test_df['prior_group_answers_correct'].iloc[0])\n",
    "        prev_test_df = prev_test_df[prev_test_df.content_type_id == False]\n",
    "        prev_group = prev_test_df[['user_id', 'part','content_id','community','answered_correctly','prior_question_elapsed_time']].groupby('user_id').apply(lambda r: (\n",
    "            r['content_id'].values,\n",
    "            r['answered_correctly'].values,\n",
    "            r['prior_question_elapsed_time'].values,\n",
    "            r['part'].values,\n",
    "            r['community'].values))\n",
    "        for prev_user_id in prev_group.index:\n",
    "            prev_group_content = prev_group[prev_user_id][0]\n",
    "            prev_group_ac = prev_group[prev_user_id][1]\n",
    "            prev_group_ela = prev_group[prev_user_id][2]\n",
    "            prev_group_part = prev_group[prev_user_id][3]\n",
    "            prev_group_com = prev_group[prev_user_id][4]\n",
    "\n",
    "            if prev_user_id in group.index:\n",
    "                group[prev_user_id] = (np.append(group[prev_user_id][0],prev_group_content), \n",
    "                                       np.append(group[prev_user_id][1],prev_group_ac),\n",
    "                                       np.append(group[prev_user_id][2],prev_group_ela),\n",
    "                                       np.append(group[prev_user_id][3],prev_group_part),\n",
    "                                       np.append(group[prev_user_id][4],prev_group_com))\n",
    " \n",
    "            else:\n",
    "                group[prev_user_id] = (prev_group_content,prev_group_ac, prev_group_ela,prev_group_part,prev_group_com)\n",
    "            if len(group[prev_user_id][0])>MAX_SEQ:\n",
    "                new_group_content = group[prev_user_id][0][-MAX_SEQ:]\n",
    "                new_group_ac = group[prev_user_id][1][-MAX_SEQ:]\n",
    "                new_group_ela = group[prev_user_id][2][-MAX_SEQ:]\n",
    "                new_group_part = group[prev_user_id][3][-MAX_SEQ:]\n",
    "                new_group_com = group[prev_user_id][4][-MAX_SEQ:]\n",
    "\n",
    "                group[prev_user_id] = (new_group_content,new_group_ac,new_group_ela,new_group_part,new_group_com)\n",
    "\n",
    "    test_df['prior_question_elapsed_time'].fillna(elapsed_mean, inplace=True)\n",
    "    test_df['prior_question_elapsed_time'] = test_df['prior_question_elapsed_time'].apply(lambda x: get_elapsed_time(x))\n",
    "             \n",
    "    test_df = pd.merge(test_df, question_df, left_on='content_id',right_on='question_id',how='left')\n",
    "    prev_test_df = test_df.copy()\n",
    " \n",
    "    #HDKIMHDKIM\n",
    "    \n",
    "    test_df = test_df[test_df.content_type_id == False]\n",
    "   \n",
    "    test_dataset = TestDataset(group, test_df, n_skill, n_ela_skill, n_part_skill)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=51200, \n",
    "                                 shuffle=False)\n",
    "    \n",
    "    outs = []\n",
    "\n",
    "    for item in tqdm(test_dataloader):\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        ela_x = item[2].to(device).long()\n",
    "        ela_target = item[3].to(device).long()\n",
    "        part_x = item[4].to(device).long()\n",
    "        part_target = item[5].to(device).long()  \n",
    "        com_x = item[6].to(device).long()\n",
    "        com_target = item[7].to(device).long() \n",
    "        \n",
    "        ans_x = item[8].to(device).long()  \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, att_weight = model(x, target_id,ela_x, ela_target,\n",
    "                                       part_x, part_target,com_x, com_target,ans_x)\n",
    "        \n",
    "        \n",
    "        output = torch.sigmoid(output)\n",
    "        output = output[:, -1]\n",
    "\n",
    "        # pred = (output >= 0.5).long()\n",
    "        # loss = criterion(output, label)\n",
    "\n",
    "        # val_loss.append(loss.item())\n",
    "        # num_corrects += (pred == label).sum().item()\n",
    "        # num_total += len(label)\n",
    "\n",
    "        # labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "        \n",
    "    test_df['answered_correctly'] =  outs\n",
    "    \n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 13.693318,
     "end_time": "2020-12-17T11:48:30.972971",
     "exception": false,
     "start_time": "2020-12-17T11:48:17.279653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SAKTDataset(Dataset):\n",
    "    def __init__(self, group, n_skill,n_ela_skill, max_seq=MAX_SEQ): #HDKIM 100\n",
    "        super(SAKTDataset, self).__init__()\n",
    "        self.max_seq = max_seq\n",
    "        self.n_skill = n_skill\n",
    "        self.n_ela_skill = n_ela_skill\n",
    "        self.samples = group\n",
    "        \n",
    "#         self.user_ids = [x for x in group.index]\n",
    "        self.user_ids = []\n",
    "    \n",
    "    \n",
    "        self.que = []\n",
    "        self.que_target = []\n",
    "        self.ela = []\n",
    "        self.ela_target = []\n",
    "        self.part = []\n",
    "        self.part_target = []\n",
    "        self.ans = []\n",
    "        self.label = []\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        for user_id in group.index:\n",
    "            q_, qa_,ela_,part_ = group[user_id]\n",
    "            if len(q_) < 2: #HDKIM 10\n",
    "                continue\n",
    "            self.user_ids.append(user_id)\n",
    "          \n",
    "            seq_len = min(self.max_seq, len(q_))\n",
    "            if seq_len > 2:\n",
    "                q = np.ones(self.max_seq, dtype=int)*13523\n",
    "                qa = np.zeros(self.max_seq, dtype=int)\n",
    "                ela = np.ones(self.max_seq, dtype=int)*301\n",
    "                part = np.ones(self.max_seq, dtype=int)*7             \n",
    "                \n",
    "                for i in range(2, seq_len):\n",
    "                    q[-i:] = q_[-i:].copy()\n",
    "                    qa[-i:] = qa_[-i:].copy()\n",
    "                    ela[-i:] = ela_[-i:].copy()\n",
    "                    part[-i:] = part_[-i:].copy()\n",
    "                    \n",
    "                    \n",
    "                    que_target = q[1:]\n",
    "                    label = qa[-1]\n",
    "                    ela_target = ela[1:]\n",
    "                    part_target = part[1:]\n",
    " \n",
    "                    x = np.ones(self.max_seq-1, dtype=int)*13523\n",
    "                    x = q[:-1].copy()\n",
    "        \n",
    "                    ela_x = np.ones(self.max_seq-1, dtype=int)*301\n",
    "                    ela_x = ela[:-1].copy()\n",
    "        \n",
    "                    part_x = np.ones(self.max_seq-1, dtype=int)*7\n",
    "                    part_x = part[:-1].copy()        \n",
    "        \n",
    "                    ans_x = np.zeros(self.max_seq-1, dtype=int)\n",
    "                    ans_x = qa[:-1].copy()\n",
    "\n",
    "                    self.que.append(x)\n",
    "                    self.que_target.append(que_target)\n",
    "                    self.ela.append(ela_x)\n",
    "                    self.ela_target.append(ela_target)\n",
    "                    self.part.append(part_x)\n",
    "                    self.part_target.append(part_target)\n",
    "                    self.ans.append(ans_x)\n",
    "                    self.label.append(np.array([label]))\n",
    "                    \n",
    "                    \n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.que[index], self.que_target[index], self.ela[index], self.ela_target[index], \\\n",
    "                self.part[index], self.part_target[index], self.ans[index], self.label[index]\n",
    "        \n",
    "#                    return x, target_id,ela_x,ela_target,part_x,part_target,com_x,com_target,ans_x,label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_iterator, optim, criterion, device=\"cpu\"):\n",
    "    model.train()\n",
    "\n",
    "    train_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "\n",
    "    tbar = tqdm(train_iterator)\n",
    "    for item in tbar:\n",
    "        x = item[0].to(device).long()\n",
    "        target_id = item[1].to(device).long()\n",
    "        ela_x = item[2].to(device).long()\n",
    "        ela_target = item[3].to(device).long()\n",
    "        part_x = item[4].to(device).long()\n",
    "        part_target = item[5].to(device).long()\n",
    "          \n",
    "            \n",
    "        ans_x = item[6].to(device).long()\n",
    "        label = item[7].to(device).float()        \n",
    "        \n",
    "        optim.zero_grad()\n",
    "        output, atten_weight = model(x, target_id, ela_x, ela_target,\n",
    "                                     part_x, part_target,ans_x)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "#         xm.mark_step()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        output = output[:, -1]\n",
    "        label = label[:, -1] \n",
    "        pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "        \n",
    "        num_corrects += (pred == label).sum().item()\n",
    "        num_total += len(label)\n",
    "\n",
    "        labels.extend(label.view(-1).data.cpu().numpy())\n",
    "        outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "        tbar.set_description('loss - {:.4f}'.format(loss))\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "    loss = np.mean(train_loss)\n",
    "\n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, test_dataloader, criterion, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    eval_loss = []\n",
    "    num_corrects = 0\n",
    "    num_total = 0\n",
    "    labels = []\n",
    "    outs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(test_dataloader):\n",
    "            x = item[0].to(device).long()\n",
    "            target_id = item[1].to(device).long()\n",
    "            ela_x = item[2].to(device).long()\n",
    "            ela_target = item[3].to(device).long()\n",
    "            part_x = item[4].to(device).long()\n",
    "            part_target = item[5].to(device).long()\n",
    "        \n",
    "            \n",
    "            ans_x = item[6].to(device).long()\n",
    "            label = item[7].to(device).float()\n",
    "#             print(\"In evaluation x shape is:{}\\t taret_id shape is:{}\\t label shape is:{}\".format(x.shape, target_id.shape,label.shape))\n",
    "            \n",
    "            output, atten_weight = model(x, target_id, ela_x, ela_target,\n",
    "                                         part_x, part_target, ans_x)\n",
    "            \n",
    "            output_loss = output[:, -1:]\n",
    "#             print(\"Output shape is:{}\\tlabel shape is:{}\".format(output.shape, label.shape))\n",
    "            loss = criterion(output_loss, label)\n",
    "            eval_loss.append(loss.item())\n",
    "            \n",
    "            output = output[:,-1]\n",
    "            label = label[:, -1] \n",
    "            pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "            \n",
    "            num_corrects += (pred == label).sum().item()\n",
    "            num_total += len(label)\n",
    "\n",
    "            labels.extend(label.view(-1).data.cpu().numpy())\n",
    "            outs.extend(output.view(-1).data.cpu().numpy())\n",
    "\n",
    "    acc = num_corrects / num_total\n",
    "#     print(\"In evaluate labels is:{}\\t outs is:{}\\t\".format(labels, outs))\n",
    "\n",
    "    auc = roc_auc_score(labels, outs)\n",
    "#     auc = 0\n",
    "\n",
    "    loss = np.mean(eval_loss)   \n",
    "    \n",
    "    return loss, acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(logits, targets, weights, average = \"batch\", label_smoothing=0.0):\n",
    "    # shape : (batch * sequence_length, num_classes)\n",
    "    logits_flat = logits.view(-1, logits.size(-1))\n",
    "    # shape : (batch * sequence_length, num_classes)\n",
    "    log_probs_flat = torch.nn.functional.log_softmax(logits_flat, dim=-1)\n",
    "    # shape : (batch * max_len, 1)\n",
    "    targets_flat = targets.view(-1, 1).long()    \n",
    "    \n",
    "    if label_smoothing is not None and label_smoothing > 0.0:\n",
    "        num_classes = logits.size(-1)\n",
    "        smoothing_value = label_smoothing / num_classes\n",
    "        # Fill all the correct indices with 1 - smoothing value.\n",
    "        one_hot_targets = torch.zeros_like(log_probs_flat).scatter_(-1, targets_flat, 1.0 - label_smoothing)\n",
    "        smoothed_targets = one_hot_targets + smoothing_value\n",
    "        negative_log_likelihood_flat = - log_probs_flat * smoothed_targets\n",
    "        negative_log_likelihood_flat = negative_log_likelihood_flat.sum(-1, keepdim=True)\n",
    "    else:\n",
    "        # Contribution to the negative log likelihood only comes from the exact indices\n",
    "        # of the targets, as the target distributions are one-hot. Here we use torch.gather\n",
    "        # to extract the indices of the num_classes dimension which contribute to the loss.\n",
    "        # shape : (batch * sequence_length, 1)\n",
    "        negative_log_likelihood_flat = - torch.gather(log_probs_flat, dim=1, index=targets_flat)    \n",
    "    \n",
    "    negative_log_likelihood = negative_log_likelihood_flat.view(*targets.size())\n",
    "    # shape : (batch, sequence_length)\n",
    "    negative_log_likelihood = negative_log_likelihood * weights.float()\n",
    "\n",
    "    if average == \"batch\":\n",
    "        # shape : (batch_size,)\n",
    "        per_batch_loss = negative_log_likelihood.sum(1) / (weights.sum(1).float() + 1e-13)\n",
    "        num_non_empty_sequences = ((weights.sum(1) > 0).float().sum() + 1e-13)\n",
    "        return per_batch_loss.sum() / num_non_empty_sequences\n",
    "    elif average == \"token\":\n",
    "        return negative_log_likelihood.sum() / (weights.sum().float() + 1e-13)\n",
    "    else:\n",
    "        # shape : (batch_size,)\n",
    "        per_batch_loss = negative_log_likelihood.sum(1) / (weights.sum(1).float() + 1e-13)\n",
    "        return per_batch_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = torch.randn(2,2,2)\n",
    "targets = torch.tensor([[1,1],[0,1]])\n",
    "weights = torch.tensor([[1,1],[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = get_loss(logits, targets, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3516)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3555, -1.2359],\n",
       "         [ 0.7282, -0.1598]],\n",
       "\n",
       "        [[ 0.4028, -1.2155],\n",
       "         [ 0.2987, -0.5407]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [0, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = F.softmax(logits, dim=-1).view([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8308, 0.1692],\n",
       "         [0.7085, 0.2915]],\n",
       "\n",
       "        [[0.8346, 0.1654],\n",
       "         [0.6983, 0.3017]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs2 = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8308, 0.1692],\n",
       "         [0.7085, 0.2915]],\n",
       "\n",
       "        [[0.8346, 0.1654],\n",
       "         [0.6983, 0.3017]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_probs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vals = torch.max(class_probs2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[0.8308, 0.7085],\n",
       "        [0.8346, 0.6983]]),\n",
       "indices=tensor([[0, 0],\n",
       "        [0, 0]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = max_vals[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0], [0, 0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-9ba62ec50533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "duration": 11765.151837,
   "end_time": "2020-12-17T11:48:46.620846",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-17T08:32:41.469009",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
