{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:09.674345Z",
     "iopub.status.busy": "2020-11-24T15:32:09.673336Z",
     "iopub.status.idle": "2020-11-24T15:32:09.683389Z",
     "shell.execute_reply": "2020-11-24T15:32:09.683971Z"
    },
    "papermill": {
     "duration": 0.047569,
     "end_time": "2020-11-24T15:32:09.684155",
     "exception": false,
     "start_time": "2020-11-24T15:32:09.636586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "env = riiideducation.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:09.754693Z",
     "iopub.status.busy": "2020-11-24T15:32:09.753824Z",
     "iopub.status.idle": "2020-11-24T15:32:12.277030Z",
     "shell.execute_reply": "2020-11-24T15:32:12.275476Z"
    },
    "papermill": {
     "duration": 2.559966,
     "end_time": "2020-11-24T15:32:12.277160",
     "exception": false,
     "start_time": "2020-11-24T15:32:09.717194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from itertools import repeat, chain, islice\n",
    "from torch.utils import data\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.029671,
     "end_time": "2020-11-24T15:32:12.337364",
     "exception": false,
     "start_time": "2020-11-24T15:32:12.307693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ARGS参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:12.794156Z",
     "iopub.status.busy": "2020-11-24T15:32:12.793300Z",
     "iopub.status.idle": "2020-11-24T15:32:12.807157Z",
     "shell.execute_reply": "2020-11-24T15:32:12.808112Z"
    },
    "papermill": {
     "duration": 0.440314,
     "end_time": "2020-11-24T15:32:12.808298",
     "exception": false,
     "start_time": "2020-11-24T15:32:12.367984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    name = 'train'\n",
    "    model = 'SAKT'\n",
    "    num_layers = 1\n",
    "    hidden_dim=100\n",
    "    input_dim = 100\n",
    "    dropout = 0.2\n",
    "    num_head = 5\n",
    "    \n",
    "    random_seed = 1\n",
    "    num_epochs = 1\n",
    "    lr = 0.01\n",
    "    seq_size = 40\n",
    "    warm_up_step_count = 4000\n",
    "    eval_steps = 500\n",
    "    train_steps = 500\n",
    "    train_batch=128\n",
    "    num_workers=1\n",
    "    \n",
    "    \n",
    "ARGS = Args()\n",
    "ARGS.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:12.923771Z",
     "iopub.status.busy": "2020-11-24T15:32:12.921283Z",
     "iopub.status.idle": "2020-11-24T15:32:12.925036Z",
     "shell.execute_reply": "2020-11-24T15:32:12.922662Z"
    },
    "papermill": {
     "duration": 0.059187,
     "end_time": "2020-11-24T15:32:12.925213",
     "exception": false,
     "start_time": "2020-11-24T15:32:12.866026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "\n",
    "QUESTION_NUM = {\n",
    "    'riii':13523\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:13.045236Z",
     "iopub.status.busy": "2020-11-24T15:32:13.044122Z",
     "iopub.status.idle": "2020-11-24T15:32:13.047233Z",
     "shell.execute_reply": "2020-11-24T15:32:13.046246Z"
    },
    "papermill": {
     "duration": 0.0687,
     "end_time": "2020-11-24T15:32:13.047381",
     "exception": false,
     "start_time": "2020-11-24T15:32:12.978681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = '/kaggle/input/riiid-test-answer-prediction/train.csv'\n",
    "que_csv = '/kaggle/input/riiid-test-answer-prediction/questions.csv'\n",
    "train_pkl_path = '/kaggle/input/saktmodel/user_seq40_timestamp.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:13.172328Z",
     "iopub.status.busy": "2020-11-24T15:32:13.171340Z",
     "iopub.status.idle": "2020-11-24T15:32:14.336317Z",
     "shell.execute_reply": "2020-11-24T15:32:14.335171Z"
    },
    "papermill": {
     "duration": 1.223874,
     "end_time": "2020-11-24T15:32:14.336610",
     "exception": false,
     "start_time": "2020-11-24T15:32:13.112736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_pkl = pd.read_pickle(train_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:14.446196Z",
     "iopub.status.busy": "2020-11-24T15:32:14.441384Z",
     "iopub.status.idle": "2020-11-24T15:32:14.481466Z",
     "shell.execute_reply": "2020-11-24T15:32:14.482218Z"
    },
    "papermill": {
     "duration": 0.098259,
     "end_time": "2020-11-24T15:32:14.482422",
     "exception": false,
     "start_time": "2020-11-24T15:32:14.384163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id_seq</th>\n",
       "      <th>answered_correctly</th>\n",
       "      <th>timestamp_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>5693,5717,129,7861,7923,157,52,51,7897,7864,13...</td>\n",
       "      <td>1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,1,1,0,0,0,...</td>\n",
       "      <td>0,56943,118363,131167,137965,157063,176092,194...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124</td>\n",
       "      <td>7901,21400,176,14802,2066,15588,15587,16888,16...</td>\n",
       "      <td>1,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0</td>\n",
       "      <td>0,32683,62000,83632,189483,189483,189483,25879...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2746</td>\n",
       "      <td>18797,14282,19500,237,13928,383,406,874,532,14...</td>\n",
       "      <td>0,0,0,1,0,1,1,1,1,0,1,1,0</td>\n",
       "      <td>0,21592,49069,72254,91945,111621,134341,234605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5382</td>\n",
       "      <td>997,902,262,447,380,829,452,6439,18863,5413,91...</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,1,0,1,0,...</td>\n",
       "      <td>389881333,389964165,390022375,390096159,390240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8623</td>\n",
       "      <td>13585,19,10596,21488,7914,195,23929,7975,131,7...</td>\n",
       "      <td>0,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,0,0,0,0,1,0,1,...</td>\n",
       "      <td>405393099,405438225,405472251,405560264,405607...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8701</td>\n",
       "      <td>3902,6672,4964,19667,8280,17488,17526,14278,11...</td>\n",
       "      <td>1,1,1,0,1,0,0,0,1,0,0</td>\n",
       "      <td>0,17833,45872,74561,121601,141679,183773,11482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12741</td>\n",
       "      <td>24224,10699,10700,16152,2627,2628,24250,10726,...</td>\n",
       "      <td>0,1,1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,0,1,1,1,1,1,...</td>\n",
       "      <td>4461666848,4461666848,4461666848,4461969611,44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13134</td>\n",
       "      <td>3116,3350,3349,3351,13063,13064,13062,3178,167...</td>\n",
       "      <td>1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,...</td>\n",
       "      <td>17787213345,17787349676,17787349676,1778734967...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24418</td>\n",
       "      <td>5045,8247,5736,17300,3777,6136,5620,4128,9128,...</td>\n",
       "      <td>1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,...</td>\n",
       "      <td>13719934601,13719969208,13719994486,1372003782...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24600</td>\n",
       "      <td>15587,2066,15588,16888,16887,16889,16471,16472...</td>\n",
       "      <td>0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,...</td>\n",
       "      <td>148601,148601,148601,219354,219354,219354,2697...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                     content_id_seq  \\\n",
       "0      115  5693,5717,129,7861,7923,157,52,51,7897,7864,13...   \n",
       "1      124  7901,21400,176,14802,2066,15588,15587,16888,16...   \n",
       "2     2746  18797,14282,19500,237,13928,383,406,874,532,14...   \n",
       "3     5382  997,902,262,447,380,829,452,6439,18863,5413,91...   \n",
       "4     8623  13585,19,10596,21488,7914,195,23929,7975,131,7...   \n",
       "5     8701  3902,6672,4964,19667,8280,17488,17526,14278,11...   \n",
       "6    12741  24224,10699,10700,16152,2627,2628,24250,10726,...   \n",
       "7    13134  3116,3350,3349,3351,13063,13064,13062,3178,167...   \n",
       "8    24418  5045,8247,5736,17300,3777,6136,5620,4128,9128,...   \n",
       "9    24600  15587,2066,15588,16888,16887,16889,16471,16472...   \n",
       "\n",
       "                                  answered_correctly  \\\n",
       "0  1,1,1,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,1,1,0,0,0,...   \n",
       "1    1,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0,0,0,0   \n",
       "2                          0,0,0,1,0,1,1,1,1,0,1,1,0   \n",
       "3  1,1,1,1,1,1,1,1,0,1,1,0,1,0,1,1,1,0,0,1,0,1,0,...   \n",
       "4  0,1,1,0,1,1,0,1,1,1,0,1,1,0,1,1,0,0,0,0,1,0,1,...   \n",
       "5                              1,1,1,0,1,0,0,0,1,0,0   \n",
       "6  0,1,1,0,1,1,0,1,0,0,1,1,0,1,0,1,1,0,1,1,1,1,1,...   \n",
       "7  1,1,1,1,1,1,1,1,0,0,1,1,1,0,1,1,1,1,1,1,1,1,0,...   \n",
       "8  1,1,1,0,1,1,1,1,1,1,1,0,1,0,1,1,1,1,1,1,0,1,1,...   \n",
       "9  0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,...   \n",
       "\n",
       "                                       timestamp_seq  \n",
       "0  0,56943,118363,131167,137965,157063,176092,194...  \n",
       "1  0,32683,62000,83632,189483,189483,189483,25879...  \n",
       "2  0,21592,49069,72254,91945,111621,134341,234605...  \n",
       "3  389881333,389964165,390022375,390096159,390240...  \n",
       "4  405393099,405438225,405472251,405560264,405607...  \n",
       "5  0,17833,45872,74561,121601,141679,183773,11482...  \n",
       "6  4461666848,4461666848,4461666848,4461969611,44...  \n",
       "7  17787213345,17787349676,17787349676,1778734967...  \n",
       "8  13719934601,13719969208,13719994486,1372003782...  \n",
       "9  148601,148601,148601,219354,219354,219354,2697...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pkl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045731,
     "end_time": "2020-11-24T15:32:14.573130",
     "exception": false,
     "start_time": "2020-11-24T15:32:14.527399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:14.670017Z",
     "iopub.status.busy": "2020-11-24T15:32:14.668952Z",
     "iopub.status.idle": "2020-11-24T15:32:14.671796Z",
     "shell.execute_reply": "2020-11-24T15:32:14.670985Z"
    },
    "papermill": {
     "duration": 0.054958,
     "end_time": "2020-11-24T15:32:14.671937",
     "exception": false,
     "start_time": "2020-11-24T15:32:14.616979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# val_data = UserSepDataSet_Rii_Test(valid, user_dict2, is_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.043148,
     "end_time": "2020-11-24T15:32:14.758782",
     "exception": false,
     "start_time": "2020-11-24T15:32:14.715634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SAKT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045331,
     "end_time": "2020-11-24T15:32:14.849525",
     "exception": false,
     "start_time": "2020-11-24T15:32:14.804194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:14.953505Z",
     "iopub.status.busy": "2020-11-24T15:32:14.952516Z",
     "iopub.status.idle": "2020-11-24T15:32:14.956523Z",
     "shell.execute_reply": "2020-11-24T15:32:14.957203Z"
    },
    "papermill": {
     "duration": 0.062389,
     "end_time": "2020-11-24T15:32:14.957373",
     "exception": false,
     "start_time": "2020-11-24T15:32:14.894984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:15.059034Z",
     "iopub.status.busy": "2020-11-24T15:32:15.058142Z",
     "iopub.status.idle": "2020-11-24T15:32:15.063947Z",
     "shell.execute_reply": "2020-11-24T15:32:15.065132Z"
    },
    "papermill": {
     "duration": 0.062677,
     "end_time": "2020-11-24T15:32:15.065306",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.002629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:15.170707Z",
     "iopub.status.busy": "2020-11-24T15:32:15.169519Z",
     "iopub.status.idle": "2020-11-24T15:32:15.223667Z",
     "shell.execute_reply": "2020-11-24T15:32:15.224968Z"
    },
    "papermill": {
     "duration": 0.113436,
     "end_time": "2020-11-24T15:32:15.225179",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.111743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model, bias=False), 4) # Q, K, V, last\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "class SAKTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Encoder block of SAKT\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._self_attn = MultiHeadedAttention(num_head, hidden_dim, dropout)\n",
    "        self._ffn = PositionwiseFeedForward(hidden_dim, hidden_dim, dropout)\n",
    "        self._layernorms = clones(nn.LayerNorm(hidden_dim, eps=1e-6), 2)\n",
    "\n",
    "    def forward(self, query, key, mask=None):\n",
    "        \"\"\"\n",
    "        query: question embeddings\n",
    "        key: interaction embeddings\n",
    "        \"\"\"\n",
    "        # self-attention block\n",
    "        output = self._self_attn(query=query, key=key, value=key, mask=mask)\n",
    "        output = self._layernorms[0](key + output)\n",
    "        # feed-forward block\n",
    "        output = self._layernorms[1](output + self._ffn(output))\n",
    "        return output\n",
    "\n",
    "\n",
    "class SAKT(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based\n",
    "    all hidden dimensions (d_k, d_v, ...) are the same as hidden_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, question_num, num_layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._question_num = question_num\n",
    "        # question_num的值是110\n",
    "        # Blocks\n",
    "        self._layers = clones(SAKTLayer(hidden_dim, num_head, dropout), num_layers)\n",
    "\n",
    "        # prediction layer\n",
    "        self._prediction = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Embedding layers\n",
    "        self._positional_embedding = nn.Embedding(ARGS.seq_size+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        self._interaction_embedding = nn.Embedding(2*question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        # 这个就是包含了qid对错信息的矩阵\n",
    "        self._question_embedding = nn.Embedding(question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "\n",
    "    def _transform_interaction_to_question_id(self, interaction):\n",
    "        \"\"\"\n",
    "        get question_id from interaction index\n",
    "        if interaction index is a number in [0, question_num], then leave it as-is\n",
    "        if interaction index is bigger than question_num (in [question_num + 1, 2 * question_num]\n",
    "        then subtract question_num\n",
    "        interaction: integer tensor of shape (batch_size, sequence_size)\n",
    "        \"\"\"\n",
    "        return interaction - self._question_num * (interaction > self._question_num).long()\n",
    "\n",
    "    def _get_position_index(self, question_id):\n",
    "        \"\"\"\n",
    "        [0, 0, 0, 4, 12] -> [0, 0, 0, 1, 2]\n",
    "        \"\"\"\n",
    "        batch_size = question_id.shape[0]\n",
    "        position_indices = []\n",
    "        for i in range(batch_size):\n",
    "            non_padding_num = (question_id[i] != PAD_INDEX).sum(-1).item()\n",
    "            position_index = [0] * (ARGS.seq_size - non_padding_num) + list(range(1, non_padding_num+1))\n",
    "            position_indices.append(position_index)\n",
    "        return torch.tensor(position_indices, dtype=int).to(ARGS.device)\n",
    "\n",
    "    def forward(self, interaction_id, target_id):\n",
    "        \"\"\"\n",
    "        Query: Question (skill, exercise, ...) embedding\n",
    "        Key, Value: Interaction embedding + positional embedding\n",
    "        \"\"\"\n",
    "        question_id = self._transform_interaction_to_question_id(interaction_id)\n",
    "        # 这个question_id就是把以前把统一qid由于对错不同对应不同id，转换成同一qid\n",
    "        # 也就是把qid数值大于q_num的，减去q_num\n",
    "        question_id = torch.cat([question_id[:, 1:], target_id], dim=-1)\n",
    "        # question_id的原来的维度是(batch, seq_len)，\n",
    "        # 然后那两个:，第一个表示在第一个维度全选\n",
    "        # 第二个1:，表示第二个维度从第一个元素选起，这主要是为了和target_id合并在一起\n",
    "\n",
    "        # 这时question_id和interaction_id存在着一个错位的问题，\n",
    "        # 也就是question_id包含了当前target_id,而interaction_id中不包含\n",
    "\n",
    "        interaction_vector = self._interaction_embedding(interaction_id)\n",
    "        question_vector = self._question_embedding(question_id)\n",
    "\n",
    "        position_index = self._get_position_index(question_id)\n",
    "        # 对于question_id获取position的下标\n",
    "        position_vector = self._positional_embedding(position_index)\n",
    "\n",
    "        mask = get_pad_mask(question_id, PAD_INDEX) & get_subsequent_mask(question_id)\n",
    "        x = interaction_vector + position_vector\n",
    "        # 这个position_vector只加给了interaction_vector向量\n",
    "        # x的维度是(batch, seq_len, hidden)\n",
    "        for layer in self._layers:\n",
    "            x = layer(query=question_vector, key=x, mask=mask)\n",
    "\n",
    "        output = self._prediction(x)\n",
    "        # 这里的output为什么会是一个三维的向量呢\n",
    "        output = output[:, -1, :]\n",
    "        # output的最初维度是(batch, seq_len, 1)\n",
    "        # 然后用[:,-1,:]只取seq_len的最后一个值\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:15.329774Z",
     "iopub.status.busy": "2020-11-24T15:32:15.328783Z",
     "iopub.status.idle": "2020-11-24T15:32:15.336987Z",
     "shell.execute_reply": "2020-11-24T15:32:15.338639Z"
    },
    "papermill": {
     "duration": 0.065529,
     "end_time": "2020-11-24T15:32:15.338828",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.273299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed_all(ARGS.random_seed)\n",
    "random.seed(ARGS.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:15.441156Z",
     "iopub.status.busy": "2020-11-24T15:32:15.440035Z",
     "iopub.status.idle": "2020-11-24T15:32:15.442868Z",
     "shell.execute_reply": "2020-11-24T15:32:15.442050Z"
    },
    "papermill": {
     "duration": 0.057134,
     "end_time": "2020-11-24T15:32:15.443017",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.385883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  model = SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "#                      ARGS.num_head, ARGS.dropout).to(ARGS.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.0484,
     "end_time": "2020-11-24T15:32:15.539414",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.491014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033573,
     "end_time": "2020-11-24T15:32:15.632521",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.598948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033298,
     "end_time": "2020-11-24T15:32:15.699459",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.666161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.033573,
     "end_time": "2020-11-24T15:32:15.766723",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.733150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:15.858008Z",
     "iopub.status.busy": "2020-11-24T15:32:15.855940Z",
     "iopub.status.idle": "2020-11-24T15:32:15.858909Z",
     "shell.execute_reply": "2020-11-24T15:32:15.859561Z"
    },
    "papermill": {
     "duration": 0.058859,
     "end_time": "2020-11-24T15:32:15.859739",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.800880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps\n",
    "        ])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "               (self.model_size ** (-0.5) *\n",
    "                min(step ** (-0.5), step * self.warmup ** (-1.5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:15.968742Z",
     "iopub.status.busy": "2020-11-24T15:32:15.942182Z",
     "iopub.status.idle": "2020-11-24T15:32:15.984701Z",
     "shell.execute_reply": "2020-11-24T15:32:15.984096Z"
    },
    "papermill": {
     "duration": 0.09106,
     "end_time": "2020-11-24T15:32:15.984840",
     "exception": false,
     "start_time": "2020-11-24T15:32:15.893780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoamOptimizer:\n",
    "    def __init__(self, model, lr, model_size, warmup):\n",
    "        self._adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self._opt = NoamOpt(\n",
    "            model_size=model_size, factor=1, warmup=warmup, optimizer=self._adam)\n",
    "\n",
    "    def step(self, loss):\n",
    "        self._opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self._opt.step()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, warm_up_step_count,\n",
    "                 d_model, num_epochs, weight_path, lr,\n",
    "                 train_data, val_data, test_data=None):\n",
    "        self._device = device\n",
    "        self._num_epochs = num_epochs\n",
    "        self._weight_path = weight_path\n",
    "\n",
    "        self._model = model\n",
    "        self._loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self._model.to(device)\n",
    "\n",
    "        self._train_data = train_data\n",
    "        self._val_data = val_data\n",
    "        self._test_data = test_data\n",
    "\n",
    "        self._opt = NoamOptimizer(model=model, lr=lr, model_size=d_model, warmup=warm_up_step_count)\n",
    "\n",
    "        self.step = 0\n",
    "        self._threshold = 0.5\n",
    "        self.max_step = 0\n",
    "        self.max_acc = 0.0\n",
    "        self.max_auc = 0.0\n",
    "\n",
    "        self.test_acc = 0.0\n",
    "        self.test_auc = 0.0\n",
    "\n",
    "    # train model and choose weight with max auc on validation dataset\n",
    "    def train(self):\n",
    "        train_gen = self._train_data\n",
    "        val_gen = self._val_data\n",
    "\n",
    "        # will train self._num_epochs copies of train data\n",
    "        to_train = chain.from_iterable(repeat(train_gen, self._num_epochs))\n",
    "        # consisting of total_steps batches\n",
    "        total_steps = len(train_gen) * self._num_epochs\n",
    "        print(\"total_steps:\",total_steps)\n",
    "\n",
    "        self.step = 0\n",
    "        while self.step < total_steps:\n",
    "            rem_steps = total_steps - self.step\n",
    "            num_steps = min(rem_steps, ARGS.train_steps)\n",
    "            self.step += num_steps\n",
    "\n",
    "            # take num_steps batches from to_train stream\n",
    "            train_batches = islice(to_train, num_steps)\n",
    "            # print(f'Step: {self.step}')\n",
    "#            print(f\"Current Training step is: {self.step}\")\n",
    "            self._train(train_batches, num_steps)\n",
    "            if self.step % ARGS.eval_steps == 0:\n",
    "                cur_weight = self._model.state_dict()\n",
    "#                 torch.save(cur_weight, f'{self._weight_path}{self.step}.pt')\n",
    "                self._test('Validation', val_gen)\n",
    "            # print(f'Current best weight: {self.max_step}.pt, best auc: {self.max_auc:.4f}')\n",
    "            # remove all weight file except {self.max_step}.pt\n",
    "                print(f\"Validation-- Best validaction acc is: {self.max_acc:.4f},\"\n",
    "                  f\"Best auc is:{self.max_auc:.4f}.\\n\")\n",
    "#             weight_list = os.listdir(self._weight_path)\n",
    "            # for w in weight_list:\n",
    "            #     if int(w[:-3]) != self.max_step:\n",
    "            #         os.unlink(f'{self._weight_path}{w}')\n",
    "        self._test('Validation', val_gen)\n",
    "    # get test results\n",
    "    def test(self, weight_num):\n",
    "        test_gen = data.DataLoader(\n",
    "            dataset=self._test_data, shuffle=False,\n",
    "            batch_size=ARGS.test_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "        # load best weight\n",
    "        if self.max_step != 0:\n",
    "            weight_num = self.max_step\n",
    "        weight_path = f'{ARGS.weight_path}{weight_num}.pt'\n",
    "        print(f'best weight: {weight_path}')\n",
    "        self._model.load_state_dict(torch.load(weight_path))\n",
    "        self._test('Test', test_gen)\n",
    "\n",
    "    def _forward(self, batch):\n",
    "#        batch = {k: t.to(self._device) for k, t in batch.items()}\n",
    "#        label = batch['label']  # shape: (batch_size, 1)\n",
    "\n",
    "#        output = self._model(batch['input'], batch['target_id'])\n",
    "\n",
    "        batch = tuple(t.to(self._device) for t in batch)\n",
    "        question_id, target_id, label = batch\n",
    "\n",
    "        output = self._model(question_id, target_id)\n",
    "        pred = (torch.sigmoid(output) >= self._threshold).long()  # shape: (batch_size, 1)\n",
    "        # 感觉这里的sigmoid加在output之前是不是会更好\n",
    "\n",
    "        return label, output, pred\n",
    "\n",
    "    def _get_loss(self, label, output):\n",
    "        # 这里的label我可以理解为是一个[0,1]序列，但是output却是上面_forward的output，不是一个（0，1）范围的值\n",
    "        # 是因为loss_fn里面有sigmoid\n",
    "        loss = self._loss_fn(output, label.float())\n",
    "        return loss.mean()\n",
    "\n",
    "    # takes iterator\n",
    "    def _train(self, batch_iter, num_batches):\n",
    "        start_time = time.time()\n",
    "        self._model.train()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        for batch in tqdm(batch_iter, total=num_batches):\n",
    "            label, out, pred = self._forward(batch)\n",
    "            train_loss = self._get_loss(label, out)\n",
    "            losses.append(train_loss.item())\n",
    "\n",
    "            self._opt.step(train_loss)\n",
    "\n",
    "            num_corrects += (pred == label).sum().item()\n",
    "            num_total += len(label)\n",
    "\n",
    "            labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "            outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / num_total\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        if self.step % ARGS.train_steps:\n",
    "            print(f\"Current Training step is: {self.step}\")\n",
    "            print(f'Training correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "            print(f'[Training]     time: {training_time:.2f}, loss: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "    # takes iterable\n",
    "    def _test(self, name, batches):\n",
    "        start_time = time.time()\n",
    "        self._model.eval()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(batches):\n",
    "                label, out, pred = self._forward(batch)\n",
    "                test_loss = self._get_loss(label, out)\n",
    "                losses.append(test_loss.item())\n",
    "\n",
    "                num_corrects += (pred == label).sum().item()\n",
    "                num_total += len(label)\n",
    "\n",
    "                labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "                outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / num_total\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        # training_time = time.time() - start_time\n",
    "\n",
    "        print(f'correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "        print(f' loss is: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "        if name == 'Validation':\n",
    "            if self.max_auc < auc:\n",
    "                self.max_auc = auc\n",
    "                self.max_acc = acc\n",
    "                self.max_step = self.step\n",
    "                torch.save(self._model.state_dict(), self._weight_path)\n",
    "\n",
    "        elif name == 'Test':\n",
    "            self.test_acc = acc\n",
    "            self.test_auc = auc\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.058417Z",
     "iopub.status.busy": "2020-11-24T15:32:16.057656Z",
     "iopub.status.idle": "2020-11-24T15:32:16.062205Z",
     "shell.execute_reply": "2020-11-24T15:32:16.062755Z"
    },
    "papermill": {
     "duration": 0.043702,
     "end_time": "2020-11-24T15:32:16.062919",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.019217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataloader = data.DataLoader(\n",
    "#             dataset=train_data, shuffle=True,\n",
    "#             batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "# valid_dataloader = data.DataLoader(\n",
    "#             dataset=val_data, shuffle=False,\n",
    "#             batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.134293Z",
     "iopub.status.busy": "2020-11-24T15:32:16.133387Z",
     "iopub.status.idle": "2020-11-24T15:32:16.136569Z",
     "shell.execute_reply": "2020-11-24T15:32:16.136045Z"
    },
    "papermill": {
     "duration": 0.039847,
     "end_time": "2020-11-24T15:32:16.136716",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.096869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.206887Z",
     "iopub.status.busy": "2020-11-24T15:32:16.206119Z",
     "iopub.status.idle": "2020-11-24T15:32:16.210624Z",
     "shell.execute_reply": "2020-11-24T15:32:16.210048Z"
    },
    "papermill": {
     "duration": 0.040908,
     "end_time": "2020-11-24T15:32:16.210741",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.169833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# del(train_data)\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.283321Z",
     "iopub.status.busy": "2020-11-24T15:32:16.281356Z",
     "iopub.status.idle": "2020-11-24T15:32:16.284140Z",
     "shell.execute_reply": "2020-11-24T15:32:16.284664Z"
    },
    "papermill": {
     "duration": 0.040277,
     "end_time": "2020-11-24T15:32:16.284789",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.244512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer = Trainer(model,ARGS.device, ARGS.warm_up_step_count,\n",
    "#                  ARGS.hidden_dim, ARGS.num_epochs, 'rid_model.pt',\n",
    "#                  ARGS.lr, train_dataloader, valid_dataloader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.365578Z",
     "iopub.status.busy": "2020-11-24T15:32:16.363620Z",
     "iopub.status.idle": "2020-11-24T15:32:16.366305Z",
     "shell.execute_reply": "2020-11-24T15:32:16.366832Z"
    },
    "papermill": {
     "duration": 0.04468,
     "end_time": "2020-11-24T15:32:16.366955",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.322275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.437408Z",
     "iopub.status.busy": "2020-11-24T15:32:16.436761Z",
     "iopub.status.idle": "2020-11-24T15:32:16.441209Z",
     "shell.execute_reply": "2020-11-24T15:32:16.440352Z"
    },
    "papermill": {
     "duration": 0.040807,
     "end_time": "2020-11-24T15:32:16.441329",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.400522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del(train_dataloader)\n",
    "# del(valid_dataloader)\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03305,
     "end_time": "2020-11-24T15:32:16.508975",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.475925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.583297Z",
     "iopub.status.busy": "2020-11-24T15:32:16.582667Z",
     "iopub.status.idle": "2020-11-24T15:32:16.589141Z",
     "shell.execute_reply": "2020-11-24T15:32:16.588350Z"
    },
    "papermill": {
     "duration": 0.046489,
     "end_time": "2020-11-24T15:32:16.589266",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.542777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:16.665060Z",
     "iopub.status.busy": "2020-11-24T15:32:16.664276Z",
     "iopub.status.idle": "2020-11-24T15:32:21.586062Z",
     "shell.execute_reply": "2020-11-24T15:32:21.585444Z"
    },
    "papermill": {
     "duration": 4.962816,
     "end_time": "2020-11-24T15:32:21.586191",
     "exception": false,
     "start_time": "2020-11-24T15:32:16.623375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKT(\n",
       "  (_layers): ModuleList(\n",
       "    (0): SAKTLayer(\n",
       "      (_self_attn): MultiHeadedAttention(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (2): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (3): Linear(in_features=100, out_features=100, bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_ffn): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (w_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_layernorms): ModuleList(\n",
       "        (0): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_prediction): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (_positional_embedding): Embedding(41, 100, padding_idx=0)\n",
       "  (_interaction_embedding): Embedding(27047, 100, padding_idx=0)\n",
       "  (_question_embedding): Embedding(13524, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)\n",
    "model.load_state_dict(torch.load('/kaggle/input/saktmodel/user_seq40_model.pt',map_location=ARGS.device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:21.665700Z",
     "iopub.status.busy": "2020-11-24T15:32:21.663555Z",
     "iopub.status.idle": "2020-11-24T15:32:21.666459Z",
     "shell.execute_reply": "2020-11-24T15:32:21.666993Z"
    },
    "papermill": {
     "duration": 0.04456,
     "end_time": "2020-11-24T15:32:21.667129",
     "exception": false,
     "start_time": "2020-11-24T15:32:21.622569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_test = env.iter_test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:21.747065Z",
     "iopub.status.busy": "2020-11-24T15:32:21.746213Z",
     "iopub.status.idle": "2020-11-24T15:32:21.750902Z",
     "shell.execute_reply": "2020-11-24T15:32:21.750276Z"
    },
    "papermill": {
     "duration": 0.047621,
     "end_time": "2020-11-24T15:32:21.751011",
     "exception": false,
     "start_time": "2020-11-24T15:32:21.703390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Rii_dataset(Dataset):\n",
    "    def __init__(self,df ):\n",
    "        self.df = df\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, index):\n",
    "        content_id_seq = torch.from_numpy(self.df.at[index,'content_id_seq_input'])\n",
    "        content_id_seq = content_id_seq.long()\n",
    "        return content_id_seq, torch.LongTensor([self.df.at[index,'content_id']])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:21.845788Z",
     "iopub.status.busy": "2020-11-24T15:32:21.837102Z",
     "iopub.status.idle": "2020-11-24T15:32:21.849533Z",
     "shell.execute_reply": "2020-11-24T15:32:21.849030Z"
    },
    "papermill": {
     "duration": 0.062723,
     "end_time": "2020-11-24T15:32:21.849678",
     "exception": false,
     "start_time": "2020-11-24T15:32:21.786955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_np(nums, ind):\n",
    "\n",
    "    nums = nums[:ind]\n",
    "    if nums.size == 0:\n",
    "        return np.array([0]*Args.seq_size)\n",
    "\n",
    "    if nums.size > Args.seq_size:\n",
    "        nums = nums[-Args.seq_size:]\n",
    "    else:\n",
    "        pad_counts = Args.seq_size - len(nums)\n",
    "        nums = np.pad(nums,(pad_counts,0),'constant',constant_values=(0,0))\n",
    "    return nums\n",
    "\n",
    "\n",
    "\n",
    "def get_index(row):\n",
    "    ind = np.searchsorted(row['timestamp_seq'],row['timestamp'])\n",
    "    return ind\n",
    "\n",
    "def pad_seq(df):\n",
    "    df['content_id'] = np.array(df['content_id'])\n",
    "\n",
    "    df['timestamp_seq'] = df['timestamp_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int64))\n",
    "    df['ind'] = df.apply(lambda x: get_index(x), axis=1)\n",
    "    \n",
    "    df['content_id_seq'] = df['content_id_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['content_id_seq_input'] = df.apply(lambda x: pad_np(x.content_id_seq, x.ind), axis=1)\n",
    "    \n",
    "    df['answered_correctly'] = df['answered_correctly'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['answered_correctly_input'] = df.apply(lambda x: pad_np(x.answered_correctly,x.ind), axis=1)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def pad_seq2(df):\n",
    "    df['content_id'] = np.array(df['content_id'])\n",
    "#     print(type(df['timestamp_seq'] ))\n",
    "#     df['timestamp_seq'] = df['timestamp_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int64))\n",
    "    df['index'] = df.apply(lambda x: get_index(x), axis=1)\n",
    "    \n",
    "    df['content_id_seq'] = df['content_id_seq'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['content_id_seq_input'] = df.apply(lambda x: pad_np(x.content_id_seq, x.index), axis=1)\n",
    "\n",
    "    df['answered_correctly'] = df['answered_correctly'].apply(lambda x: np.array(x.split(',')).astype(np.int16))\n",
    "    df['answered_correctly_input'] = df.apply(lambda x: pad_np(x['answered_correctly',x['index']]))\n",
    "#     df['answered_correctly'] = df['answered_correctly'].apply(lambda x: pad_np(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:21.926560Z",
     "iopub.status.busy": "2020-11-24T15:32:21.925843Z",
     "iopub.status.idle": "2020-11-24T15:32:21.929476Z",
     "shell.execute_reply": "2020-11-24T15:32:21.928972Z"
    },
    "papermill": {
     "duration": 0.044384,
     "end_time": "2020-11-24T15:32:21.929577",
     "exception": false,
     "start_time": "2020-11-24T15:32:21.885193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "\n",
    "# test_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_test.csv')\n",
    "# test_df['content_id'] = test_df['content_id'] + 1\n",
    "\n",
    "\n",
    "# test_df = test_df.loc[:,['content_id','content_type_id',\n",
    "#                              'row_id','user_id']]\n",
    "\n",
    "# test_df = test_df.loc[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "# print(\"test_df:\", test_df.shape)\n",
    "\n",
    "# test_df = pd.merge(test_df, train_pkl, on='user_id',how='left').fillna('0')\n",
    "\n",
    "# test_df = pad_seq(test_df)\n",
    "\n",
    "# test_dataset = Rii_dataset(test_df)\n",
    "\n",
    "# test_dataloader = data.DataLoader(\n",
    "#             dataset=test_dataset, shuffle=False,\n",
    "#             batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "# preds = []\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(test_dataloader):\n",
    "#         batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "#         question_id, target_id = batch\n",
    "#         output = model(question_id, target_id)\n",
    "#         pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "#         preds.append(pred)\n",
    "\n",
    "# preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "# print(\"preds:\",preds)\n",
    "# test_df['answered_correctly'] =  preds\n",
    "\n",
    "# end = datetime.datetime.now()\n",
    "# print(\"Test running time:\", end-start)\n",
    "\n",
    "\n",
    "# for row in test_df.itertuples():\n",
    "#     user_id = getattr(row, \"user_id\")\n",
    "#     content_id = getattr(row, \"content_id\")\n",
    "#     content_id_seq = getattr(row, \"content_id_seq\")\n",
    "    \n",
    "#     print(len(content_id_seq))\n",
    "#     a = torch.LongTensor([content_id])\n",
    "#     b = torch.from_numpy(content_id_seq)\n",
    "#     b = b.long()\n",
    "#     print(\"content_id is:\",content_id)\n",
    "#     print(\"content_id_seq:\",content_id_seq)\n",
    "#     print(\"a is:\",a)\n",
    "#     print(\"b is:\",b)\n",
    "#     print(\"\\n\\n\")\n",
    "#     print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:22.007620Z",
     "iopub.status.busy": "2020-11-24T15:32:22.005552Z",
     "iopub.status.idle": "2020-11-24T15:32:22.008464Z",
     "shell.execute_reply": "2020-11-24T15:32:22.009034Z"
    },
    "papermill": {
     "duration": 0.043883,
     "end_time": "2020-11-24T15:32:22.009169",
     "exception": false,
     "start_time": "2020-11-24T15:32:21.965286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:22.096373Z",
     "iopub.status.busy": "2020-11-24T15:32:22.095446Z",
     "iopub.status.idle": "2020-11-24T15:32:24.000218Z",
     "shell.execute_reply": "2020-11-24T15:32:24.001261Z"
    },
    "papermill": {
     "duration": 1.956789,
     "end_time": "2020-11-24T15:32:24.001447",
     "exception": false,
     "start_time": "2020-11-24T15:32:22.044658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 152.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 111.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 116.11it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for(test_df, sample_prediction_df) in iter_test:\n",
    "    try:\n",
    "        test_df['content_id'] = test_df['content_id'] + 1\n",
    "        test_df = test_df.loc[:,['content_id','content_type_id',\n",
    "                             'row_id','user_id','timestamp']]\n",
    "\n",
    "        test_df = test_df.loc[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "\n",
    "        test_df = pd.merge(test_df, train_pkl, on='user_id',how='left').fillna('0')\n",
    "        test_df = pad_seq(test_df)\n",
    "\n",
    "        test_dataset = Rii_dataset(test_df)\n",
    "        test_dataloader = data.DataLoader(\n",
    "            dataset=test_dataset, shuffle=False,batch_size=ARGS.train_batch)\n",
    "\n",
    "        \n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_dataloader):\n",
    "                batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "                question_id, target_id = batch\n",
    "                output = model(question_id, target_id)\n",
    "                pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "                preds.append(pred)\n",
    "\n",
    "        preds = torch.cat(preds, dim=0).cpu().numpy()\n",
    "#         print(\"preds:\",preds)\n",
    "        test_df['answered_correctly'] =  preds\n",
    "        env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "    except:\n",
    "        print(test_df)\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:24.138291Z",
     "iopub.status.busy": "2020-11-24T15:32:24.137370Z",
     "iopub.status.idle": "2020-11-24T15:32:24.141838Z",
     "shell.execute_reply": "2020-11-24T15:32:24.142903Z"
    },
    "papermill": {
     "duration": 0.07786,
     "end_time": "2020-11-24T15:32:24.143069",
     "exception": false,
     "start_time": "2020-11-24T15:32:24.065209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./submission.csv\")\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-24T15:32:24.277539Z",
     "iopub.status.busy": "2020-11-24T15:32:24.276626Z",
     "iopub.status.idle": "2020-11-24T15:32:24.284146Z",
     "shell.execute_reply": "2020-11-24T15:32:24.285698Z"
    },
    "papermill": {
     "duration": 0.082399,
     "end_time": "2020-11-24T15:32:24.285881",
     "exception": false,
     "start_time": "2020-11-24T15:32:24.203482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_id  answered_correctly\n",
       "0         0                   1\n",
       "1         1                   1\n",
       "2         2                   1\n",
       "3         3                   1\n",
       "4         4                   0\n",
       "..      ...                 ...\n",
       "99      104                   1\n",
       "100     105                   1\n",
       "101     106                   1\n",
       "102     107                   1\n",
       "103     108                   1\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.049697,
     "end_time": "2020-11-24T15:32:24.398981",
     "exception": false,
     "start_time": "2020-11-24T15:32:24.349284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "duration": 20.974997,
   "end_time": "2020-11-24T15:32:25.815263",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-24T15:32:04.840266",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
