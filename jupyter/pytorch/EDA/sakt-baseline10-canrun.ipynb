{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:21.566803Z",
     "iopub.status.busy": "2020-11-18T14:44:21.565803Z",
     "iopub.status.idle": "2020-11-18T14:44:22.647848Z",
     "shell.execute_reply": "2020-11-18T14:44:22.647141Z"
    },
    "papermill": {
     "duration": 1.129841,
     "end_time": "2020-11-18T14:44:22.647995",
     "exception": false,
     "start_time": "2020-11-18T14:44:21.518154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import riiideducation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "env = riiideducation.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:22.729155Z",
     "iopub.status.busy": "2020-11-18T14:44:22.728338Z",
     "iopub.status.idle": "2020-11-18T14:44:22.732612Z",
     "shell.execute_reply": "2020-11-18T14:44:22.731819Z"
    },
    "papermill": {
     "duration": 0.046135,
     "end_time": "2020-11-18T14:44:22.732752",
     "exception": false,
     "start_time": "2020-11-18T14:44:22.686617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/riiid-test-answer-prediction/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037217,
     "end_time": "2020-11-18T14:44:22.807607",
     "exception": false,
     "start_time": "2020-11-18T14:44:22.770390",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ARGS参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:22.891438Z",
     "iopub.status.busy": "2020-11-18T14:44:22.890572Z",
     "iopub.status.idle": "2020-11-18T14:44:22.894523Z",
     "shell.execute_reply": "2020-11-18T14:44:22.893792Z"
    },
    "papermill": {
     "duration": 0.049615,
     "end_time": "2020-11-18T14:44:22.894654",
     "exception": false,
     "start_time": "2020-11-18T14:44:22.845039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    name = 'train'\n",
    "    model = 'SAKT'\n",
    "    num_layers = 1\n",
    "    hidden_dim=100\n",
    "    input_dim = 100\n",
    "    dropout = 0.2\n",
    "    num_head = 5\n",
    "    \n",
    "    random_seed = 1\n",
    "    num_epochs = 1\n",
    "    lr = 0.01\n",
    "    seq_size = 20\n",
    "    warm_up_step_count = 4000\n",
    "    eval_steps = 50000\n",
    "    train_steps = 50000\n",
    "    train_batch=2048\n",
    "    num_workers=1\n",
    "    device='cpu'\n",
    "    \n",
    "    \n",
    "ARGS = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:22.978992Z",
     "iopub.status.busy": "2020-11-18T14:44:22.978181Z",
     "iopub.status.idle": "2020-11-18T14:44:22.981499Z",
     "shell.execute_reply": "2020-11-18T14:44:22.980708Z"
    },
    "papermill": {
     "duration": 0.047551,
     "end_time": "2020-11-18T14:44:22.981679",
     "exception": false,
     "start_time": "2020-11-18T14:44:22.934128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "\n",
    "QUESTION_NUM = {\n",
    "    'riii':13523\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:23.067072Z",
     "iopub.status.busy": "2020-11-18T14:44:23.066269Z",
     "iopub.status.idle": "2020-11-18T14:44:24.113825Z",
     "shell.execute_reply": "2020-11-18T14:44:24.112980Z"
    },
    "papermill": {
     "duration": 1.093194,
     "end_time": "2020-11-18T14:44:24.113966",
     "exception": false,
     "start_time": "2020-11-18T14:44:23.020772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from itertools import repeat, chain, islice\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:24.218713Z",
     "iopub.status.busy": "2020-11-18T14:44:24.204493Z",
     "iopub.status.idle": "2020-11-18T14:44:24.222561Z",
     "shell.execute_reply": "2020-11-18T14:44:24.221884Z"
    },
    "papermill": {
     "duration": 0.068864,
     "end_time": "2020-11-18T14:44:24.222721",
     "exception": false,
     "start_time": "2020-11-18T14:44:24.153857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UserSepDataSet_Rii_Train(Dataset):\n",
    "\n",
    "    def __init__(self,user_dict):\n",
    "\n",
    "        self.user_dict = user_dict\n",
    "#         self.question_df = question_df\n",
    "\n",
    "#         self.combine = self.get_combine()\n",
    "        self.question_ids, self.target_ids, self.labels = self.get_data_for_train()\n",
    "\n",
    "\n",
    "    def get_data_for_train(self):\n",
    "        all_question_ids = []\n",
    "        all_labels= []\n",
    "        all_target_qids = []\n",
    "\n",
    "        for k,v in self.user_dict.items():\n",
    "            user_id = k\n",
    "            if len(v) != 2:\n",
    "                print(v)\n",
    "                continue\n",
    "            \n",
    "            question_ids = v[0]\n",
    "            answers = v[1]\n",
    "\n",
    "            assert len(question_ids) == len(answers)\n",
    "\n",
    "\n",
    "            for target_index in range(0, len(question_ids)):\n",
    "                qids = question_ids[:target_index + 1]\n",
    "                ans_flags = answers[:target_index + 1]\n",
    "\n",
    "                length = len(qids)\n",
    "                if length > ARGS.seq_size + 1:\n",
    "                    qids = qids[-(ARGS.seq_size + 1):]\n",
    "                    ans_flags = ans_flags[-(ARGS.seq_size + 1):]\n",
    "                    pad_counts = 0\n",
    "                else:\n",
    "                    pad_counts = ARGS.seq_size + 1 - length\n",
    "\n",
    "                input_list = []\n",
    "                for idx in range(len(qids)):\n",
    "                    # print(f\"idx is:{idx}, qids[idx] is:{qids[idx]}\")\n",
    "                    tag_id = qids[idx]\n",
    "                    is_correct = ans_flags[idx]\n",
    "\n",
    "                    if idx == len(qids) - 1:\n",
    "                        last_is_correct = is_correct\n",
    "                        target_id = tag_id\n",
    "                    else:\n",
    "                        if is_correct:\n",
    "                            input_list.append(tag_id)\n",
    "                        else:\n",
    "                            input_list.append(tag_id + QUESTION_NUM['riii'])\n",
    "\n",
    "                paddings = [PAD_INDEX]*pad_counts\n",
    "                input_list = paddings + input_list\n",
    "                assert len(input_list) == ARGS.seq_size\n",
    "\n",
    "                all_question_ids.append(input_list)\n",
    "                all_target_qids.append([target_id])\n",
    "                all_labels.append([last_is_correct])\n",
    "\n",
    "        return torch.LongTensor(all_question_ids), \\\n",
    "            torch.LongTensor(all_target_qids),\\\n",
    "            torch.LongTensor(all_labels)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.question_ids[index], self.target_ids[index], self.labels[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:24.340090Z",
     "iopub.status.busy": "2020-11-18T14:44:24.327149Z",
     "iopub.status.idle": "2020-11-18T14:44:24.343910Z",
     "shell.execute_reply": "2020-11-18T14:44:24.344510Z"
    },
    "papermill": {
     "duration": 0.08356,
     "end_time": "2020-11-18T14:44:24.344717",
     "exception": false,
     "start_time": "2020-11-18T14:44:24.261157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UserSepDataSet_Rii_Test(Dataset):\n",
    "\n",
    "    def __init__(self, test_df, user_dict, is_test=True):\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.user_dict = user_dict\n",
    "        self.is_test = is_test\n",
    "        if self.is_test:\n",
    "            self.question_ids, self.target_ids = self.get_data_for_test()\n",
    "        else:\n",
    "            self.question_ids, self.target_ids, self.labels = self.get_data_for_valid()\n",
    "\n",
    "\n",
    "    def get_data_for_test(self):\n",
    "        all_question_ids = []\n",
    "        all_target_ids = []\n",
    "\n",
    "        for row in self.test_df.itertuples():\n",
    "            user_id = getattr(row, 'user_id')\n",
    "            q_id = getattr(row, 'content_id')\n",
    "           \n",
    "            # ans = getattr(row, 'answered_correctly')\n",
    "            # last_is_correct = ans\n",
    "            target_id = int(float(q_id))\n",
    "\n",
    "#             train_user = self.train_combine.loc[self.train_combine['user_id']==user_id]\n",
    "            if user_id in self.user_dict.keys():\n",
    "#                 timestamps = train_user['timestamp'].item().strip().split(',')\n",
    "#                 timestamps = [int(float(e.strip())) for e in timestamps]\n",
    "\n",
    "                qids = self.user_dict[user_id][0]\n",
    "#                 qids = [int(float(e.strip())) for e in q_ids]\n",
    "\n",
    "#                 answers = train_user['answered_correctly'].item().strip().split(',')\n",
    "                ans_flags = self.user_dict[user_id][1]\n",
    "\n",
    "                assert len(qids) == len(ans_flags)\n",
    "               \n",
    "\n",
    "                length = len(qids)\n",
    "                if length > ARGS.seq_size:\n",
    "                    qids = qids[-ARGS.seq_size:]\n",
    "                    ans_flags =  ans_flags[-ARGS.seq_size:]\n",
    "                    pad_counts = 0\n",
    "                else:\n",
    "                    pad_counts = ARGS.seq_size - length\n",
    "\n",
    "                input_list = []\n",
    "                for idx in range(len(qids)):\n",
    "                    tag_id = qids[idx]\n",
    "                    is_correct = ans_flags[idx]\n",
    "\n",
    "                    if is_correct:\n",
    "                        input_list.append(tag_id)\n",
    "                    else:\n",
    "                        input_list.append(tag_id + QUESTION_NUM['riii'])\n",
    "\n",
    "                paddings = [PAD_INDEX]*pad_counts\n",
    "                input_list = paddings + input_list\n",
    "                assert len(input_list) == ARGS.seq_size\n",
    "\n",
    "            else:\n",
    "                input_list = [PAD_INDEX] * ARGS.seq_size\n",
    "\n",
    "            all_question_ids.append(input_list)\n",
    "            all_target_ids.append([target_id])\n",
    "\n",
    "        return torch.LongTensor(all_question_ids), \\\n",
    "            torch.LongTensor(all_target_ids),\n",
    "\n",
    "\n",
    "\n",
    "    def get_data_for_valid(self):\n",
    "        all_question_ids = []\n",
    "        all_labels = []\n",
    "        all_target_ids = []\n",
    "\n",
    "        for row in self.test_df.itertuples():\n",
    "            user_id = getattr(row, 'user_id')\n",
    "            q_id = getattr(row, 'content_id')\n",
    "#             timestamp = getattr(row, 'timestamp')\n",
    "            ans = getattr(row, 'answered_correctly')\n",
    "            last_is_correct = ans\n",
    "            target_id = int(float(q_id))\n",
    "            if target_id > 13523:\n",
    "                print(\"user_id:{}, q_id:{}\".format(user_id, q_id))\n",
    "\n",
    "#             train_user = self.train_combine.loc[self.train_combine['user_id']==user_id]\n",
    "            if user_id in self.user_dict.keys():\n",
    "                # print(\"Bingo\")\n",
    "#                 timestamps = train_user['timestamp'].item().strip().split(',')\n",
    "#                 timestamps = [int(float(e.strip())) for e in timestamps]\n",
    "\n",
    "#                 q_ids = train_user['question_id'].item().strip().split(',')\n",
    "                qids = self.user_dict[user_id][0]\n",
    "\n",
    "#                 answers = train_user['answered_correctly'].item().strip().split(',')\n",
    "                ans_flags = self.user_dict[user_id][1]\n",
    "    \n",
    "                assert len(qids)  == len(ans_flags)\n",
    "\n",
    "\n",
    "                length = len(qids)\n",
    "                if length > ARGS.seq_size:\n",
    "                    qids = qids[-ARGS.seq_size:]\n",
    "                    ans_flags =  ans_flags[-ARGS.seq_size:]\n",
    "                    pad_counts = 0\n",
    "                else:\n",
    "                    pad_counts = ARGS.seq_size - length\n",
    "\n",
    "                input_list = []\n",
    "                for idx in range(len(qids)):\n",
    "                    tag_id = qids[idx]\n",
    "                    is_correct = ans_flags[idx]\n",
    "\n",
    "                    if is_correct:\n",
    "                        input_list.append(tag_id)\n",
    "                    else:\n",
    "                        input_list.append(tag_id + QUESTION_NUM['riii'])\n",
    "\n",
    "                paddings = [PAD_INDEX]*pad_counts\n",
    "                input_list = paddings + input_list\n",
    "                assert len(input_list) == ARGS.seq_size\n",
    "\n",
    "            else:\n",
    "                input_list = [PAD_INDEX] * ARGS.seq_size\n",
    "\n",
    "            all_question_ids.append(input_list)\n",
    "            all_target_ids.append([target_id])\n",
    "            all_labels.append([last_is_correct])\n",
    "\n",
    "        return torch.LongTensor(all_question_ids), \\\n",
    "            torch.LongTensor(all_target_ids), \\\n",
    "            torch.LongTensor(all_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return self.question_ids[index], self.target_ids[index]\n",
    "        else:\n",
    "            return self.question_ids[index], self.target_ids[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:24.428010Z",
     "iopub.status.busy": "2020-11-18T14:44:24.427087Z",
     "iopub.status.idle": "2020-11-18T14:44:24.431158Z",
     "shell.execute_reply": "2020-11-18T14:44:24.430405Z"
    },
    "papermill": {
     "duration": 0.047856,
     "end_time": "2020-11-18T14:44:24.431282",
     "exception": false,
     "start_time": "2020-11-18T14:44:24.383426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = '/kaggle/input/riiid-test-answer-prediction/train.csv'\n",
    "que_csv = '/kaggle/input/riiid-test-answer-prediction/questions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:44:24.520251Z",
     "iopub.status.busy": "2020-11-18T14:44:24.519028Z",
     "iopub.status.idle": "2020-11-18T14:46:34.185103Z",
     "shell.execute_reply": "2020-11-18T14:46:34.184367Z"
    },
    "papermill": {
     "duration": 129.715342,
     "end_time": "2020-11-18T14:46:34.185306",
     "exception": false,
     "start_time": "2020-11-18T14:44:24.469964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv, usecols = [1,2,3,4,7],\n",
    "                   dtype={'timestamp':'int64',\n",
    "                         'used_id':'int16',\n",
    "                         'content_id':'int16',\n",
    "                         'content_type_id':'int8',\n",
    "                         'answered_correctly':'int8'})\n",
    "\n",
    "train_df['content_id'] = train_df['content_id'] + 1\n",
    "train_df = train_df[train_df.content_type_id == False]\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:34.270539Z",
     "iopub.status.busy": "2020-11-18T14:46:34.269752Z",
     "iopub.status.idle": "2020-11-18T14:46:52.432180Z",
     "shell.execute_reply": "2020-11-18T14:46:52.431552Z"
    },
    "papermill": {
     "duration": 18.207626,
     "end_time": "2020-11-18T14:46:52.432341",
     "exception": false,
     "start_time": "2020-11-18T14:46:34.224715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(frac=1.0)\n",
    "train = train_df.iloc[-5000:-2500]\n",
    "valid = train_df.iloc[-2500:]\n",
    "\n",
    "del(train_df)\n",
    "gc.collect()\n",
    "\n",
    "# train = train.sort_values(['timestamp'], ascending=True).reset_index(drop=True)\n",
    "# valid = valid.sort_values(['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:52.520992Z",
     "iopub.status.busy": "2020-11-18T14:46:52.520110Z",
     "iopub.status.idle": "2020-11-18T14:46:52.540146Z",
     "shell.execute_reply": "2020-11-18T14:46:52.539477Z"
    },
    "papermill": {
     "duration": 0.066167,
     "end_time": "2020-11-18T14:46:52.540303",
     "exception": false,
     "start_time": "2020-11-18T14:46:52.474136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "question_df = pd.read_csv(que_csv)\n",
    "question_df['question_id'] = question_df['question_id'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:52.630409Z",
     "iopub.status.busy": "2020-11-18T14:46:52.629265Z",
     "iopub.status.idle": "2020-11-18T14:46:52.641062Z",
     "shell.execute_reply": "2020-11-18T14:46:52.640412Z"
    },
    "papermill": {
     "duration": 0.061411,
     "end_time": "2020-11-18T14:46:52.641186",
     "exception": false,
     "start_time": "2020-11-18T14:46:52.579775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31701388</th>\n",
       "      <td>943638867</td>\n",
       "      <td>1065517323</td>\n",
       "      <td>4534</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15761351</th>\n",
       "      <td>159124138</td>\n",
       "      <td>290633882</td>\n",
       "      <td>10497</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26202860</th>\n",
       "      <td>598693305</td>\n",
       "      <td>360387024</td>\n",
       "      <td>7954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54151021</th>\n",
       "      <td>3336806199</td>\n",
       "      <td>603646233</td>\n",
       "      <td>6263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48249668</th>\n",
       "      <td>2493718857</td>\n",
       "      <td>461944680</td>\n",
       "      <td>835</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82202008</th>\n",
       "      <td>15214906155</td>\n",
       "      <td>1675115071</td>\n",
       "      <td>6125</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53558770</th>\n",
       "      <td>3234591008</td>\n",
       "      <td>1752599884</td>\n",
       "      <td>6269</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26943552</th>\n",
       "      <td>627850457</td>\n",
       "      <td>1599559259</td>\n",
       "      <td>8979</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86903000</th>\n",
       "      <td>19610475452</td>\n",
       "      <td>271136436</td>\n",
       "      <td>2102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23357514</th>\n",
       "      <td>440371408</td>\n",
       "      <td>2071214979</td>\n",
       "      <td>5461</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     user_id  content_id  content_type_id  \\\n",
       "31701388    943638867  1065517323        4534                0   \n",
       "15761351    159124138   290633882       10497                0   \n",
       "26202860    598693305   360387024        7954                0   \n",
       "54151021   3336806199   603646233        6263                0   \n",
       "48249668   2493718857   461944680         835                0   \n",
       "82202008  15214906155  1675115071        6125                0   \n",
       "53558770   3234591008  1752599884        6269                0   \n",
       "26943552    627850457  1599559259        8979                0   \n",
       "86903000  19610475452   271136436        2102                0   \n",
       "23357514    440371408  2071214979        5461                0   \n",
       "\n",
       "          answered_correctly  \n",
       "31701388                   1  \n",
       "15761351                   0  \n",
       "26202860                   0  \n",
       "54151021                   1  \n",
       "48249668                   1  \n",
       "82202008                   1  \n",
       "53558770                   1  \n",
       "26943552                   1  \n",
       "86903000                   0  \n",
       "23357514                   1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:52.735680Z",
     "iopub.status.busy": "2020-11-18T14:46:52.734344Z",
     "iopub.status.idle": "2020-11-18T14:46:53.036788Z",
     "shell.execute_reply": "2020-11-18T14:46:53.035919Z"
    },
    "papermill": {
     "duration": 0.353248,
     "end_time": "2020-11-18T14:46:53.036921",
     "exception": false,
     "start_time": "2020-11-18T14:46:52.683673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user = pd.merge(train, question_df,left_on=\"content_id\", right_on='question_id', how='left')\n",
    "user_dict = train_user.groupby('user_id')[['question_id','answered_correctly']].apply(\n",
    "    lambda g:g.values.tolist()).to_dict()\n",
    "del(train)\n",
    "del(question_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.129032Z",
     "iopub.status.busy": "2020-11-18T14:46:53.128249Z",
     "iopub.status.idle": "2020-11-18T14:46:53.133136Z",
     "shell.execute_reply": "2020-11-18T14:46:53.132086Z"
    },
    "papermill": {
     "duration": 0.053958,
     "end_time": "2020-11-18T14:46:53.133311",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.079353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# user_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.225884Z",
     "iopub.status.busy": "2020-11-18T14:46:53.224824Z",
     "iopub.status.idle": "2020-11-18T14:46:53.228801Z",
     "shell.execute_reply": "2020-11-18T14:46:53.229428Z"
    },
    "papermill": {
     "duration": 0.051321,
     "end_time": "2020-11-18T14:46:53.229632",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.178311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2432"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.325796Z",
     "iopub.status.busy": "2020-11-18T14:46:53.324968Z",
     "iopub.status.idle": "2020-11-18T14:46:53.328699Z",
     "shell.execute_reply": "2020-11-18T14:46:53.327909Z"
    },
    "papermill": {
     "duration": 0.057125,
     "end_time": "2020-11-18T14:46:53.328842",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.271717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_dict2 = dict()\n",
    "for k, v in user_dict.items():\n",
    "    ques = []\n",
    "    ans = []\n",
    "    \n",
    "    for e in v:\n",
    "        ques.append(e[0])\n",
    "        ans.append(e[1])\n",
    "    user_dict2[k] = [ques, ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.422321Z",
     "iopub.status.busy": "2020-11-18T14:46:53.421474Z",
     "iopub.status.idle": "2020-11-18T14:46:53.446860Z",
     "shell.execute_reply": "2020-11-18T14:46:53.446189Z"
    },
    "papermill": {
     "duration": 0.076115,
     "end_time": "2020-11-18T14:46:53.447012",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.370897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = UserSepDataSet_Rii_Train(user_dict2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.624055Z",
     "iopub.status.busy": "2020-11-18T14:46:53.623218Z",
     "iopub.status.idle": "2020-11-18T14:46:53.629117Z",
     "shell.execute_reply": "2020-11-18T14:46:53.628475Z"
    },
    "papermill": {
     "duration": 0.139279,
     "end_time": "2020-11-18T14:46:53.629254",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.489975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(user_dict)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.736376Z",
     "iopub.status.busy": "2020-11-18T14:46:53.731250Z",
     "iopub.status.idle": "2020-11-18T14:46:53.740585Z",
     "shell.execute_reply": "2020-11-18T14:46:53.739762Z"
    },
    "papermill": {
     "duration": 0.068401,
     "end_time": "2020-11-18T14:46:53.740714",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.672313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = UserSepDataSet_Rii_Test(valid, user_dict2, is_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.836794Z",
     "iopub.status.busy": "2020-11-18T14:46:53.835957Z",
     "iopub.status.idle": "2020-11-18T14:46:53.841170Z",
     "shell.execute_reply": "2020-11-18T14:46:53.840475Z"
    },
    "papermill": {
     "duration": 0.057263,
     "end_time": "2020-11-18T14:46:53.841297",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.784034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:53.934979Z",
     "iopub.status.busy": "2020-11-18T14:46:53.934040Z",
     "iopub.status.idle": "2020-11-18T14:46:53.939238Z",
     "shell.execute_reply": "2020-11-18T14:46:53.938530Z"
    },
    "papermill": {
     "duration": 0.054597,
     "end_time": "2020-11-18T14:46:53.939365",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.884768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045232,
     "end_time": "2020-11-18T14:46:54.034104",
     "exception": false,
     "start_time": "2020-11-18T14:46:53.988872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SAKT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044696,
     "end_time": "2020-11-18T14:46:54.123205",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.078509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:54.224580Z",
     "iopub.status.busy": "2020-11-18T14:46:54.223781Z",
     "iopub.status.idle": "2020-11-18T14:46:54.228419Z",
     "shell.execute_reply": "2020-11-18T14:46:54.227544Z"
    },
    "papermill": {
     "duration": 0.059434,
     "end_time": "2020-11-18T14:46:54.228555",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.169121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:54.331414Z",
     "iopub.status.busy": "2020-11-18T14:46:54.330570Z",
     "iopub.status.idle": "2020-11-18T14:46:54.333874Z",
     "shell.execute_reply": "2020-11-18T14:46:54.334510Z"
    },
    "papermill": {
     "duration": 0.059208,
     "end_time": "2020-11-18T14:46:54.334669",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.275461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:54.472702Z",
     "iopub.status.busy": "2020-11-18T14:46:54.465240Z",
     "iopub.status.idle": "2020-11-18T14:46:54.476476Z",
     "shell.execute_reply": "2020-11-18T14:46:54.475632Z"
    },
    "papermill": {
     "duration": 0.096886,
     "end_time": "2020-11-18T14:46:54.476608",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.379722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model, bias=False), 4) # Q, K, V, last\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "class SAKTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Encoder block of SAKT\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._self_attn = MultiHeadedAttention(num_head, hidden_dim, dropout)\n",
    "        self._ffn = PositionwiseFeedForward(hidden_dim, hidden_dim, dropout)\n",
    "        self._layernorms = clones(nn.LayerNorm(hidden_dim, eps=1e-6), 2)\n",
    "\n",
    "    def forward(self, query, key, mask=None):\n",
    "        \"\"\"\n",
    "        query: question embeddings\n",
    "        key: interaction embeddings\n",
    "        \"\"\"\n",
    "        # self-attention block\n",
    "        output = self._self_attn(query=query, key=key, value=key, mask=mask)\n",
    "        output = self._layernorms[0](key + output)\n",
    "        # feed-forward block\n",
    "        output = self._layernorms[1](output + self._ffn(output))\n",
    "        return output\n",
    "\n",
    "\n",
    "class SAKT(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based\n",
    "    all hidden dimensions (d_k, d_v, ...) are the same as hidden_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, question_num, num_layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._question_num = question_num\n",
    "        # question_num的值是110\n",
    "        # Blocks\n",
    "        self._layers = clones(SAKTLayer(hidden_dim, num_head, dropout), num_layers)\n",
    "\n",
    "        # prediction layer\n",
    "        self._prediction = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Embedding layers\n",
    "        self._positional_embedding = nn.Embedding(ARGS.seq_size+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        self._interaction_embedding = nn.Embedding(2*question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        # 这个就是包含了qid对错信息的矩阵\n",
    "        self._question_embedding = nn.Embedding(question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "\n",
    "    def _transform_interaction_to_question_id(self, interaction):\n",
    "        \"\"\"\n",
    "        get question_id from interaction index\n",
    "        if interaction index is a number in [0, question_num], then leave it as-is\n",
    "        if interaction index is bigger than question_num (in [question_num + 1, 2 * question_num]\n",
    "        then subtract question_num\n",
    "        interaction: integer tensor of shape (batch_size, sequence_size)\n",
    "        \"\"\"\n",
    "        return interaction - self._question_num * (interaction > self._question_num).long()\n",
    "\n",
    "    def _get_position_index(self, question_id):\n",
    "        \"\"\"\n",
    "        [0, 0, 0, 4, 12] -> [0, 0, 0, 1, 2]\n",
    "        \"\"\"\n",
    "        batch_size = question_id.shape[0]\n",
    "        position_indices = []\n",
    "        for i in range(batch_size):\n",
    "            non_padding_num = (question_id[i] != PAD_INDEX).sum(-1).item()\n",
    "            position_index = [0] * (ARGS.seq_size - non_padding_num) + list(range(1, non_padding_num+1))\n",
    "            position_indices.append(position_index)\n",
    "        return torch.tensor(position_indices, dtype=int).to(ARGS.device)\n",
    "\n",
    "    def forward(self, interaction_id, target_id):\n",
    "        \"\"\"\n",
    "        Query: Question (skill, exercise, ...) embedding\n",
    "        Key, Value: Interaction embedding + positional embedding\n",
    "        \"\"\"\n",
    "        question_id = self._transform_interaction_to_question_id(interaction_id)\n",
    "        # 这个question_id就是把以前把统一qid由于对错不同对应不同id，转换成同一qid\n",
    "        # 也就是把qid数值大于q_num的，减去q_num\n",
    "        question_id = torch.cat([question_id[:, 1:], target_id], dim=-1)\n",
    "        # question_id的原来的维度是(batch, seq_len)，\n",
    "        # 然后那两个:，第一个表示在第一个维度全选\n",
    "        # 第二个1:，表示第二个维度从第一个元素选起，这主要是为了和target_id合并在一起\n",
    "\n",
    "        # 这时question_id和interaction_id存在着一个错位的问题，\n",
    "        # 也就是question_id包含了当前target_id,而interaction_id中不包含\n",
    "\n",
    "        interaction_vector = self._interaction_embedding(interaction_id)\n",
    "        question_vector = self._question_embedding(question_id)\n",
    "\n",
    "        position_index = self._get_position_index(question_id)\n",
    "        # 对于question_id获取position的下标\n",
    "        position_vector = self._positional_embedding(position_index)\n",
    "\n",
    "        mask = get_pad_mask(question_id, PAD_INDEX) & get_subsequent_mask(question_id)\n",
    "        x = interaction_vector + position_vector\n",
    "        # 这个position_vector只加给了interaction_vector向量\n",
    "        # x的维度是(batch, seq_len, hidden)\n",
    "        for layer in self._layers:\n",
    "            x = layer(query=question_vector, key=x, mask=mask)\n",
    "\n",
    "        output = self._prediction(x)\n",
    "        # 这里的output为什么会是一个三维的向量呢\n",
    "        output = output[:, -1, :]\n",
    "        # output的最初维度是(batch, seq_len, 1)\n",
    "        # 然后用[:,-1,:]只取seq_len的最后一个值\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:54.576169Z",
     "iopub.status.busy": "2020-11-18T14:46:54.575319Z",
     "iopub.status.idle": "2020-11-18T14:46:54.583320Z",
     "shell.execute_reply": "2020-11-18T14:46:54.582463Z"
    },
    "papermill": {
     "duration": 0.061862,
     "end_time": "2020-11-18T14:46:54.583451",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.521589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ARGS.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed_all(ARGS.random_seed)\n",
    "random.seed(ARGS.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:54.687283Z",
     "iopub.status.busy": "2020-11-18T14:46:54.686427Z",
     "iopub.status.idle": "2020-11-18T14:46:54.783500Z",
     "shell.execute_reply": "2020-11-18T14:46:54.782809Z"
    },
    "papermill": {
     "duration": 0.154827,
     "end_time": "2020-11-18T14:46:54.783675",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.628848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " model = SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045821,
     "end_time": "2020-11-18T14:46:54.875625",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.829804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045576,
     "end_time": "2020-11-18T14:46:54.967258",
     "exception": false,
     "start_time": "2020-11-18T14:46:54.921682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046726,
     "end_time": "2020-11-18T14:46:55.062330",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.015604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.047314,
     "end_time": "2020-11-18T14:46:55.156652",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.109338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:55.279774Z",
     "iopub.status.busy": "2020-11-18T14:46:55.278916Z",
     "iopub.status.idle": "2020-11-18T14:46:55.283205Z",
     "shell.execute_reply": "2020-11-18T14:46:55.282430Z"
    },
    "papermill": {
     "duration": 0.071424,
     "end_time": "2020-11-18T14:46:55.283345",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.211921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps\n",
    "        ])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "               (self.model_size ** (-0.5) *\n",
    "                min(step ** (-0.5), step * self.warmup ** (-1.5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:55.434615Z",
     "iopub.status.busy": "2020-11-18T14:46:55.411078Z",
     "iopub.status.idle": "2020-11-18T14:46:55.437866Z",
     "shell.execute_reply": "2020-11-18T14:46:55.437085Z"
    },
    "papermill": {
     "duration": 0.107883,
     "end_time": "2020-11-18T14:46:55.438004",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.330121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoamOptimizer:\n",
    "    def __init__(self, model, lr, model_size, warmup):\n",
    "        self._adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self._opt = NoamOpt(\n",
    "            model_size=model_size, factor=1, warmup=warmup, optimizer=self._adam)\n",
    "\n",
    "    def step(self, loss):\n",
    "        self._opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self._opt.step()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, warm_up_step_count,\n",
    "                 d_model, num_epochs, weight_path, lr,\n",
    "                 train_data, val_data, test_data=None):\n",
    "        self._device = device\n",
    "        self._num_epochs = num_epochs\n",
    "        self._weight_path = weight_path\n",
    "\n",
    "        self._model = model\n",
    "        self._loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self._model.to(device)\n",
    "\n",
    "        self._train_data = train_data\n",
    "        self._val_data = val_data\n",
    "        self._test_data = test_data\n",
    "\n",
    "        self._opt = NoamOptimizer(model=model, lr=lr, model_size=d_model, warmup=warm_up_step_count)\n",
    "\n",
    "        self.step = 0\n",
    "        self._threshold = 0.5\n",
    "        self.max_step = 0\n",
    "        self.max_acc = 0.0\n",
    "        self.max_auc = 0.0\n",
    "\n",
    "        self.test_acc = 0.0\n",
    "        self.test_auc = 0.0\n",
    "\n",
    "    # train model and choose weight with max auc on validation dataset\n",
    "    def train(self):\n",
    "        train_gen = self._train_data\n",
    "        val_gen = self._val_data\n",
    "\n",
    "        # will train self._num_epochs copies of train data\n",
    "        to_train = chain.from_iterable(repeat(train_gen, self._num_epochs))\n",
    "        # consisting of total_steps batches\n",
    "        total_steps = len(train_gen) * self._num_epochs\n",
    "        print(\"total_steps:\",total_steps)\n",
    "\n",
    "        self.step = 0\n",
    "        while self.step < total_steps:\n",
    "            rem_steps = total_steps - self.step\n",
    "            num_steps = min(rem_steps, ARGS.train_steps)\n",
    "            self.step += num_steps\n",
    "\n",
    "            # take num_steps batches from to_train stream\n",
    "            train_batches = islice(to_train, num_steps)\n",
    "            # print(f'Step: {self.step}')\n",
    "#            print(f\"Current Training step is: {self.step}\")\n",
    "            self._train(train_batches, num_steps)\n",
    "            if self.step % ARGS.eval_steps == 0:\n",
    "                cur_weight = self._model.state_dict()\n",
    "#                 torch.save(cur_weight, f'{self._weight_path}{self.step}.pt')\n",
    "                self._test('Validation', val_gen)\n",
    "            # print(f'Current best weight: {self.max_step}.pt, best auc: {self.max_auc:.4f}')\n",
    "            # remove all weight file except {self.max_step}.pt\n",
    "                print(f\"Validation-- Best validaction acc is: {self.max_acc:.4f},\"\n",
    "                  f\"Best auc is:{self.max_auc:.4f}.\\n\")\n",
    "#             weight_list = os.listdir(self._weight_path)\n",
    "            # for w in weight_list:\n",
    "            #     if int(w[:-3]) != self.max_step:\n",
    "            #         os.unlink(f'{self._weight_path}{w}')\n",
    "        self._test('Validation', val_gen)\n",
    "    # get test results\n",
    "    def test(self, weight_num):\n",
    "        test_gen = data.DataLoader(\n",
    "            dataset=self._test_data, shuffle=False,\n",
    "            batch_size=ARGS.test_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "        # load best weight\n",
    "        if self.max_step != 0:\n",
    "            weight_num = self.max_step\n",
    "        weight_path = f'{ARGS.weight_path}{weight_num}.pt'\n",
    "        print(f'best weight: {weight_path}')\n",
    "        self._model.load_state_dict(torch.load(weight_path))\n",
    "        self._test('Test', test_gen)\n",
    "\n",
    "    def _forward(self, batch):\n",
    "#        batch = {k: t.to(self._device) for k, t in batch.items()}\n",
    "#        label = batch['label']  # shape: (batch_size, 1)\n",
    "\n",
    "#        output = self._model(batch['input'], batch['target_id'])\n",
    "\n",
    "        batch = tuple(t.to(self._device) for t in batch)\n",
    "        question_id, target_id, label = batch\n",
    "\n",
    "        output = self._model(question_id, target_id)\n",
    "        pred = (torch.sigmoid(output) >= self._threshold).long()  # shape: (batch_size, 1)\n",
    "        # 感觉这里的sigmoid加在output之前是不是会更好\n",
    "\n",
    "        return label, output, pred\n",
    "\n",
    "    def _get_loss(self, label, output):\n",
    "        # 这里的label我可以理解为是一个[0,1]序列，但是output却是上面_forward的output，不是一个（0，1）范围的值\n",
    "        # 是因为loss_fn里面有sigmoid\n",
    "        loss = self._loss_fn(output, label.float())\n",
    "        return loss.mean()\n",
    "\n",
    "    # takes iterator\n",
    "    def _train(self, batch_iter, num_batches):\n",
    "        start_time = time.time()\n",
    "        self._model.train()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        for batch in tqdm(batch_iter, total=num_batches):\n",
    "            label, out, pred = self._forward(batch)\n",
    "            train_loss = self._get_loss(label, out)\n",
    "            losses.append(train_loss.item())\n",
    "\n",
    "            self._opt.step(train_loss)\n",
    "\n",
    "            num_corrects += (pred == label).sum().item()\n",
    "            num_total += len(label)\n",
    "\n",
    "            labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "            outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / num_total\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        if self.step % ARGS.train_steps:\n",
    "            print(f\"Current Training step is: {self.step}\")\n",
    "            print(f'Training correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "            print(f'[Training]     time: {training_time:.2f}, loss: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "    # takes iterable\n",
    "    def _test(self, name, batches):\n",
    "        start_time = time.time()\n",
    "        self._model.eval()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(batches):\n",
    "                label, out, pred = self._forward(batch)\n",
    "                test_loss = self._get_loss(label, out)\n",
    "                losses.append(test_loss.item())\n",
    "\n",
    "                num_corrects += (pred == label).sum().item()\n",
    "                num_total += len(label)\n",
    "\n",
    "                labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "                outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / num_total\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        # training_time = time.time() - start_time\n",
    "\n",
    "        print(f'correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "        print(f' loss is: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "        if name == 'Validation':\n",
    "            if self.max_auc < auc:\n",
    "                self.max_auc = auc\n",
    "                self.max_acc = acc\n",
    "                self.max_step = self.step\n",
    "                torch.save(self._model.state_dict(), self._weight_path)\n",
    "\n",
    "        elif name == 'Test':\n",
    "            self.test_acc = acc\n",
    "            self.test_auc = auc\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:55.538383Z",
     "iopub.status.busy": "2020-11-18T14:46:55.537352Z",
     "iopub.status.idle": "2020-11-18T14:46:55.541048Z",
     "shell.execute_reply": "2020-11-18T14:46:55.540386Z"
    },
    "papermill": {
     "duration": 0.056619,
     "end_time": "2020-11-18T14:46:55.541169",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.484550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "train_dataloader = data.DataLoader(\n",
    "            dataset=train_data, shuffle=True,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "valid_dataloader = data.DataLoader(\n",
    "            dataset=val_data, shuffle=False,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:55.638549Z",
     "iopub.status.busy": "2020-11-18T14:46:55.637774Z",
     "iopub.status.idle": "2020-11-18T14:46:55.641883Z",
     "shell.execute_reply": "2020-11-18T14:46:55.641162Z"
    },
    "papermill": {
     "duration": 0.055062,
     "end_time": "2020-11-18T14:46:55.642012",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.586950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:55.825533Z",
     "iopub.status.busy": "2020-11-18T14:46:55.824407Z",
     "iopub.status.idle": "2020-11-18T14:46:55.828530Z",
     "shell.execute_reply": "2020-11-18T14:46:55.827806Z"
    },
    "papermill": {
     "duration": 0.140301,
     "end_time": "2020-11-18T14:46:55.828656",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.688355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "del(train_data)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:55.935699Z",
     "iopub.status.busy": "2020-11-18T14:46:55.934756Z",
     "iopub.status.idle": "2020-11-18T14:46:55.939987Z",
     "shell.execute_reply": "2020-11-18T14:46:55.939184Z"
    },
    "papermill": {
     "duration": 0.060953,
     "end_time": "2020-11-18T14:46:55.940117",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.879164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model,ARGS.device, ARGS.warm_up_step_count,\n",
    "                 ARGS.hidden_dim, ARGS.num_epochs, 'rid_model.pt',\n",
    "                 ARGS.lr, train_dataloader, valid_dataloader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:56.048235Z",
     "iopub.status.busy": "2020-11-18T14:46:56.047260Z",
     "iopub.status.idle": "2020-11-18T14:46:58.522414Z",
     "shell.execute_reply": "2020-11-18T14:46:58.521612Z"
    },
    "papermill": {
     "duration": 2.529104,
     "end_time": "2020-11-18T14:46:58.522552",
     "exception": false,
     "start_time": "2020-11-18T14:46:55.993448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.19it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training step is: 2\n",
      "Training correct predict num is: 936, total num is: 2500\n",
      "[Training]     time: 1.70, loss: 0.7224, acc: 0.3744, auc: 0.5219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predict num is: 916, total num is: 2500\n",
      " loss is: 0.7179, acc: 0.3664, auc: 0.5139\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:58.734865Z",
     "iopub.status.busy": "2020-11-18T14:46:58.733960Z",
     "iopub.status.idle": "2020-11-18T14:46:58.738539Z",
     "shell.execute_reply": "2020-11-18T14:46:58.739100Z"
    },
    "papermill": {
     "duration": 0.164234,
     "end_time": "2020-11-18T14:46:58.739261",
     "exception": false,
     "start_time": "2020-11-18T14:46:58.575027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(train_dataloader)\n",
    "del(valid_dataloader)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051753,
     "end_time": "2020-11-18T14:46:58.842912",
     "exception": false,
     "start_time": "2020-11-18T14:46:58.791159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:58.955137Z",
     "iopub.status.busy": "2020-11-18T14:46:58.953925Z",
     "iopub.status.idle": "2020-11-18T14:46:59.010579Z",
     "shell.execute_reply": "2020-11-18T14:46:59.011286Z"
    },
    "papermill": {
     "duration": 0.116636,
     "end_time": "2020-11-18T14:46:59.011448",
     "exception": false,
     "start_time": "2020-11-18T14:46:58.894812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " model = SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:59.123445Z",
     "iopub.status.busy": "2020-11-18T14:46:59.122600Z",
     "iopub.status.idle": "2020-11-18T14:46:59.140374Z",
     "shell.execute_reply": "2020-11-18T14:46:59.139471Z"
    },
    "papermill": {
     "duration": 0.076232,
     "end_time": "2020-11-18T14:46:59.140526",
     "exception": false,
     "start_time": "2020-11-18T14:46:59.064294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKT(\n",
       "  (_layers): ModuleList(\n",
       "    (0): SAKTLayer(\n",
       "      (_self_attn): MultiHeadedAttention(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (2): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (3): Linear(in_features=100, out_features=100, bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_ffn): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (w_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_layernorms): ModuleList(\n",
       "        (0): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_prediction): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (_positional_embedding): Embedding(21, 100, padding_idx=0)\n",
       "  (_interaction_embedding): Embedding(27047, 100, padding_idx=0)\n",
       "  (_question_embedding): Embedding(13524, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('rid_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:59.275333Z",
     "iopub.status.busy": "2020-11-18T14:46:59.274238Z",
     "iopub.status.idle": "2020-11-18T14:46:59.283574Z",
     "shell.execute_reply": "2020-11-18T14:46:59.282893Z"
    },
    "papermill": {
     "duration": 0.076717,
     "end_time": "2020-11-18T14:46:59.283708",
     "exception": false,
     "start_time": "2020-11-18T14:46:59.206991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "iter_test = env.iter_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:46:59.420645Z",
     "iopub.status.busy": "2020-11-18T14:46:59.419359Z",
     "iopub.status.idle": "2020-11-18T14:47:00.534186Z",
     "shell.execute_reply": "2020-11-18T14:47:00.533384Z"
    },
    "papermill": {
     "duration": 1.188067,
     "end_time": "2020-11-18T14:47:00.534349",
     "exception": false,
     "start_time": "2020-11-18T14:46:59.346282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.93it/s]\n"
     ]
    }
   ],
   "source": [
    "for(test_df, sample_prediction_df) in iter_test:\n",
    "    test_df['content_id'] = test_df['content_id'] + 1\n",
    "#     test_df = pd.merge(test_df, question_df, left_on='content_id', \n",
    "#                        right_on='question_id', how='left')\n",
    "    test_df = test_df.loc[:,['content_id','content_type_id',\n",
    "                             'row_id','user_id','timestamp']]\n",
    "#     test_df.drop(['content_id'], axis=1)\n",
    "#     test_df['answered_correctly_user'].fillna(0.5, inplace=True)\n",
    "#     test_df['answered_correctly_content'].fillna(0.5, inplace=True)\n",
    "#     test_df.drop(['part','prior_question_elapsed_time','prior_question_had_explanation'],axis=1)\n",
    "#     test_df['part'].fillna(4, inplace=True)\n",
    "#     test_df['prior_question_elapsed_time'].fillna(0.0, inplace = True)\n",
    "#     test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n",
    "#     test_df.fillna(0.0,inplace=True)\n",
    "#     question_df.fillna(0.0,inplace=True)\n",
    "#     train_data.combine.fillna(0.0,inplace=True)\n",
    "    test_df = test_df.loc[test_df['content_type_id'] == 0].reset_index(drop=True)\n",
    "    \n",
    "    test_dataset = UserSepDataSet_Rii_Test(test_df, user_dict2, is_test=True)\n",
    "    test_dataloader = data.DataLoader(\n",
    "            dataset=test_dataset, shuffle=False,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "    model =  SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)\n",
    "    model.load_state_dict(torch.load('rid_model.pt'))\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "            question_id, target_id = batch\n",
    "            output = model(question_id, target_id)\n",
    "            pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "            pred = pred.view(-1)\n",
    "            preds.extend(pred)\n",
    "        preds = [int(e) for e in preds]\n",
    "        test_df['answered_correctly'] =  preds\n",
    "        env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T14:47:00.659913Z",
     "iopub.status.busy": "2020-11-18T14:47:00.655379Z",
     "iopub.status.idle": "2020-11-18T14:47:00.665921Z",
     "shell.execute_reply": "2020-11-18T14:47:00.665284Z"
    },
    "papermill": {
     "duration": 0.073861,
     "end_time": "2020-11-18T14:47:00.666066",
     "exception": false,
     "start_time": "2020-11-18T14:47:00.592205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./submission.csv\")\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.058871,
     "end_time": "2020-11-18T14:47:00.783562",
     "exception": false,
     "start_time": "2020-11-18T14:47:00.724691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.058072,
     "end_time": "2020-11-18T14:47:00.900257",
     "exception": false,
     "start_time": "2020-11-18T14:47:00.842185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "duration": 164.914745,
   "end_time": "2020-11-18T14:47:01.168981",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-18T14:44:16.254236",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
