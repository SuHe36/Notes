{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:52.460300Z",
     "iopub.status.busy": "2020-11-18T08:28:52.459416Z",
     "iopub.status.idle": "2020-11-18T08:28:53.620041Z",
     "shell.execute_reply": "2020-11-18T08:28:53.619218Z"
    },
    "papermill": {
     "duration": 1.206924,
     "end_time": "2020-11-18T08:28:53.620208",
     "exception": false,
     "start_time": "2020-11-18T08:28:52.413284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import riiideducation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# env = riiideducation.make_env()\n",
    "# iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037676,
     "end_time": "2020-11-18T08:28:53.777632",
     "exception": false,
     "start_time": "2020-11-18T08:28:53.739956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ARGS参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:53.861618Z",
     "iopub.status.busy": "2020-11-18T08:28:53.860630Z",
     "iopub.status.idle": "2020-11-18T08:28:53.863765Z",
     "shell.execute_reply": "2020-11-18T08:28:53.863119Z"
    },
    "papermill": {
     "duration": 0.048874,
     "end_time": "2020-11-18T08:28:53.863887",
     "exception": false,
     "start_time": "2020-11-18T08:28:53.815013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args():\n",
    "    name = 'train'\n",
    "    model = 'SAKT'\n",
    "    num_layers = 1\n",
    "    hidden_dim=100\n",
    "    input_dim = 100\n",
    "    dropout = 0.2\n",
    "    num_head = 5\n",
    "    \n",
    "    random_seed = 1\n",
    "    num_epochs = 1\n",
    "    lr = 0.01\n",
    "    seq_size = 20\n",
    "    warm_up_step_count = 4000\n",
    "    eval_steps = 50000\n",
    "    train_steps = 50000\n",
    "    train_batch=2048\n",
    "    num_workers=4\n",
    "    device='cpu'\n",
    "    \n",
    "    \n",
    "ARGS = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:53.944927Z",
     "iopub.status.busy": "2020-11-18T08:28:53.943993Z",
     "iopub.status.idle": "2020-11-18T08:28:53.947241Z",
     "shell.execute_reply": "2020-11-18T08:28:53.946509Z"
    },
    "papermill": {
     "duration": 0.046037,
     "end_time": "2020-11-18T08:28:53.947363",
     "exception": false,
     "start_time": "2020-11-18T08:28:53.901326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PAD_INDEX = 0\n",
    "\n",
    "QUESTION_NUM = {\n",
    "    'riii':13523\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:54.031032Z",
     "iopub.status.busy": "2020-11-18T08:28:54.030113Z",
     "iopub.status.idle": "2020-11-18T08:28:55.143059Z",
     "shell.execute_reply": "2020-11-18T08:28:55.142425Z"
    },
    "papermill": {
     "duration": 1.158054,
     "end_time": "2020-11-18T08:28:55.143215",
     "exception": false,
     "start_time": "2020-11-18T08:28:53.985161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from itertools import repeat, chain, islice\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:55.245389Z",
     "iopub.status.busy": "2020-11-18T08:28:55.244281Z",
     "iopub.status.idle": "2020-11-18T08:28:55.247697Z",
     "shell.execute_reply": "2020-11-18T08:28:55.247121Z"
    },
    "papermill": {
     "duration": 0.066555,
     "end_time": "2020-11-18T08:28:55.247822",
     "exception": false,
     "start_time": "2020-11-18T08:28:55.181267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UserSepDataSet_Rii_Train(Dataset):\n",
    "\n",
    "    def __init__(self,user_dict):\n",
    "\n",
    "        self.user_dict = user_dict\n",
    "#         self.question_df = question_df\n",
    "\n",
    "#         self.combine = self.get_combine()\n",
    "        self.question_ids, self.target_ids, self.labels = self.get_data_for_train()\n",
    "\n",
    "\n",
    "    def get_data_for_train(self):\n",
    "        all_question_ids = []\n",
    "        all_labels= []\n",
    "        all_target_qids = []\n",
    "\n",
    "        for k,v in self.user_dict.items():\n",
    "            user_id = k\n",
    "            if len(v) != 2:\n",
    "                print(v)\n",
    "                continue\n",
    "            \n",
    "            question_ids = v[0]\n",
    "            answers = v[1]\n",
    "\n",
    "            assert len(question_ids) == len(answers)\n",
    "\n",
    "\n",
    "            for target_index in range(0, len(question_ids)):\n",
    "                qids = question_ids[:target_index + 1]\n",
    "                ans_flags = answers[:target_index + 1]\n",
    "\n",
    "                length = len(qids)\n",
    "                if length > ARGS.seq_size + 1:\n",
    "                    qids = qids[-(ARGS.seq_size + 1):]\n",
    "                    ans_flags = ans_flags[-(ARGS.seq_size + 1):]\n",
    "                    pad_counts = 0\n",
    "                else:\n",
    "                    pad_counts = ARGS.seq_size + 1 - length\n",
    "\n",
    "                input_list = []\n",
    "                for idx in range(len(qids)):\n",
    "                    # print(f\"idx is:{idx}, qids[idx] is:{qids[idx]}\")\n",
    "                    tag_id = qids[idx]\n",
    "                    is_correct = ans_flags[idx]\n",
    "\n",
    "                    if idx == len(qids) - 1:\n",
    "                        last_is_correct = is_correct\n",
    "                        target_id = tag_id\n",
    "                    else:\n",
    "                        if is_correct:\n",
    "                            input_list.append(tag_id)\n",
    "                        else:\n",
    "                            input_list.append(tag_id + QUESTION_NUM['riii'])\n",
    "\n",
    "                paddings = [PAD_INDEX]*pad_counts\n",
    "                input_list = paddings + input_list\n",
    "                assert len(input_list) == ARGS.seq_size\n",
    "\n",
    "                all_question_ids.append(input_list)\n",
    "                all_target_qids.append([target_id])\n",
    "                all_labels.append([last_is_correct])\n",
    "\n",
    "        return torch.LongTensor(all_question_ids), \\\n",
    "            torch.LongTensor(all_target_qids),\\\n",
    "            torch.LongTensor(all_labels)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.question_ids[index], self.target_ids[index], self.labels[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:55.345622Z",
     "iopub.status.busy": "2020-11-18T08:28:55.334266Z",
     "iopub.status.idle": "2020-11-18T08:28:55.367244Z",
     "shell.execute_reply": "2020-11-18T08:28:55.366450Z"
    },
    "papermill": {
     "duration": 0.081904,
     "end_time": "2020-11-18T08:28:55.367379",
     "exception": false,
     "start_time": "2020-11-18T08:28:55.285475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UserSepDataSet_Rii_Test(Dataset):\n",
    "\n",
    "    def __init__(self, test_df, user_dict, is_test=True):\n",
    "        self.test_df = test_df\n",
    "        \n",
    "        self.user_dict = user_dict\n",
    "        self.is_test = is_test\n",
    "        if self.is_test:\n",
    "            self.question_ids, self.target_ids = self.get_data_for_test()\n",
    "        else:\n",
    "            self.question_ids, self.target_ids, self.labels = self.get_data_for_valid()\n",
    "\n",
    "\n",
    "    def get_data_for_test(self):\n",
    "        all_question_ids = []\n",
    "        all_target_ids = []\n",
    "\n",
    "        for row in self.test_df.itertuples():\n",
    "            user_id = getattr(row, 'user_id')\n",
    "            q_id = getattr(row, 'content_id')\n",
    "           \n",
    "            # ans = getattr(row, 'answered_correctly')\n",
    "            # last_is_correct = ans\n",
    "            target_id = int(float(q_id))\n",
    "\n",
    "#             train_user = self.train_combine.loc[self.train_combine['user_id']==user_id]\n",
    "            if user_id in self.user_dict.keys():\n",
    "#                 timestamps = train_user['timestamp'].item().strip().split(',')\n",
    "#                 timestamps = [int(float(e.strip())) for e in timestamps]\n",
    "\n",
    "                qids = self.user_dict[user_id][0]\n",
    "#                 qids = [int(float(e.strip())) for e in q_ids]\n",
    "\n",
    "#                 answers = train_user['answered_correctly'].item().strip().split(',')\n",
    "                ans_flags = self.user_dict[user_id][1]\n",
    "\n",
    "                assert len(qids) == len(ans_flags)\n",
    "               \n",
    "\n",
    "                length = len(qids)\n",
    "                if length > ARGS.seq_size:\n",
    "                    qids = qids[-ARGS.seq_size:]\n",
    "                    ans_flags =  ans_flags[-ARGS.seq_size:]\n",
    "                    pad_counts = 0\n",
    "                else:\n",
    "                    pad_counts = ARGS.seq_size - length\n",
    "\n",
    "                input_list = []\n",
    "                for idx in range(len(qids)):\n",
    "                    tag_id = qids[idx]\n",
    "                    is_correct = ans_flags[idx]\n",
    "\n",
    "                    if is_correct:\n",
    "                        input_list.append(tag_id)\n",
    "                    else:\n",
    "                        input_list.append(tag_id + QUESTION_NUM['riii'])\n",
    "\n",
    "                paddings = [PAD_INDEX]*pad_counts\n",
    "                input_list = paddings + input_list\n",
    "                assert len(input_list) == ARGS.seq_size\n",
    "\n",
    "            else:\n",
    "                input_list = [PAD_INDEX] * ARGS.seq_size\n",
    "\n",
    "            all_question_ids.append(input_list)\n",
    "            all_target_ids.append([target_id])\n",
    "\n",
    "        return torch.LongTensor(all_question_ids), \\\n",
    "            torch.LongTensor(all_target_ids),\n",
    "\n",
    "\n",
    "\n",
    "    def get_data_for_valid(self):\n",
    "        all_question_ids = []\n",
    "        all_labels = []\n",
    "        all_target_ids = []\n",
    "\n",
    "        for row in self.test_df.itertuples():\n",
    "            user_id = getattr(row, 'user_id')\n",
    "            q_id = getattr(row, 'content_id')\n",
    "#             timestamp = getattr(row, 'timestamp')\n",
    "            ans = getattr(row, 'answered_correctly')\n",
    "            last_is_correct = ans\n",
    "            target_id = int(float(q_id))\n",
    "            if target_id > 13523:\n",
    "                print(\"user_id:{}, q_id:{}\".format(user_id, q_id))\n",
    "\n",
    "#             train_user = self.train_combine.loc[self.train_combine['user_id']==user_id]\n",
    "            if user_id in self.user_dict.keys():\n",
    "                # print(\"Bingo\")\n",
    "#                 timestamps = train_user['timestamp'].item().strip().split(',')\n",
    "#                 timestamps = [int(float(e.strip())) for e in timestamps]\n",
    "\n",
    "#                 q_ids = train_user['question_id'].item().strip().split(',')\n",
    "                qids = self.user_dict[user_id][0]\n",
    "\n",
    "#                 answers = train_user['answered_correctly'].item().strip().split(',')\n",
    "                ans_flags = self.user_dict[user_id][1]\n",
    "    \n",
    "                assert len(qids)  == len(ans_flags)\n",
    "\n",
    "\n",
    "                length = len(qids)\n",
    "                if length > ARGS.seq_size:\n",
    "                    qids = qids[-ARGS.seq_size:]\n",
    "                    ans_flags =  ans_flags[-ARGS.seq_size:]\n",
    "                    pad_counts = 0\n",
    "                else:\n",
    "                    pad_counts = ARGS.seq_size - length\n",
    "\n",
    "                input_list = []\n",
    "                for idx in range(len(qids)):\n",
    "                    tag_id = qids[idx]\n",
    "                    is_correct = ans_flags[idx]\n",
    "\n",
    "                    if is_correct:\n",
    "                        input_list.append(tag_id)\n",
    "                    else:\n",
    "                        input_list.append(tag_id + QUESTION_NUM['riii'])\n",
    "\n",
    "                paddings = [PAD_INDEX]*pad_counts\n",
    "                input_list = paddings + input_list\n",
    "                assert len(input_list) == ARGS.seq_size\n",
    "\n",
    "            else:\n",
    "                input_list = [PAD_INDEX] * ARGS.seq_size\n",
    "\n",
    "            all_question_ids.append(input_list)\n",
    "            all_target_ids.append([target_id])\n",
    "            all_labels.append([last_is_correct])\n",
    "\n",
    "        return torch.LongTensor(all_question_ids), \\\n",
    "            torch.LongTensor(all_target_ids), \\\n",
    "            torch.LongTensor(all_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.question_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.is_test:\n",
    "            return self.question_ids[index], self.target_ids[index]\n",
    "        else:\n",
    "            return self.question_ids[index], self.target_ids[index], self.labels[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:55.449532Z",
     "iopub.status.busy": "2020-11-18T08:28:55.448763Z",
     "iopub.status.idle": "2020-11-18T08:28:55.452070Z",
     "shell.execute_reply": "2020-11-18T08:28:55.451349Z"
    },
    "papermill": {
     "duration": 0.0465,
     "end_time": "2020-11-18T08:28:55.452210",
     "exception": false,
     "start_time": "2020-11-18T08:28:55.405710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_csv = '/Users/hesu/Documents/KT/riiid/train.csv'\n",
    "que_csv = '/Users/hesu/Documents/KT/riiid/questions.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:28:55.553425Z",
     "iopub.status.busy": "2020-11-18T08:28:55.552168Z",
     "iopub.status.idle": "2020-11-18T08:30:56.907758Z",
     "shell.execute_reply": "2020-11-18T08:30:56.906919Z"
    },
    "papermill": {
     "duration": 121.413208,
     "end_time": "2020-11-18T08:30:56.907896",
     "exception": false,
     "start_time": "2020-11-18T08:28:55.494688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_csv, usecols = [1,2,3,4,7],\n",
    "                   dtype={'timestamp':'int64',\n",
    "                         'used_id':'int16',\n",
    "                         'content_id':'int16',\n",
    "                         'content_type_id':'int8',\n",
    "                         'answered_correctly':'int8'})\n",
    "\n",
    "train_df = train_df[train_df.content_type_id == False]\n",
    "train_df['content_id'] = train_df['content_id'].fillna(-1)\n",
    "train_df['content_id'] = train_df['content_id'] + 1\n",
    "\n",
    "train_df['timestamp'] = train_df['timestamp'].fillna(0)\n",
    "train_df = train_df.sort_values(['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:30:56.992492Z",
     "iopub.status.busy": "2020-11-18T08:30:56.991695Z",
     "iopub.status.idle": "2020-11-18T08:31:15.064880Z",
     "shell.execute_reply": "2020-11-18T08:31:15.065541Z"
    },
    "papermill": {
     "duration": 18.118955,
     "end_time": "2020-11-18T08:31:15.065806",
     "exception": false,
     "start_time": "2020-11-18T08:30:56.946851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sample(frac=1.0)\n",
    "train = train_df.iloc[-12500:-250]\n",
    "valid = train_df.iloc[-250:]\n",
    "test_df = train_df.iloc[:8000000]\n",
    "del(train_df)\n",
    "gc.collect()\n",
    "\n",
    "# train = train.sort_values(['timestamp'], ascending=True).reset_index(drop=True)\n",
    "# valid = valid.sort_values(['timestamp'], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:31:15.154962Z",
     "iopub.status.busy": "2020-11-18T08:31:15.154196Z",
     "iopub.status.idle": "2020-11-18T08:31:15.172417Z",
     "shell.execute_reply": "2020-11-18T08:31:15.171709Z"
    },
    "papermill": {
     "duration": 0.065795,
     "end_time": "2020-11-18T08:31:15.172550",
     "exception": false,
     "start_time": "2020-11-18T08:31:15.106755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "question_df = pd.read_csv(que_csv)\n",
    "question_df['question_id'] = question_df['question_id'].fillna(-1)\n",
    "question_df['question_id'] = question_df['question_id'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:31:15.263483Z",
     "iopub.status.busy": "2020-11-18T08:31:15.262691Z",
     "iopub.status.idle": "2020-11-18T08:31:15.273727Z",
     "shell.execute_reply": "2020-11-18T08:31:15.272985Z"
    },
    "papermill": {
     "duration": 0.0616,
     "end_time": "2020-11-18T08:31:15.273859",
     "exception": false,
     "start_time": "2020-11-18T08:31:15.212259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54091472</th>\n",
       "      <td>3323757559</td>\n",
       "      <td>998657470</td>\n",
       "      <td>10936</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33170468</th>\n",
       "      <td>1044953640</td>\n",
       "      <td>1975243972</td>\n",
       "      <td>10230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12335341</th>\n",
       "      <td>69752617</td>\n",
       "      <td>399735812</td>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56764147</th>\n",
       "      <td>3790129915</td>\n",
       "      <td>894020367</td>\n",
       "      <td>9531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8037738</th>\n",
       "      <td>1387007</td>\n",
       "      <td>1755186732</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37478088</th>\n",
       "      <td>1382435438</td>\n",
       "      <td>1103222398</td>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30901611</th>\n",
       "      <td>877391852</td>\n",
       "      <td>1231958138</td>\n",
       "      <td>478</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94959104</th>\n",
       "      <td>34799641480</td>\n",
       "      <td>1304922436</td>\n",
       "      <td>10403</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81722246</th>\n",
       "      <td>14858187701</td>\n",
       "      <td>1390421632</td>\n",
       "      <td>6607</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89729567</th>\n",
       "      <td>23629154870</td>\n",
       "      <td>532085896</td>\n",
       "      <td>12272</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     user_id  content_id  content_type_id  \\\n",
       "54091472   3323757559   998657470       10936                0   \n",
       "33170468   1044953640  1975243972       10230                0   \n",
       "12335341     69752617   399735812        1297                0   \n",
       "56764147   3790129915   894020367        9531                0   \n",
       "8037738       1387007  1755186732         803                0   \n",
       "37478088   1382435438  1103222398         767                0   \n",
       "30901611    877391852  1231958138         478                0   \n",
       "94959104  34799641480  1304922436       10403                0   \n",
       "81722246  14858187701  1390421632        6607                0   \n",
       "89729567  23629154870   532085896       12272                0   \n",
       "\n",
       "          answered_correctly  \n",
       "54091472                   1  \n",
       "33170468                   0  \n",
       "12335341                   1  \n",
       "56764147                   0  \n",
       "8037738                    1  \n",
       "37478088                   0  \n",
       "30901611                   0  \n",
       "94959104                   1  \n",
       "81722246                   1  \n",
       "89729567                   1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:31:15.363014Z",
     "iopub.status.busy": "2020-11-18T08:31:15.362252Z",
     "iopub.status.idle": "2020-11-18T08:32:03.701405Z",
     "shell.execute_reply": "2020-11-18T08:32:03.701997Z"
    },
    "papermill": {
     "duration": 48.387856,
     "end_time": "2020-11-18T08:32:03.702188",
     "exception": false,
     "start_time": "2020-11-18T08:31:15.314332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user = pd.merge(train, question_df,left_on=\"content_id\", right_on='question_id', how='left')\n",
    "user_dict = train_user.groupby('user_id')[['question_id','answered_correctly']].apply(\n",
    "    lambda g:g.values.tolist()).to_dict()\n",
    "del(train)\n",
    "del(question_df)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:32:03.789055Z",
     "iopub.status.busy": "2020-11-18T08:32:03.788294Z",
     "iopub.status.idle": "2020-11-18T08:32:03.791693Z",
     "shell.execute_reply": "2020-11-18T08:32:03.791013Z"
    },
    "papermill": {
     "duration": 0.048806,
     "end_time": "2020-11-18T08:32:03.791818",
     "exception": false,
     "start_time": "2020-11-18T08:32:03.743012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# user_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:32:03.880469Z",
     "iopub.status.busy": "2020-11-18T08:32:03.879412Z",
     "iopub.status.idle": "2020-11-18T08:32:03.882961Z",
     "shell.execute_reply": "2020-11-18T08:32:03.883609Z"
    },
    "papermill": {
     "duration": 0.050839,
     "end_time": "2020-11-18T08:32:03.883766",
     "exception": false,
     "start_time": "2020-11-18T08:32:03.832927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10817"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:32:03.985418Z",
     "iopub.status.busy": "2020-11-18T08:32:03.980322Z",
     "iopub.status.idle": "2020-11-18T08:32:08.748709Z",
     "shell.execute_reply": "2020-11-18T08:32:08.747844Z"
    },
    "papermill": {
     "duration": 4.823675,
     "end_time": "2020-11-18T08:32:08.748851",
     "exception": false,
     "start_time": "2020-11-18T08:32:03.925176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "user_dict2 = dict()\n",
    "for k, v in user_dict.items():\n",
    "    ques = []\n",
    "    ans = []\n",
    "    \n",
    "    for e in v:\n",
    "        ques.append(e[0])\n",
    "        ans.append(e[1])\n",
    "    user_dict2[k] = [ques, ans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:32:08.863720Z",
     "iopub.status.busy": "2020-11-18T08:32:08.842869Z",
     "iopub.status.idle": "2020-11-18T08:35:06.863968Z",
     "shell.execute_reply": "2020-11-18T08:35:06.863280Z"
    },
    "papermill": {
     "duration": 178.072158,
     "end_time": "2020-11-18T08:35:06.864162",
     "exception": false,
     "start_time": "2020-11-18T08:32:08.792004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = UserSepDataSet_Rii_Train(user_dict2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:35:07.984426Z",
     "iopub.status.busy": "2020-11-18T08:35:07.529994Z",
     "iopub.status.idle": "2020-11-18T08:35:07.989358Z",
     "shell.execute_reply": "2020-11-18T08:35:07.988614Z"
    },
    "papermill": {
     "duration": 1.08289,
     "end_time": "2020-11-18T08:35:07.989480",
     "exception": false,
     "start_time": "2020-11-18T08:35:06.906590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(user_dict)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:35:08.116354Z",
     "iopub.status.busy": "2020-11-18T08:35:08.095629Z",
     "iopub.status.idle": "2020-11-18T08:36:05.847477Z",
     "shell.execute_reply": "2020-11-18T08:36:05.846786Z"
    },
    "papermill": {
     "duration": 57.815218,
     "end_time": "2020-11-18T08:36:05.847631",
     "exception": false,
     "start_time": "2020-11-18T08:35:08.032413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_data = UserSepDataSet_Rii_Test(valid, user_dict2, is_test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:05.941368Z",
     "iopub.status.busy": "2020-11-18T08:36:05.940269Z",
     "iopub.status.idle": "2020-11-18T08:36:05.945244Z",
     "shell.execute_reply": "2020-11-18T08:36:05.944448Z"
    },
    "papermill": {
     "duration": 0.054694,
     "end_time": "2020-11-18T08:36:05.945384",
     "exception": false,
     "start_time": "2020-11-18T08:36:05.890690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12250"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:06.039145Z",
     "iopub.status.busy": "2020-11-18T08:36:06.038012Z",
     "iopub.status.idle": "2020-11-18T08:36:06.042609Z",
     "shell.execute_reply": "2020-11-18T08:36:06.041969Z"
    },
    "papermill": {
     "duration": 0.053705,
     "end_time": "2020-11-18T08:36:06.042737",
     "exception": false,
     "start_time": "2020-11-18T08:36:05.989032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044702,
     "end_time": "2020-11-18T08:36:06.132137",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.087435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SAKT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043683,
     "end_time": "2020-11-18T08:36:06.220576",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.176893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:06.320243Z",
     "iopub.status.busy": "2020-11-18T08:36:06.319285Z",
     "iopub.status.idle": "2020-11-18T08:36:06.322449Z",
     "shell.execute_reply": "2020-11-18T08:36:06.321830Z"
    },
    "papermill": {
     "duration": 0.057905,
     "end_time": "2020-11-18T08:36:06.322578",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.264673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pad_mask(seq, pad_idx):\n",
    "    return (seq != pad_idx).unsqueeze(-2)\n",
    "\n",
    "\n",
    "def get_subsequent_mask(seq):\n",
    "    ''' For masking out the subsequent info. '''\n",
    "    sz_b, len_s = seq.size()\n",
    "    subsequent_mask = (1 - torch.triu(torch.ones((1, len_s, len_s), device=seq.device), diagonal=1)).bool()\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:06.422226Z",
     "iopub.status.busy": "2020-11-18T08:36:06.421194Z",
     "iopub.status.idle": "2020-11-18T08:36:06.424154Z",
     "shell.execute_reply": "2020-11-18T08:36:06.424682Z"
    },
    "papermill": {
     "duration": 0.05703,
     "end_time": "2020-11-18T08:36:06.424851",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.367821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:06.560360Z",
     "iopub.status.busy": "2020-11-18T08:36:06.554294Z",
     "iopub.status.idle": "2020-11-18T08:36:06.564023Z",
     "shell.execute_reply": "2020-11-18T08:36:06.563393Z"
    },
    "papermill": {
     "duration": 0.095024,
     "end_time": "2020-11-18T08:36:06.564175",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.469151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model, bias=False), 4) # Q, K, V, last\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "class SAKTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Single Encoder block of SAKT\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._self_attn = MultiHeadedAttention(num_head, hidden_dim, dropout)\n",
    "        self._ffn = PositionwiseFeedForward(hidden_dim, hidden_dim, dropout)\n",
    "        self._layernorms = clones(nn.LayerNorm(hidden_dim, eps=1e-6), 2)\n",
    "\n",
    "    def forward(self, query, key, mask=None):\n",
    "        \"\"\"\n",
    "        query: question embeddings\n",
    "        key: interaction embeddings\n",
    "        \"\"\"\n",
    "        # self-attention block\n",
    "        output = self._self_attn(query=query, key=key, value=key, mask=mask)\n",
    "        output = self._layernorms[0](key + output)\n",
    "        # feed-forward block\n",
    "        output = self._layernorms[1](output + self._ffn(output))\n",
    "        return output\n",
    "\n",
    "\n",
    "class SAKT(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer-based\n",
    "    all hidden dimensions (d_k, d_v, ...) are the same as hidden_dim\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, question_num, num_layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self._question_num = question_num\n",
    "        # question_num的值是110\n",
    "        # Blocks\n",
    "        self._layers = clones(SAKTLayer(hidden_dim, num_head, dropout), num_layers)\n",
    "\n",
    "        # prediction layer\n",
    "        self._prediction = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # Embedding layers\n",
    "        self._positional_embedding = nn.Embedding(ARGS.seq_size+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        self._interaction_embedding = nn.Embedding(2*question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "        # 这个就是包含了qid对错信息的矩阵\n",
    "        self._question_embedding = nn.Embedding(question_num+1, hidden_dim, padding_idx=PAD_INDEX)\n",
    "\n",
    "    def _transform_interaction_to_question_id(self, interaction):\n",
    "        \"\"\"\n",
    "        get question_id from interaction index\n",
    "        if interaction index is a number in [0, question_num], then leave it as-is\n",
    "        if interaction index is bigger than question_num (in [question_num + 1, 2 * question_num]\n",
    "        then subtract question_num\n",
    "        interaction: integer tensor of shape (batch_size, sequence_size)\n",
    "        \"\"\"\n",
    "        return interaction - self._question_num * (interaction > self._question_num).long()\n",
    "\n",
    "    def _get_position_index(self, question_id):\n",
    "        \"\"\"\n",
    "        [0, 0, 0, 4, 12] -> [0, 0, 0, 1, 2]\n",
    "        \"\"\"\n",
    "        batch_size = question_id.shape[0]\n",
    "        position_indices = []\n",
    "        for i in range(batch_size):\n",
    "            non_padding_num = (question_id[i] != PAD_INDEX).sum(-1).item()\n",
    "            position_index = [0] * (ARGS.seq_size - non_padding_num) + list(range(1, non_padding_num+1))\n",
    "            position_indices.append(position_index)\n",
    "        return torch.tensor(position_indices, dtype=int).to(ARGS.device)\n",
    "\n",
    "    def forward(self, interaction_id, target_id):\n",
    "        \"\"\"\n",
    "        Query: Question (skill, exercise, ...) embedding\n",
    "        Key, Value: Interaction embedding + positional embedding\n",
    "        \"\"\"\n",
    "        question_id = self._transform_interaction_to_question_id(interaction_id)\n",
    "        # 这个question_id就是把以前把统一qid由于对错不同对应不同id，转换成同一qid\n",
    "        # 也就是把qid数值大于q_num的，减去q_num\n",
    "        question_id = torch.cat([question_id[:, 1:], target_id], dim=-1)\n",
    "        # question_id的原来的维度是(batch, seq_len)，\n",
    "        # 然后那两个:，第一个表示在第一个维度全选\n",
    "        # 第二个1:，表示第二个维度从第一个元素选起，这主要是为了和target_id合并在一起\n",
    "\n",
    "        # 这时question_id和interaction_id存在着一个错位的问题，\n",
    "        # 也就是question_id包含了当前target_id,而interaction_id中不包含\n",
    "\n",
    "        interaction_vector = self._interaction_embedding(interaction_id)\n",
    "        question_vector = self._question_embedding(question_id)\n",
    "\n",
    "        position_index = self._get_position_index(question_id)\n",
    "        # 对于question_id获取position的下标\n",
    "        position_vector = self._positional_embedding(position_index)\n",
    "\n",
    "        mask = get_pad_mask(question_id, PAD_INDEX) & get_subsequent_mask(question_id)\n",
    "        x = interaction_vector + position_vector\n",
    "        # 这个position_vector只加给了interaction_vector向量\n",
    "        # x的维度是(batch, seq_len, hidden)\n",
    "        for layer in self._layers:\n",
    "            x = layer(query=question_vector, key=x, mask=mask)\n",
    "\n",
    "        output = self._prediction(x)\n",
    "        # 这里的output为什么会是一个三维的向量呢\n",
    "        output = output[:, -1, :]\n",
    "        # output的最初维度是(batch, seq_len, 1)\n",
    "        # 然后用[:,-1,:]只取seq_len的最后一个值\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:06.662017Z",
     "iopub.status.busy": "2020-11-18T08:36:06.661254Z",
     "iopub.status.idle": "2020-11-18T08:36:06.669749Z",
     "shell.execute_reply": "2020-11-18T08:36:06.669054Z"
    },
    "papermill": {
     "duration": 0.061141,
     "end_time": "2020-11-18T08:36:06.669880",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.608739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ARGS.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed(ARGS.random_seed)\n",
    "torch.cuda.manual_seed_all(ARGS.random_seed)\n",
    "random.seed(ARGS.random_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:06.772940Z",
     "iopub.status.busy": "2020-11-18T08:36:06.770668Z",
     "iopub.status.idle": "2020-11-18T08:36:06.899432Z",
     "shell.execute_reply": "2020-11-18T08:36:06.898206Z"
    },
    "papermill": {
     "duration": 0.18485,
     "end_time": "2020-11-18T08:36:06.899575",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.714725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " model = SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045556,
     "end_time": "2020-11-18T08:36:07.002783",
     "exception": false,
     "start_time": "2020-11-18T08:36:06.957227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.044694,
     "end_time": "2020-11-18T08:36:07.096594",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.051900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.045059,
     "end_time": "2020-11-18T08:36:07.192842",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.147783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.044491,
     "end_time": "2020-11-18T08:36:07.282327",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.237836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:07.400470Z",
     "iopub.status.busy": "2020-11-18T08:36:07.399371Z",
     "iopub.status.idle": "2020-11-18T08:36:07.402429Z",
     "shell.execute_reply": "2020-11-18T08:36:07.401550Z"
    },
    "papermill": {
     "duration": 0.073744,
     "end_time": "2020-11-18T08:36:07.402582",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.328838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class ScheduledOptim():\n",
    "    '''A simple wrapper class for learning rate scheduling'''\n",
    "    def __init__(self, optimizer, d_model, n_warmup_steps):\n",
    "        self._optimizer = optimizer\n",
    "        self.n_warmup_steps = n_warmup_steps\n",
    "        self.n_current_steps = 0\n",
    "        self.init_lr = np.power(d_model, -0.5)\n",
    "\n",
    "    def step_and_update_lr(self):\n",
    "        \"Step with the inner optimizer\"\n",
    "        self._update_learning_rate()\n",
    "        self._optimizer.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"Zero out the gradients by the inner optimizer\"\n",
    "        self._optimizer.zero_grad()\n",
    "\n",
    "    def _get_lr_scale(self):\n",
    "        return np.min([\n",
    "            np.power(self.n_current_steps, -0.5),\n",
    "            np.power(self.n_warmup_steps, -1.5) * self.n_current_steps\n",
    "        ])\n",
    "\n",
    "    def _update_learning_rate(self):\n",
    "        ''' Learning rate scheduling per step '''\n",
    "\n",
    "        self.n_current_steps += 1\n",
    "        lr = self.init_lr * self._get_lr_scale()\n",
    "\n",
    "        for param_group in self._optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "\n",
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def rate(self, step=None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "               (self.model_size ** (-0.5) *\n",
    "                min(step ** (-0.5), step * self.warmup ** (-1.5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:07.553957Z",
     "iopub.status.busy": "2020-11-18T08:36:07.519947Z",
     "iopub.status.idle": "2020-11-18T08:36:07.556872Z",
     "shell.execute_reply": "2020-11-18T08:36:07.557623Z"
    },
    "papermill": {
     "duration": 0.105882,
     "end_time": "2020-11-18T08:36:07.557840",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.451958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoamOptimizer:\n",
    "    def __init__(self, model, lr, model_size, warmup):\n",
    "        self._adam = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        self._opt = NoamOpt(\n",
    "            model_size=model_size, factor=1, warmup=warmup, optimizer=self._adam)\n",
    "\n",
    "    def step(self, loss):\n",
    "        self._opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self._opt.step()\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, device, warm_up_step_count,\n",
    "                 d_model, num_epochs, weight_path, lr,\n",
    "                 train_data, val_data, test_data=None):\n",
    "        self._device = device\n",
    "        self._num_epochs = num_epochs\n",
    "        self._weight_path = weight_path\n",
    "\n",
    "        self._model = model\n",
    "        self._loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
    "        self._model.to(device)\n",
    "\n",
    "        self._train_data = train_data\n",
    "        self._val_data = val_data\n",
    "        self._test_data = test_data\n",
    "\n",
    "        self._opt = NoamOptimizer(model=model, lr=lr, model_size=d_model, warmup=warm_up_step_count)\n",
    "\n",
    "        self.step = 0\n",
    "        self._threshold = 0.5\n",
    "        self.max_step = 0\n",
    "        self.max_acc = 0.0\n",
    "        self.max_auc = 0.0\n",
    "\n",
    "        self.test_acc = 0.0\n",
    "        self.test_auc = 0.0\n",
    "\n",
    "    # train model and choose weight with max auc on validation dataset\n",
    "    def train(self):\n",
    "        train_gen = self._train_data\n",
    "        val_gen = self._val_data\n",
    "\n",
    "        # will train self._num_epochs copies of train data\n",
    "        to_train = chain.from_iterable(repeat(train_gen, self._num_epochs))\n",
    "        # consisting of total_steps batches\n",
    "        total_steps = len(train_gen) * self._num_epochs\n",
    "        print(\"total_steps:\",total_steps)\n",
    "\n",
    "        self.step = 0\n",
    "        while self.step < total_steps:\n",
    "            rem_steps = total_steps - self.step\n",
    "            num_steps = min(rem_steps, ARGS.train_steps)\n",
    "            self.step += num_steps\n",
    "\n",
    "            # take num_steps batches from to_train stream\n",
    "            train_batches = islice(to_train, num_steps)\n",
    "            # print(f'Step: {self.step}')\n",
    "#            print(f\"Current Training step is: {self.step}\")\n",
    "            self._train(train_batches, num_steps)\n",
    "            if self.step % ARGS.eval_steps == 0:\n",
    "                cur_weight = self._model.state_dict()\n",
    "#                 torch.save(cur_weight, f'{self._weight_path}{self.step}.pt')\n",
    "                self._test('Validation', val_gen)\n",
    "            # print(f'Current best weight: {self.max_step}.pt, best auc: {self.max_auc:.4f}')\n",
    "            # remove all weight file except {self.max_step}.pt\n",
    "                print(f\"Validation-- Best validaction acc is: {self.max_acc:.4f},\"\n",
    "                  f\"Best auc is:{self.max_auc:.4f}.\\n\")\n",
    "#             weight_list = os.listdir(self._weight_path)\n",
    "            # for w in weight_list:\n",
    "            #     if int(w[:-3]) != self.max_step:\n",
    "            #         os.unlink(f'{self._weight_path}{w}')\n",
    "        self._test('Validation', val_gen)\n",
    "    # get test results\n",
    "    def test(self, weight_num):\n",
    "        test_gen = data.DataLoader(\n",
    "            dataset=self._test_data, shuffle=False,\n",
    "            batch_size=ARGS.test_batch, num_workers=ARGS.num_workers)\n",
    "\n",
    "        # load best weight\n",
    "        if self.max_step != 0:\n",
    "            weight_num = self.max_step\n",
    "        weight_path = f'{ARGS.weight_path}{weight_num}.pt'\n",
    "        print(f'best weight: {weight_path}')\n",
    "        self._model.load_state_dict(torch.load(weight_path))\n",
    "        self._test('Test', test_gen)\n",
    "\n",
    "    def _forward(self, batch):\n",
    "#        batch = {k: t.to(self._device) for k, t in batch.items()}\n",
    "#        label = batch['label']  # shape: (batch_size, 1)\n",
    "\n",
    "#        output = self._model(batch['input'], batch['target_id'])\n",
    "\n",
    "        batch = tuple(t.to(self._device) for t in batch)\n",
    "        question_id, target_id, label = batch\n",
    "\n",
    "        output = self._model(question_id, target_id)\n",
    "        pred = (torch.sigmoid(output) >= self._threshold).long()  # shape: (batch_size, 1)\n",
    "        # 感觉这里的sigmoid加在output之前是不是会更好\n",
    "\n",
    "        return label, output, pred\n",
    "\n",
    "    def _get_loss(self, label, output):\n",
    "        # 这里的label我可以理解为是一个[0,1]序列，但是output却是上面_forward的output，不是一个（0，1）范围的值\n",
    "        # 是因为loss_fn里面有sigmoid\n",
    "        loss = self._loss_fn(output, label.float())\n",
    "        return loss.mean()\n",
    "\n",
    "    # takes iterator\n",
    "    def _train(self, batch_iter, num_batches):\n",
    "        start_time = time.time()\n",
    "        self._model.train()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        for batch in tqdm(batch_iter, total=num_batches):\n",
    "            label, out, pred = self._forward(batch)\n",
    "            train_loss = self._get_loss(label, out)\n",
    "            losses.append(train_loss.item())\n",
    "\n",
    "            self._opt.step(train_loss)\n",
    "\n",
    "            num_corrects += (pred == label).sum().item()\n",
    "            num_total += len(label)\n",
    "\n",
    "            labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "            outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / (num_total + 1e-9)\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        if self.step % ARGS.train_steps:\n",
    "            print(f\"Current Training step is: {self.step}\")\n",
    "            print(f'Training correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "            print(f'[Training]     time: {training_time:.2f}, loss: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "    # takes iterable\n",
    "    def _test(self, name, batches):\n",
    "        start_time = time.time()\n",
    "        self._model.eval()\n",
    "\n",
    "        losses = []\n",
    "        num_corrects = 0\n",
    "        num_total = 0\n",
    "        labels = []\n",
    "        outs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(batches):\n",
    "                label, out, pred = self._forward(batch)\n",
    "                test_loss = self._get_loss(label, out)\n",
    "                losses.append(test_loss.item())\n",
    "\n",
    "                num_corrects += (pred == label).sum().item()\n",
    "                num_total += len(label)\n",
    "\n",
    "                labels.extend(label.squeeze(-1).data.cpu().numpy())\n",
    "                outs.extend(out.squeeze(-1).data.cpu().numpy())\n",
    "\n",
    "        acc = num_corrects / (num_total + 1e-9)\n",
    "        auc = roc_auc_score(labels, outs)\n",
    "        loss = np.mean(losses)\n",
    "        # training_time = time.time() - start_time\n",
    "\n",
    "        print(f'correct predict num is: {num_corrects}, total num is: {num_total}')\n",
    "        print(f' loss is: {loss:.4f}, acc: {acc:.4f}, auc: {auc:.4f}')\n",
    "\n",
    "        if name == 'Validation':\n",
    "            if self.max_auc < auc:\n",
    "                self.max_auc = auc\n",
    "                self.max_acc = acc\n",
    "                self.max_step = self.step\n",
    "                torch.save(self._model.state_dict(), self._weight_path)\n",
    "\n",
    "        elif name == 'Test':\n",
    "            self.test_acc = acc\n",
    "            self.test_auc = auc\n",
    "\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:07.666981Z",
     "iopub.status.busy": "2020-11-18T08:36:07.666036Z",
     "iopub.status.idle": "2020-11-18T08:36:07.668745Z",
     "shell.execute_reply": "2020-11-18T08:36:07.669361Z"
    },
    "papermill": {
     "duration": 0.060151,
     "end_time": "2020-11-18T08:36:07.669528",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.609377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "train_dataloader = data.DataLoader(\n",
    "            dataset=train_data, shuffle=True,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "valid_dataloader = data.DataLoader(\n",
    "            dataset=val_data, shuffle=False,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:07.767148Z",
     "iopub.status.busy": "2020-11-18T08:36:07.766024Z",
     "iopub.status.idle": "2020-11-18T08:36:07.769729Z",
     "shell.execute_reply": "2020-11-18T08:36:07.769119Z"
    },
    "papermill": {
     "duration": 0.054597,
     "end_time": "2020-11-18T08:36:07.769863",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.715266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:08.319840Z",
     "iopub.status.busy": "2020-11-18T08:36:08.319049Z",
     "iopub.status.idle": "2020-11-18T08:36:08.324741Z",
     "shell.execute_reply": "2020-11-18T08:36:08.324160Z"
    },
    "papermill": {
     "duration": 0.508535,
     "end_time": "2020-11-18T08:36:08.324870",
     "exception": false,
     "start_time": "2020-11-18T08:36:07.816335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "del(train_data)\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:08.424699Z",
     "iopub.status.busy": "2020-11-18T08:36:08.423788Z",
     "iopub.status.idle": "2020-11-18T08:36:08.427571Z",
     "shell.execute_reply": "2020-11-18T08:36:08.426842Z"
    },
    "papermill": {
     "duration": 0.056149,
     "end_time": "2020-11-18T08:36:08.427712",
     "exception": false,
     "start_time": "2020-11-18T08:36:08.371563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model,ARGS.device, ARGS.warm_up_step_count,\n",
    "                 ARGS.hidden_dim, ARGS.num_epochs, 'rid_model.pt',\n",
    "                 ARGS.lr, train_dataloader, valid_dataloader, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T08:36:08.528760Z",
     "iopub.status.busy": "2020-11-18T08:36:08.527951Z",
     "iopub.status.idle": "2020-11-18T09:28:47.140405Z",
     "shell.execute_reply": "2020-11-18T09:28:47.139526Z"
    },
    "papermill": {
     "duration": 3158.666765,
     "end_time": "2020-11-18T09:28:47.140548",
     "exception": false,
     "start_time": "2020-11-18T08:36:08.473783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.69it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Training step is: 6\n",
      "Training correct predict num is: 4790, total num is: 12250\n",
      "[Training]     time: 3.56, loss: 0.7177, acc: 0.3910, auc: 0.5062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predict num is: 96, total num is: 250\n",
      " loss is: 0.7089, acc: 0.3840, auc: 0.5316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T09:28:52.532284Z",
     "iopub.status.busy": "2020-11-18T09:28:52.531231Z",
     "iopub.status.idle": "2020-11-18T09:28:52.537316Z",
     "shell.execute_reply": "2020-11-18T09:28:52.536316Z"
    },
    "papermill": {
     "duration": 2.958129,
     "end_time": "2020-11-18T09:28:52.537461",
     "exception": false,
     "start_time": "2020-11-18T09:28:49.579332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(train_dataloader)\n",
    "del(valid_dataloader)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 3.577943,
     "end_time": "2020-11-18T09:29:00.520381",
     "exception": false,
     "start_time": "2020-11-18T09:28:56.942438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 模型解码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T09:29:05.516400Z",
     "iopub.status.busy": "2020-11-18T09:29:05.515237Z",
     "iopub.status.idle": "2020-11-18T09:29:05.601665Z",
     "shell.execute_reply": "2020-11-18T09:29:05.602251Z"
    },
    "papermill": {
     "duration": 2.641123,
     "end_time": "2020-11-18T09:29:05.602444",
     "exception": false,
     "start_time": "2020-11-18T09:29:02.961321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " model = SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T09:29:10.841354Z",
     "iopub.status.busy": "2020-11-18T09:29:10.840446Z",
     "iopub.status.idle": "2020-11-18T09:29:10.879562Z",
     "shell.execute_reply": "2020-11-18T09:29:10.880385Z"
    },
    "papermill": {
     "duration": 2.831434,
     "end_time": "2020-11-18T09:29:10.880590",
     "exception": false,
     "start_time": "2020-11-18T09:29:08.049156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAKT(\n",
       "  (_layers): ModuleList(\n",
       "    (0): SAKTLayer(\n",
       "      (_self_attn): MultiHeadedAttention(\n",
       "        (linears): ModuleList(\n",
       "          (0): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (1): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (2): Linear(in_features=100, out_features=100, bias=False)\n",
       "          (3): Linear(in_features=100, out_features=100, bias=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_ffn): PositionwiseFeedForward(\n",
       "        (w_1): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (w_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (_layernorms): ModuleList(\n",
       "        (0): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "        (1): LayerNorm((100,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_prediction): Linear(in_features=100, out_features=1, bias=True)\n",
       "  (_positional_embedding): Embedding(21, 100, padding_idx=0)\n",
       "  (_interaction_embedding): Embedding(27047, 100, padding_idx=0)\n",
       "  (_question_embedding): Embedding(13524, 100, padding_idx=0)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('rid_model.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T09:29:16.282883Z",
     "iopub.status.busy": "2020-11-18T09:29:16.281755Z",
     "iopub.status.idle": "2020-11-18T09:29:16.285427Z",
     "shell.execute_reply": "2020-11-18T09:29:16.284635Z"
    },
    "papermill": {
     "duration": 2.482964,
     "end_time": "2020-11-18T09:29:16.285554",
     "exception": false,
     "start_time": "2020-11-18T09:29:13.802590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>answered_correctly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23880198</th>\n",
       "      <td>468610029</td>\n",
       "      <td>1514053191</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85063924</th>\n",
       "      <td>17632785307</td>\n",
       "      <td>2057338899</td>\n",
       "      <td>1662</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23530629</th>\n",
       "      <td>447781757</td>\n",
       "      <td>506346902</td>\n",
       "      <td>8268</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44641962</th>\n",
       "      <td>2072126927</td>\n",
       "      <td>1825993815</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96940391</th>\n",
       "      <td>43369418950</td>\n",
       "      <td>9172123</td>\n",
       "      <td>3236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63705876</th>\n",
       "      <td>5355333461</td>\n",
       "      <td>1755854454</td>\n",
       "      <td>4046</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718166</th>\n",
       "      <td>807265</td>\n",
       "      <td>372907427</td>\n",
       "      <td>3879</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57280242</th>\n",
       "      <td>3885523418</td>\n",
       "      <td>509791974</td>\n",
       "      <td>8694</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865885</th>\n",
       "      <td>458045</td>\n",
       "      <td>1304965240</td>\n",
       "      <td>4269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96586282</th>\n",
       "      <td>41459337420</td>\n",
       "      <td>788119785</td>\n",
       "      <td>7388</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     user_id  content_id  content_type_id  \\\n",
       "23880198    468610029  1514053191         438                0   \n",
       "85063924  17632785307  2057338899        1662                0   \n",
       "23530629    447781757   506346902        8268                0   \n",
       "44641962   2072126927  1825993815         291                0   \n",
       "96940391  43369418950     9172123        3236                0   \n",
       "63705876   5355333461  1755854454        4046                0   \n",
       "6718166        807265   372907427        3879                0   \n",
       "57280242   3885523418   509791974        8694                0   \n",
       "4865885        458045  1304965240        4269                0   \n",
       "96586282  41459337420   788119785        7388                0   \n",
       "\n",
       "          answered_correctly  \n",
       "23880198                   0  \n",
       "85063924                   1  \n",
       "23530629                   1  \n",
       "44641962                   0  \n",
       "96940391                   1  \n",
       "63705876                   1  \n",
       "6718166                    0  \n",
       "57280242                   1  \n",
       "4865885                    0  \n",
       "96586282                   1  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iter_test = env.iter_test()\n",
    "test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df2 = test_df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df2[-1000000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T09:29:21.261115Z",
     "iopub.status.busy": "2020-11-18T09:29:21.259952Z",
     "iopub.status.idle": "2020-11-18T09:29:23.872990Z",
     "shell.execute_reply": "2020-11-18T09:29:23.872322Z"
    },
    "papermill": {
     "duration": 5.078061,
     "end_time": "2020-11-18T09:29:23.873173",
     "exception": false,
     "start_time": "2020-11-18T09:29:18.795112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 489/489 [01:36<00:00,  5.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bingo\n"
     ]
    }
   ],
   "source": [
    "# test_df = pd.read_csv('/Users/hesu/Documents/KT/riiid/example_test.csv')\n",
    "try:\n",
    "    test_df = test_df.loc[test_df['content_type_id'] == 0]\n",
    "# test_df['content_id'] = test_df['content_id'] + 1\n",
    "    test_df['content_id'].fillna(0,inplace=True)\n",
    "#     test_df = pd.merge(test_df, question_df, left_on='content_id', \n",
    "#                        right_on='question_id', how='left')\n",
    "    test_df = test_df.loc[:,['content_id','content_type_id','user_id','timestamp']]\n",
    "    test_df = test_df.fillna(-1)\n",
    "    \n",
    "    test_dataset = UserSepDataSet_Rii_Test(test_df, user_dict2, is_test=True)\n",
    "    test_dataloader = data.DataLoader(\n",
    "            dataset=test_dataset, shuffle=False,\n",
    "            batch_size=ARGS.train_batch, num_workers=ARGS.num_workers)\n",
    "    model =  SAKT(ARGS.hidden_dim, QUESTION_NUM['riii'], ARGS.num_layers,\n",
    "                     ARGS.num_head, ARGS.dropout).to(ARGS.device)\n",
    "    model.load_state_dict(torch.load('rid_model.pt'))\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader):\n",
    "            batch = tuple(t.to(ARGS.device) for t in batch)\n",
    "            question_id, target_id = batch\n",
    "            output = model(question_id, target_id)\n",
    "            pred = (torch.sigmoid(output) >= 0.5).long()\n",
    "            pred = pred.view(-1)\n",
    "            preds.extend(pred)\n",
    "        preds = [int(e) for e in preds]\n",
    "        test_df['answered_correctly'] =  preds\n",
    "finally:\n",
    "    print(\"Bingo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000000, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-18T09:29:28.888646Z",
     "iopub.status.busy": "2020-11-18T09:29:28.884420Z",
     "iopub.status.idle": "2020-11-18T09:29:28.893654Z",
     "shell.execute_reply": "2020-11-18T09:29:28.892980Z"
    },
    "papermill": {
     "duration": 2.535949,
     "end_time": "2020-11-18T09:29:28.893796",
     "exception": false,
     "start_time": "2020-11-18T09:29:26.357847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"./submission.csv\")\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 2.524167,
     "end_time": "2020-11-18T09:29:33.986067",
     "exception": false,
     "start_time": "2020-11-18T09:29:31.461900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/hesu/Documents/KT/riiid/example_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 2.546031,
     "end_time": "2020-11-18T09:29:39.018609",
     "exception": false,
     "start_time": "2020-11-18T09:29:36.472578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>group_num</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>content_type_id</th>\n",
       "      <th>task_container_id</th>\n",
       "      <th>prior_question_elapsed_time</th>\n",
       "      <th>prior_question_had_explanation</th>\n",
       "      <th>prior_group_answers_correct</th>\n",
       "      <th>prior_group_responses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>275030867</td>\n",
       "      <td>5729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13309898705</td>\n",
       "      <td>554169193</td>\n",
       "      <td>12010</td>\n",
       "      <td>0</td>\n",
       "      <td>4427</td>\n",
       "      <td>19000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4213672059</td>\n",
       "      <td>1720860329</td>\n",
       "      <td>457</td>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>62798072960</td>\n",
       "      <td>288641214</td>\n",
       "      <td>13262</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10585422061</td>\n",
       "      <td>1728340777</td>\n",
       "      <td>6119</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>72400.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>18020362258</td>\n",
       "      <td>1364159702</td>\n",
       "      <td>12023</td>\n",
       "      <td>0</td>\n",
       "      <td>4424</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2325432079</td>\n",
       "      <td>1521618396</td>\n",
       "      <td>574</td>\n",
       "      <td>0</td>\n",
       "      <td>1367</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>39456940781</td>\n",
       "      <td>1317245193</td>\n",
       "      <td>12043</td>\n",
       "      <td>0</td>\n",
       "      <td>5314</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3460555189</td>\n",
       "      <td>1700555100</td>\n",
       "      <td>7910</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2214770464</td>\n",
       "      <td>998511398</td>\n",
       "      <td>7908</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>516803182</td>\n",
       "      <td>1422853669</td>\n",
       "      <td>1143</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11033</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11032</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11034</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>2153839851</td>\n",
       "      <td>1096784725</td>\n",
       "      <td>11031</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>34250.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1218852591</td>\n",
       "      <td>385471210</td>\n",
       "      <td>9538</td>\n",
       "      <td>0</td>\n",
       "      <td>378</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>32722340115</td>\n",
       "      <td>1202386221</td>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2059097926</td>\n",
       "      <td>2018567473</td>\n",
       "      <td>12148</td>\n",
       "      <td>0</td>\n",
       "      <td>589</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>23609</td>\n",
       "      <td>275030867</td>\n",
       "      <td>5502</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 3, 3, 1, 1, 0, 3, 1, 2, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2035159380</td>\n",
       "      <td>1233875513</td>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>1431</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  group_num    timestamp     user_id  content_id  content_type_id  \\\n",
       "0        0          0            0   275030867        5729                0   \n",
       "1        1          0  13309898705   554169193       12010                0   \n",
       "2        2          0   4213672059  1720860329         457                0   \n",
       "3        3          0  62798072960   288641214       13262                0   \n",
       "4        4          0  10585422061  1728340777        6119                0   \n",
       "5        5          0  18020362258  1364159702       12023                0   \n",
       "6        6          0   2325432079  1521618396         574                0   \n",
       "7        7          0  39456940781  1317245193       12043                0   \n",
       "8        8          0   3460555189  1700555100        7910                0   \n",
       "9        9          0   2214770464   998511398        7908                0   \n",
       "10      10          0    516803182  1422853669        1143                0   \n",
       "11      11          0   2153839851  1096784725       11033                0   \n",
       "12      12          0   2153839851  1096784725       11032                0   \n",
       "13      13          0   2153839851  1096784725       11034                0   \n",
       "14      14          0   2153839851  1096784725       11031                0   \n",
       "15      15          0   1218852591   385471210        9538                0   \n",
       "16      16          0  32722340115  1202386221        1002                0   \n",
       "17      17          0   2059097926  2018567473       12148                0   \n",
       "18      18          1        23609   275030867        5502                0   \n",
       "19      19          1   2035159380  1233875513        1512                0   \n",
       "\n",
       "    task_container_id  prior_question_elapsed_time  \\\n",
       "0                   0                          NaN   \n",
       "1                4427                      19000.0   \n",
       "2                 240                      17000.0   \n",
       "3                 266                      23000.0   \n",
       "4                 162                      72400.0   \n",
       "5                4424                      18000.0   \n",
       "6                1367                      18000.0   \n",
       "7                5314                      17000.0   \n",
       "8                 532                      21000.0   \n",
       "9                 393                      21000.0   \n",
       "10                 85                      15000.0   \n",
       "11                315                      34250.0   \n",
       "12                315                      34250.0   \n",
       "13                315                      34250.0   \n",
       "14                315                      34250.0   \n",
       "15                378                      11000.0   \n",
       "16                136                      16000.0   \n",
       "17                589                      17000.0   \n",
       "18                  1                      34000.0   \n",
       "19               1431                      25000.0   \n",
       "\n",
       "   prior_question_had_explanation  \\\n",
       "0                             NaN   \n",
       "1                            True   \n",
       "2                            True   \n",
       "3                            True   \n",
       "4                            True   \n",
       "5                            True   \n",
       "6                            True   \n",
       "7                            True   \n",
       "8                            True   \n",
       "9                            True   \n",
       "10                           True   \n",
       "11                           True   \n",
       "12                           True   \n",
       "13                           True   \n",
       "14                           True   \n",
       "15                           True   \n",
       "16                           True   \n",
       "17                           True   \n",
       "18                          False   \n",
       "19                           True   \n",
       "\n",
       "                          prior_group_answers_correct  \\\n",
       "0                                                  []   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18  [0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, ...   \n",
       "19                                                NaN   \n",
       "\n",
       "                                prior_group_responses  \n",
       "0                                                  []  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "3                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                                                 NaN  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18  [0, 0, 1, 1, 0, 1, 3, 3, 1, 1, 0, 3, 1, 2, 2, ...  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    test_df['answered_correctly'] = 0.5\n",
    "    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "duration": 3654.781962,
   "end_time": "2020-11-18T09:29:41.902416",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-18T08:28:47.120454",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
